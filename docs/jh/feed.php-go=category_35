<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">
<channel>
<title><![CDATA[流浪的龙－个人知识管理]]></title> 
<link>http://i.renjihe.com/blog/index.php</link> 
<description><![CDATA[]]></description> 
<language>zh-cn</language> 
<copyright><![CDATA[流浪的龙－个人知识管理]]></copyright>
<item>
<link>http://i.renjihe.com/blog/read.php?7476</link>
<title><![CDATA[大牛的《深度学习》笔记，Deep Learning速成教程]]></title> 
<author>renjihe1988 &lt;admin@yourname.com&gt;</author>
<category><![CDATA[AR&amp;AI&amp;模式识别]]></category>
<pubDate>Wed, 17 Aug 2016 13:33:41 +0000</pubDate> 
<guid>http://i.renjihe.com/blog/read.php?7476</guid> 
<description>
<![CDATA[ 
	http://www.leiphone.com/news/201608/7lwVZCXnScbQb6cJ.html<br /><br /><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><strong><span style="color: #7f7f7f"><em style="font-weight: normal">雷锋网<span style="color: #fd5d3c">(搜索&ldquo;雷锋网&rdquo;公众号关注)</span>按：本文由Zouxy责编，全面介绍了深度学习的发展历史及其在各个领域的应用，并解释了深度学习的基本思想，深度与浅度学习的区别和深度学习与<a style="text-decoration: none; color: #ed5565; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline; transition: all 0.2s ease-out" href="http://www.leiphone.com/news/201505/t3T1XQy2g3spCUdd.html" target="_blank" title="神经网络">神经网络</a>之间的关系。</em></span></strong></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #3f3f3f"><em>深度学习</em></span><em><em style="line-height: 1.8"><span style="line-height: 1.8">，</span></em></em><em style="line-height: 1.8">即Deep Learning,是一种学习算法（Learning algorithm）,亦是人工智能领域的一个重要分支。从快速发展到实际应用，短短几年时间里，深度学习颠覆了语音识别、图像分类、文本理解等众多领域的算法设计思路，渐渐形成了一种从训练数据出发，经过一个端到端（end-to-end）的模型，然后直接输出得到最终结果的一种新模式。那么，深度学习有多深？学了究竟有几分？本文将带你领略深度学习高端范儿背后的方法与过程。</em></p><h5 style="margin: 20px 0px 15px; padding: 0px; font-size: 13px; color: #5a5a5a; font-family: 'microsoft yahei'"><span style="color: #3f3f3f">一、概述</span><span style="color: #4f81bd"><br /></span></h5><h5 style="margin: 20px 0px 15px; padding: 0px; font-size: 13px; color: #5a5a5a; font-family: 'microsoft yahei'"><span style="color: #3f3f3f">二、背景</span></h5><h5 style="margin: 20px 0px 15px; padding: 0px; font-size: 13px; color: #5a5a5a; font-family: 'microsoft yahei'"><span style="color: #3f3f3f">三、人脑视觉机理</span></h5><h5 style="margin: 20px 0px 15px; padding: 0px; font-size: 13px; color: #5a5a5a; font-family: 'microsoft yahei'"><span style="color: #3f3f3f">四、关于特征</span><br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.1、特征表示的粒度</h5><h5 style="margin: 20px 0px 15px; padding: 0px; font-size: 13px; color: #5a5a5a; font-family: 'microsoft yahei'">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.2、初级（浅层）特征表示</h5><h5 style="margin: 20px 0px 15px; padding: 0px; font-size: 13px; color: #5a5a5a; font-family: 'microsoft yahei'">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.3、结构性特征表示</h5><h5 style="margin: 20px 0px 15px; padding: 0px; font-size: 13px; color: #5a5a5a; font-family: 'microsoft yahei'">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.4、需要有多少个特征？</h5><h5 style="margin: 20px 0px 15px; padding: 0px; font-size: 13px; color: #5a5a5a; font-family: 'microsoft yahei'"><span style="color: #3f3f3f">五、Deep Learning的基本思想</span></h5><h5 style="margin: 20px 0px 15px; padding: 0px; font-size: 13px; color: #5a5a5a; font-family: 'microsoft yahei'"><span style="color: #3f3f3f">六、浅层学习（Shallow Learning）和深度学习（Deep Learning）</span></h5><h5 style="margin: 20px 0px 15px; padding: 0px; font-size: 13px; color: #5a5a5a; font-family: 'microsoft yahei'"><span style="color: #3f3f3f">七、Deep learning与Neural Network</span></h5><h5 style="margin: 20px 0px 15px; padding: 0px; font-size: 13px; color: #5a5a5a; font-family: 'microsoft yahei'"><span style="color: #3f3f3f">八、Deep learning训练过程</span></h5><h5 style="margin: 20px 0px 15px; padding: 0px; font-size: 13px; color: #5a5a5a; font-family: 'microsoft yahei'">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 8.1、传统神经网络的训练方法</h5><h5 style="margin: 20px 0px 15px; padding: 0px; font-size: 13px; color: #5a5a5a; font-family: 'microsoft yahei'">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 8.2、deep learning训练过程</h5><h5 style="margin: 20px 0px 15px; padding: 0px; font-size: 13px; color: #5a5a5a; font-family: 'microsoft yahei'"><span style="color: #3f3f3f">九、Deep Learning的常用模型或者方法</span></h5><h5 style="margin: 20px 0px 15px; padding: 0px; font-size: 13px; color: #5a5a5a; font-family: 'microsoft yahei'">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 9.1、AutoEncoder自动编码器</h5><h5 style="margin: 20px 0px 15px; padding: 0px; font-size: 13px; color: #5a5a5a; font-family: 'microsoft yahei'">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 9.2、Sparse Coding稀疏编码</h5><h5 style="margin: 20px 0px 15px; padding: 0px; font-size: 13px; color: #5a5a5a; font-family: 'microsoft yahei'">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 9.3、Restricted Boltzmann Machine(RBM)限制波尔兹曼机</h5><h5 style="margin: 20px 0px 15px; padding: 0px; font-size: 13px; color: #5a5a5a; font-family: 'microsoft yahei'">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 9.4、Deep BeliefNetworks深信度网络</h5><h5 style="margin: 20px 0px 15px; padding: 0px; font-size: 13px; color: #5a5a5a; font-family: 'microsoft yahei'">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 9.5、Convolutional Neural Networks卷积神经网络</h5><h5 style="margin: 20px 0px 15px; padding: 0px; font-size: 13px; color: #5a5a5a; font-family: 'microsoft yahei'"><span style="color: #3f3f3f">十、总结与展望</span></h5><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"></p><hr style="color: #5a5a5a; font-family: 'microsoft yahei'; font-size: 16px; line-height: 28.8px" /><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="font-size: 24px"><strong><span style="color: #ff0000">&#124;</span></strong></span><strong><span style="color: #000000">一、概述</span></strong><br /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">Artificial Intelligence，也就是人 &nbsp; 工智能，就像长生不老和星际漫游一样，是人类最美好的梦想之一。虽然计算机技术已经取得了长足的进步，但是到目前为止，还没有一台电脑能产生&ldquo;自我&rdquo;的意识。是的，在人类和大量现成数据的帮助下，电脑可以表现的十分强大，但是离开了这两者，它甚至都不能分辨一个喵星人和一个汪星人。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">图灵（图灵，大家都知道吧。计算机和人工智能的鼻祖，分别对应于其著名的&ldquo;图灵机&rdquo;和&ldquo;图灵测试&rdquo;）在 1950 年的论文里，提出图灵试验的设想，即，隔墙对话，你将不知道与你谈话的，是人还是电脑。这无疑给计算机，尤其是人工智能，预设了一个很高的期望值。但是半个世纪过去了，人工智能的进展，远远没有达到图灵试验的标准。这不仅让多年翘首以待的人们，心灰意冷，认为人工智能是忽悠，相关领域是&ldquo;伪科学&rdquo;。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">但是自 2006 年以来，机器学习领域，取得了突破性的进展。图灵试验，至少不是那么可望而不可及了。至于技术手段，不仅仅依赖于云计算对大数据的并行处理能力，而且依赖于算法。这个算法就是，Deep Learning。借助于 Deep Learning 算法，人类终于找到了如何处理&ldquo;抽象概念&rdquo;这个亘古难题的方法。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a1949a44b00.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><br /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">2012年6月，《纽约时报》披露了Google Brain项目，吸引了公众的广泛关注。这个项目是由著名的斯坦福大学的机器学习教授Andrew Ng和在大规模计算机系统方面的世界顶尖专家JeffDean共同主导，用16000个CPU Core的并行计算平台训练一种称为&ldquo;深度神经网络&rdquo;（DNN，Deep Neural Networks）的机器学习模型（内部共有10亿个节点。这一网络自然是不能跟人类的神经网络相提并论的。要知道，人脑中可是有150多亿个神经元，互相连接的节点也就是突触数更是如银河沙数。曾经有人估算过，如果将一个人的大脑中所有神经细胞的轴突和树突依次连接起来，并拉成一根直线，可从地球连到月亮，再从月亮返回地球），在语音识别和图像识别等领域获得了巨大的成功。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">项目负责人之一Andrew称：&ldquo;我们没有像通常做的那样自己框定边界，而是直接把海量数据投放到算法中，让数据自己说话，系统会自动从数据中学习。&rdquo;另外一名负责人Jeff则说：&ldquo;我们在训练的时候从来不会告诉机器说：&lsquo;这是一只猫。&rsquo;系统其实是自己发明或者领悟了&ldquo;猫&rdquo;的概念。&rdquo;</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a194a6d11b3.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">2012年11月，微软在中国天津的一次活动上公开演示了一个全自动的同声传译系统，讲演者用英文演讲，后台的计算机一气呵成自动完成语音识别、英中机器翻译和中文语音合成，效果非常流畅。据报道，后面支撑的关键技术也是DNN，或者深度学习（DL，DeepLearning）。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">2013年1月，在百度年会上，创始人兼CEO李彦宏高调宣布要成立百度研究院，其中第一个成立的就是&ldquo;深度学习研究所&rdquo;（IDL，Institue of Deep Learning）。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a194a894f79.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><br /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">为什么拥有大数据的互联网公司争相投入大量资源研发深度学习技术。听起来感觉deeplearning很牛那样。那什么是deep learning？为什么有deep learning？它是怎么来的？又能干什么呢？目前存在哪些困难呢？这些问题的简答都需要慢慢来。咱们先来了解下机器学习（人工智能的核心）的背景。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="font-size: 24px"><strong><span style="color: #ff0000">&#124;</span></strong></span><strong><span style="color: #0c0c0c">二、背景</span></strong></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">机器学习（Machine Learning）是一门专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能的学科。机器能否像人类一样能具有学习能力呢？1959年美国的塞缪尔(Samuel)设计了一个下棋程序，这个程序具有学习能力，它可以在不断的对弈中改善自己的棋艺。4年后，这个程序战胜了设计者本人。又过了3年，这个程序战胜了美国一个保持8年之久的常胜不败的冠军。这个程序向人们展示了机器学习的能力，提出了许多令人深思的社会问题与哲学问题（呵呵，人工智能正常的轨道没有很大的发展，这些什么哲学伦理啊倒发展的挺快。什么未来机器越来越像人，人越来越像机器啊。什么机器会反人类啊，ATM是开第一枪的啊等等。人类的思维无穷啊）。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">机器学习虽然发展了几十年，但还是存在很多没有良好解决的问题：</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a194aa12a0b.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><br /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">例如图像识别、语音识别、自然语言理解、天气预测、基因表达、内容推荐等等。目前我们通过机器学习去解决这些问题的思路都是这样的（以视觉感知为例子）：<br /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a194ab9d5b5.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">从开始的通过传感器（例如CMOS）来获得数据。然后经过预处理、特征提取、特征选择，再到推理、预测或者识别。最后一个部分，也就是机器学习的部分，绝大部分的工作是在这方面做的，也存在很多的paper和研究。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">而中间的三部分，概括起来就是特征表达。良好的特征表达，对最终算法的准确性起了非常关键的作用，而且系统主要的计算和测试工作都耗在这一大部分。但，这块实际中一般都是人工完成的。靠人工提取特征。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a194adb59f3.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">截止现在，也出现了不少NB的特征（好的特征应具有不变性（大小、尺度和旋转等）和可区分性）：例如Sift的出现，是局部图像特征描述子研究领域一项里程碑式的工作。由于SIFT对尺度、旋转以及一定视角和光照变化等图像变化都具有不变性，并且SIFT具有很强的可区分性，的确让很多问题的解决变为可能。但它也不是万能的。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a194af44009.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">然而，手工地选取特征是一件非常费力、启发式（需要专业知识）的方法，能不能选取好很大程度上靠经验和运气，而且它的调节需要大量的时间。既然手工选取特征不太好，那么能不能自动地学习一些特征呢？答案是能！Deep Learning就是用来干这个事情的，看它的一个别名UnsupervisedFeature Learning，就可以顾名思义了，Unsupervised的意思就是不要人参与特征的选取过程。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">那它是怎么学习的呢？怎么知道哪些特征好哪些不好呢？我们说机器学习是一门专门研究计算机怎样模拟或实现人类的学习行为的学科。好，那我们人的视觉系统是怎么工作的呢？为什么在茫茫人海，芸芸众生，滚滚红尘中我们都可以找到另一个她（因为，你存在我深深的脑海里，我的梦里 我的心里 我的歌声里&hellip;&hellip;）。人脑那么NB，我们能不能参考人脑，模拟人脑呢？（好像和人脑扯上点关系的特征啊，算法啊，都不错，但不知道是不是人为强加的，为了使自己的作品变得神圣和高雅。） 近几十年以来，认知神经科学、生物学等等学科的发展，让我们对自己这个神秘的而又神奇的大脑不再那么的陌生。也给人工智能的发展推波助澜。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><strong><span style="font-size: 24px; color: #ff0000">&#124;</span><span style="color: #0c0c0c">三、人脑视觉机理</span></strong></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">1981 年的诺贝尔医学奖，颁发给了 David Hubel（出生于加拿大的美国神经生物学家） 和TorstenWiesel，以及 Roger Sperry。前两位的主要贡献，是&ldquo;发现了视觉系统的信息处理&rdquo;：可视皮层是分级的：</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a194b0b1b64.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">我们看看他们做了什么。1958 年，DavidHubel 和Torsten Wiesel 在 JohnHopkins University，研究瞳孔区域与大脑皮层神经元的对应关系。他们在猫的后脑头骨上，开了一个3 毫米的小洞，向洞里插入电极，测量神经元的活跃程度。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">然后，他们在小猫的眼前，展现各种形状、各种亮度的物体。并且，在展现每一件物体时，还改变物体放置的位置和角度。他们期望通过这个办法，让小猫瞳孔感受不同类型、不同强弱的刺激。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">之所以做这个试验，目的是去证明一个猜测。位于后脑皮层的不同视觉神经元，与瞳孔所受刺激之间，存在某种对应关系。一旦瞳孔受到某一种刺激，后脑皮层的某一部分神经元就会活跃。经历了很多天反复的枯燥的试验，同时牺牲了若干只可怜的小猫，David Hubel 和Torsten Wiesel 发现了一种被称为&ldquo;方向选择性细胞（Orientation Selective Cell）&rdquo;的神经元细胞。当瞳孔发现了眼前的物体的边缘，而且这个边缘指向某个方向时，这种神经元细胞就会活跃。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">这个发现激发了人们对于神经系统的进一步思考。神经-中枢-大脑的工作过程，或许是一个不断迭代、不断抽象的过程。这里的关键词有两个，一个是抽象，一个是迭代。从原始信号，做低级抽象，逐渐向高级抽象迭代。人类的逻辑思维，经常使用高度抽象的概念。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">例如，从原始信号摄入开始（瞳孔摄入像素 Pixels），接着做初步处理（大脑皮层某些细胞发现边缘和方向），然后抽象（大脑判定，眼前的物体的形状，是圆形的），然后进一步抽象（大脑进一步判定该物体是只气球）。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a194b23a6e1.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">这个生理学的发现，促成了计算机人工智能，在四十年后的突破性发展。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">总的来说，人的视觉系统的信息处理是分级的。从低级的V1区提取边缘特征，再到V2区的形状或者目标的部分等，再到更高层，整个目标、目标的行为等。也就是说高层的特征是低层特征的组合，从低层到高层的特征表示越来越抽象，越来越能表现语义或者意图。而抽象层面越高，存在的可能猜测就越少，就越利于分类。例如，单词集合和句子的对应是多对一的，句子和语义的对应又是多对一的，语义和意图的对应还是多对一的，这是个层级体系。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">敏感的人注意到关键词了：分层。而Deep learning的deep是不是就表示我存在多少层，也就是多深呢？没错。那Deep learning是如何借鉴这个过程的呢？毕竟是归于计算机来处理，面对的一个问题就是怎么对这个过程建模？</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">因为我们要学习的是特征的表达，那么关于特征，或者说关于这个层级特征，我们需要了解地更深入点。所以在说Deep Learning之前，我们有必要再啰嗦下特征（呵呵，实际上是看到那么好的对特征的解释，不放在这里有点可惜，所以就塞到这了）。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="font-size: 24px; color: #ff0000"><strong>&#124;</strong></span><span style="color: #0c0c0c">四、关于特征</span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">特征是机器学习系统的原材料，对最终模型的影响是毋庸置疑的。如果数据被很好的表达成了特征，通常线性模型就能达到满意的精度。那对于特征，我们需要考虑什么呢？</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #0c0c0c">4.1、特征表示的粒度</span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">学习算法在一个什么粒度上的特征表示，才有能发挥作用-？就一个图片来说，像素级的特征根本没有价值。例如下面的摩托车，从像素级别，根本得不到任何信息，其无法进行摩托车和非摩托车的区分。而如果特征是一个具有结构性（或者说有含义）的时候，比如是否具有车把手（handle），是否具有车轮（wheel），就很容易把摩托车和非摩托车区分，学习算法才能发挥作用。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a194b422c8b.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #0c0c0c">4.2、初级（浅层）特征表示</span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #0c0c0c">既然像素级的特征表示方法没有作用，那怎样的表示才有用呢？</span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">1995 年前后，Bruno Olshausen和 David Field 两位学者任职 Cornell University，他们试图同时用生理学和计算机的手段，双管齐下，研究视觉问题。 他们收集了很多黑白风景照片，从这些照片中，提取出400个小碎片，每个照片碎片的尺寸均为 16x16 像素，不妨把这400个碎片标记为 S[i], i = 0,.. 399。接下来，再从这些黑白风景照片中，随机提取另一个碎片，尺寸也是 16x16 像素，不妨把这个碎片标记为 T。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">他们提出的问题是，如何从这400个碎片中，选取一组碎片，S[k], 通过叠加的办法，合成出一个新的碎片，而这个新的碎片，应当与随机选择的目标碎片 T，尽可能相似，同时，S[k] 的数量尽可能少。用数学的语言来描述，就是：</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #7f7f7f"><em>Sum_k (a[k] * S[k]) --&gt; T,&nbsp;&nbsp;&nbsp;&nbsp; 其中 a[k] 是在叠加碎片 S[k] 时的权重系数。</em></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #7f7f7f"><em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 为解决这个问题，Bruno Olshausen和 David Field 发明了一个算法，稀疏编码（Sparse Coding）。</em></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">稀疏编码是一个重复迭代的过程，每次迭代分两步：</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><em><span style="color: #7f7f7f">1）选择一组 S[k]，然后调整 a[k]，使得Sum_k (a[k] * S[k]) 最接近 T。</span></em></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><em><span style="color: #7f7f7f">2）固定住 a[k]，在 400 个碎片中，选择其它更合适的碎片S&rsquo;[k]，替代原先的 S[k]，使得Sum_k (a[k] * S&rsquo;[k]) 最接近 T。</span></em></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">&nbsp;经过几次迭代后，最佳的 S[k] 组合，被遴选出来了。令人惊奇的是，被选中的 S[k]，基本上都是照片上不同物体的边缘线，这些线段形状相似，区别在于方向。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">Bruno Olshausen和 David Field 的算法结果，与 David Hubel 和Torsten Wiesel 的生理发现，不谋而合！</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">也就是说，复杂图形，往往由一些基本结构组成。比如下图：一个图可以通过用64种正交的edges（可以理解成正交的基本结构）来线性表示。比如样例的x可以用1-64个edges中的三个按照0.8,0.3,0.5的权重调和而成。而其他基本edge没有贡献，因此均为0 。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a194b62d876.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">另外，大牛们还发现，不仅图像存在这个规律，声音也存在。他们从未标注的声音中发现了20种基本的声音结构，其余的声音可以由这20种基本结构合成。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a194bd723b9.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="line-height: 1.8; color: #0c0c0c">4.3、结构性特征表示</span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">小块的图形可以由基本edge构成，更结构化，更复杂的，具有概念性的图形如何表示呢？这就需要更高层次的特征表示，比如V2，V4。因此V1看像素级是像素级。V2看V1是像素级，这个是层次递进的，高层表达由底层表达的组合而成。专业点说就是基basis。V1取提出的basis是边缘，然后V2层是V1层这些basis的组合，这时候V2区得到的又是高一层的basis。即上一层的basis组合的结果，上上层又是上一层的组合basis&hellip;&hellip;（所以有大牛说Deep learning就是&ldquo;搞基&rdquo;，因为难听，所以美其名曰Deep learning或者Unsupervised Feature Learning）</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a194bf934d3.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">&nbsp;直观上说，就是找到make sense的小patch再将其进行combine，就得到了上一层的feature，递归地向上learning feature。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">在不同object上做training是，所得的edge basis 是非常相似的，但object parts和models 就会completely different了（那咱们分辨car或者face是不是容易多了）：</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a194c11bdbb.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">从文本来说，一个doc表示什么意思？我们描述一件事情，用什么来表示比较合适？用一个一个字嘛，我看不是，字就是像素级别了，起码应该是term，换句话说每个doc都由term构成，但这样表示概念的能力就够了嘛，可能也不够，需要再上一步，达到topic级，有了topic，再到doc就合理。但每个层次的数量差距很大，比如doc表示的概念-&gt;topic（千-万量级）-&gt;term（10万量级）-&gt;word（百万量级）。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">一个人在看一个doc的时候，眼睛看到的是word，由这些word在大脑里自动切词形成term，在按照概念组织的方式，先验的学习，得到topic，然后再进行高层次的learning。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #0c0c0c">4.4、需要有多少个特征？</span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">我们知道需要层次的特征构建，由浅入深，但每一层该有多少个特征呢？</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">任何一种方法，特征越多，给出的参考信息就越多，准确性会得到提升。但特征多意味着计算复杂，探索的空间大，可以用来训练的数据在每个特征上就会稀疏，都会带来各种问题，并不一定特征越多越好。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a194c332598.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><br /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">好了，到了这一步，终于可以聊到Deep learning了。上面我们聊到为什么会有Deep learning（让机器自动学习良好的特征，而免去人工选取过程。还有参考人的分层视觉处理系统），我们得到一个结论就是Deep learning需要多层来获得更抽象的特征表达。那么多少层才合适呢？用什么架构来建模呢？怎么进行非监督训练呢？</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><strong><span style="font-size: 24px; color: #ff0000">&#124;</span></strong><span style="color: #0c0c0c">五、Deep Learning的基本思想</span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">假设我们有一个系统S，它有n层（S1,&hellip;Sn），它的输入是I，输出是O，形象地表示为： I =&gt;S1=&gt;S2=&gt;&hellip;..=&gt;Sn =&gt; O，如果输出O等于输入I，即输入I经过这个系统变化之后没有任何的信息损失（呵呵，大牛说，这是不可能的。信息论中有个&ldquo;信息逐层丢失&rdquo;的说法（信息处理不等式），设处理a信息得到b，再对b处理得到c，那么可以证明：a和c的互信息不会超过a和b的互信息。这表明信息处理不会增加信息，大部分处理会丢失信息。当然了，如果丢掉的是没用的信息那多好啊），保持了不变，这意味着输入I经过每一层Si都没有任何的信息损失，即在任何一层Si，它都是原有信息（即输入I）的另外一种表示。现在回到我们的主题Deep Learning，我们需要自动地学习特征，假设我们有一堆输入I（如一堆图像或者文本），假设我们设计了一个系统S（有n层），我们通过调整系统中参数，使得它的输出仍然是输入I，那么我们就可以自动地获取得到输入I的一系列层次特征，即S1，&hellip;, Sn。<br /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">对于深度学习来说，其思想就是对堆叠多个层，也就是说这一层的输出作为下一层的输入。通过这种方式，就可以实现对输入信息进行分级表达了。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">另外，前面是假设输出严格地等于输入，这个限制太严格，我们可以略微地放松这个限制，例如我们只要使得输入与输出的差别尽可能地小即可，这个放松会导致另外一类不同的Deep Learning方法。上述就是Deep Learning的基本思想。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><strong><span style="font-size: 24px; color: #ff0000">&#124;</span><span style="color: #0c0c0c">六、浅层学习（Shallow Learning）和深度学习（Deep Learning）</span></strong></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><span style="color: #0c0c0c">浅层学习是机器学习的第一次浪潮。</span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">20世纪80年代末期，用于人工神经网络的反向传播算法（也叫Back Propagation算法或者BP算法）的发明，给机器学习带来了希望，掀起了基于统计模型的机器学习热潮。这个热潮一直持续到今天。人们发现，利用BP算法可以让一个人工神经网络模型从大量训练样本中学习统计规律，从而对未知事件做预测。这种基于统计的机器学习方法比起过去基于人工规则的系统，在很多方面显出优越性。这个时候的人工神经网络，虽也被称作多层感知机（Multi-layer Perceptron），但实际是种只含有一层隐层节点的浅层模型。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">20世纪90年代，各种各样的浅层机器学习模型相继被提出，例如支撑向量机（SVM，Support Vector Machines）、 Boosting、最大熵方法（如LR，Logistic Regression）等。这些模型的结构基本上可以看成带有一层隐层节点（如SVM、Boosting），或没有隐层节点（如LR）。这些模型无论是在理论分析还是应用中都获得了巨大的成功。相比之下，由于理论分析的难度大，训练方法又需要很多经验和技巧，这个时期浅层人工神经网络反而相对沉寂。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><span style="color: #0c0c0c">&nbsp;深度学习是机器学习的第二次浪潮。</span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">2006年，加拿大多伦多大学教授、机器学习领域的泰斗Geoffrey Hinton和他的学生RuslanSalakhutdinov在《科学》上发表了一篇文章，开启了深度学习在学术界和工业界的浪潮。这篇文章有两个主要观点：1）多隐层的人工神经网络具有优异的特征学习能力，学习得到的特征对数据有更本质的刻画，从而有利于可视化或分类；2）深度神经网络在训练上的难度，可以通过&ldquo;逐层初始化&rdquo;（layer-wise pre-training）来有效克服，在这篇文章中，逐层初始化是通过无监督学习实现的。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">当前多数分类、回归等学习方法为浅层结构算法，其局限性在于有限样本和计算单元情况下对复杂函数的表示能力有限，针对复杂分类问题其泛化能力受到一定制约。深度学习可通过学习一种深层非线性网络结构，实现复杂函数逼近，表征输入数据分布式表示，并展现了强大的从少数样本集中学习数据集本质特征的能力。（多层的好处是可以用较少的参数表示复杂的函数）</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a194c4ac548.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">深度学习的实质，是通过构建具有很多隐层的机器学习模型和海量的训练数据，来学习更有用的特征，从而最终提升分类或预测的准确性。因此，&ldquo;深度模型&rdquo;是手段，&ldquo;特征学习&rdquo;是目的。区别于传统的浅层学习，深度学习的不同在于：1）强调了模型结构的深度，通常有5层、6层，甚至10多层的隐层节点；2）明确突出了特征学习的重要性，也就是说，通过逐层特征变换，将样本在原空间的特征表示变换到一个新特征空间，从而使分类或预测更加容易。与人工规则构造特征的方法相比，利用大数据来学习特征，更能够刻画数据的丰富内在信息。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><strong><span style="font-size: 24px; color: #ff0000">&#124;</span><span style="color: #0c0c0c">七、Deep learning与Neural Network</span></strong></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">深度学习是机器学习研究中的一个新的领域，其动机在于建立、模拟人脑进行分析学习的神经网络，它模仿人脑的机制来解释数据，例如图像，声音和文本。深度学习是无监督学习的一种。<br /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">深度学习的概念源于人工神经网络的研究。含多隐层的多层感知器就是一种深度学习结构。深度学习通过组合低层特征形成更加抽象的高层表示属性类别或特征，以发现数据的分布式特征表示。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">Deep learning本身算是machine learning的一个分支，简单可以理解为neural network的发展。大约二三十年前，neural network曾经是ML领域特别火热的一个方向，但是后来确慢慢淡出了，原因包括以下几个方面：</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #7f7f7f"><em>1）比较容易过拟合，参数比较难tune，而且需要不少trick；</em></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #7f7f7f"><em>2）训练速度比较慢，在层次比较少（小于等于3）的情况下效果并不比其它方法更优；</em></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">所以中间有大约20多年的时间，神经网络被关注很少，这段时间基本上是SVM和boosting算法的天下。但是，一个痴心的老先生Hinton，他坚持了下来，并最终（和其它人一起Bengio、Yann.lecun等）提成了一个实际可行的deep learning框架。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #000000">Deep learning与传统的神经网络之间有相同的地方也有很多不同。</span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">二者的相同在于deep learning采用了神经网络相似的分层结构，系统由包括输入层、隐层（多层）、输出层组成的多层网络，只有相邻层节点之间有连接，同一层以及跨层节点之间相互无连接，每一层可以看作是一个logistic regression模型；这种分层结构，是比较接近人类大脑的结构的。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a194c60b147.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><br /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">而为了克服神经网络训练中的问题，DL采用了与神经网络很不同的训练机制。传统神经网络中，采用的是back propagation的方式进行，简单来讲就是采用迭代的算法来训练整个网络，随机设定初值，计算当前网络的输出，然后根据当前输出和label之间的差去改变前面各层的参数，直到收敛（整体是一个梯度下降法）。而deep learning整体上是一个layer-wise的训练机制。这样做的原因是因为，如果采用back propagation的机制，对于一个deep network（7层以上），残差传播到最前面的层已经变得太小，出现所谓的gradient diffusion（梯度扩散）。这个问题我们接下来讨论。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><strong><span style="font-size: 24px; color: #ff0000">&#124;</span><span style="color: #000000">八、Deep learning训练过程</span></strong></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #000000">8.1、传统神经网络的训练方法为什么不能用在深度神经网络</span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">BP算法作为传统训练多层网络的典型算法，实际上对仅含几层网络，该训练方法就已经很不理想。深度结构（涉及多个非线性处理单元层）非凸目标代价函数中普遍存在的局部最小是训练困难的主要来源。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><strong><em style="font-weight: normal"><span style="color: #7f7f7f">BP算法存在的问题：</span></em></strong></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><em><span style="color: #7f7f7f">（1）梯度越来越稀疏：从顶层越往下，误差校正信号越来越小；</span></em></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><em><span style="color: #7f7f7f">（2）收敛到局部最小值：尤其是从远离最优区域开始的时候（随机值初始化会导致这种情况的发生）；</span></em></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><em><span style="color: #7f7f7f">（3）一般，我们只能用有标签的数据来训练：但大部分的数据是没标签的，而大脑可以从没有标签的的数据中学习；</span></em></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #000000">8.2、deep learning训练过程</span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">如果对所有层同时训练，时间复杂度会太高；如果每次训练一层，偏差就会逐层传递。这会面临跟上面监督学习中相反的问题，会严重欠拟合（因为深度网络的神经元和参数太多了）。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">2006年，hinton提出了在非监督数据上建立多层神经网络的一个有效方法，简单的说，分为两步，一是每次训练一层网络，二是调优，使原始表示x向上生成的高级表示r和该高级表示r向下生成的x'尽可能一致。方法是：</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #7f7f7f"><em>1）首先逐层构建单层神经元，这样每次都是训练一个单层网络。</em></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #7f7f7f"><em>2）当所有层训练完后，Hinton使用wake-sleep算法进行调优。</em></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">将除最顶层的其它层间的权重变为双向的，这样最顶层仍然是一个单层神经网络，而其它层则变为了图模型。向上的权重用于&ldquo;认知&rdquo;，向下的权重用于&ldquo;生成&rdquo;。然后使用Wake-Sleep算法调整所有的权重。让认知和生成达成一致，也就是保证生成的最顶层表示能够尽可能正确的复原底层的结点。比如顶层的一个结点表示人脸，那么所有人脸的图像应该激活这个结点，并且这个结果向下生成的图像应该能够表现为一个大概的人脸图像。Wake-Sleep算法分为醒（wake）和睡（sleep）两个部分。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #7f7f7f"><em>1）wake阶段：认知过程，通过外界的特征和向上的权重（认知权重）产生每一层的抽象表示（结点状态），并且使用梯度下降修改层间的下行权重（生成权重）。也就是&ldquo;如果现实跟我想象的不一样，改变我的权重使得我想象的东西就是这样的&rdquo;。</em></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #7f7f7f"><em>2）sleep阶段：生成过程，通过顶层表示（醒时学得的概念）和向下权重，生成底层的状态，同时修改层间向上的权重。也就是&ldquo;如果梦中的景象不是我脑中的相应概念，改变我的认知权重使得这种景象在我看来就是这个概念&rdquo;。</em></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #000000">deep learning训练过程具体如下：</span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><strong><span style="color: #3f3f3f"><em style="font-weight: normal">1）使用自下上升非监督学习（就是从底层开始，一层一层的往顶层训练）：</em></span></strong></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">采用无标定数据（有标定数据也可）分层训练各层参数，这一步可以看作是一个无监督训练过程，是和传统神经网络区别最大的部分（这个过程可以看作是feature learning过程）</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">具体的，先用无标定数据训练第一层，训练时先学习第一层的参数（这一层可以看作是得到一个使得输出和输入差别最小的三层神经网络的隐层），由于模型capacity的限制以及稀疏性约束，使得得到的模型能够学习到数据本身的结构，从而得到比输入更具有表示能力的特征；在学习得到第n-1层后，将n-1层的输出作为第n层的输入，训练第n层，由此分别得到各层的参数；</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><strong><span style="color: #3f3f3f"><em style="font-weight: normal">2）自顶向下的监督学习（就是通过带标签的数据去训练，误差自顶向下传输，对网络进行微调）：</em></span></strong></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">基于第一步得到的各层参数进一步fine-tune整个多层模型的参数，这一步是一个有监督训练过程；第一步类似神经网络的随机初始化初值过程，由于DL的第一步不是随机初始化，而是通过学习输入数据的结构得到的，因而这个初值更接近全局最优，从而能够取得更好的效果；所以deep learning效果好很大程度上归功于第一步的feature learning过程。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><strong><span style="font-size: 24px; color: #ff0000">&#124;</span><span style="color: #000000">九、Deep Learning的常用模型或者方法</span></strong></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #000000">9.1、AutoEncoder自动编码器</span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">Deep Learning最简单的一种方法是利用人工神经网络的特点，人工神经网络（ANN）本身就是具有层次结构的系统，如果给定一个神经网络，我们假设其输出与输入是相同的，然后训练调整其参数，得到每一层中的权重。自然地，我们就得到了输入I的几种不同表示（每一层代表一种表示），这些表示就是特征。自动编码器就是一种尽可能复现输入信号的神经网络。为了实现这种复现，自动编码器就必须捕捉可以代表输入数据的最重要的因素，就像PCA那样，找到可以代表原信息的主要成分。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #000000">具体过程简单的说明如下：</span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><strong><span style="color: #3f3f3f"><em style="font-weight: normal">1）给定无标签数据，用非监督学习学习特征：</em></span></strong></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><em><span style="color: #262626"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a194c780cc3.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></span></em></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><br /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">在我们之前的神经网络中，如第一个图，我们输入的样本是有标签的，即（input, target），这样我们根据当前输出和target（label）之间的差去改变前面各层的参数，直到收敛。但现在我们只有无标签数据，也就是右边的图。那么这个误差怎么得到呢？</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a194c8aaccd.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><br /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">如上图，我们将input输入一个encoder编码器，就会得到一个code，这个code也就是输入的一个表示，那么我们怎么知道这个code表示的就是input呢？我们加一个decoder解码器，这时候decoder就会输出一个信息，那么如果输出的这个信息和一开始的输入信号input是很像的（理想情况下就是一样的），那很明显，我们就有理由相信这个code是靠谱的。所以，我们就通过调整encoder和decoder的参数，使得重构误差最小，这时候我们就得到了输入input信号的第一个表示了，也就是编码code了。因为是无标签数据，所以误差的来源就是直接重构后与原输入相比得到。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a194c9d65f0.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><strong><span style="color: #3f3f3f"><em style="font-weight: normal">2）通过编码器产生特征，然后训练下一层。这样逐层训练：</em></span></strong></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">那上面我们就得到第一层的code，我们的重构误差最小让我们相信这个code就是原输入信号的良好表达了，或者牵强点说，它和原信号是一模一样的（表达不一样，反映的是一个东西）。那第二层和第一层的训练方式就没有差别了，我们将第一层输出的code当成第二层的输入信号，同样最小化重构误差，就会得到第二层的参数，并且得到第二层输入的code，也就是原输入信息的第二个表达了。其他层就同样的方法炮制就行了（训练这一层，前面层的参数都是固定的，并且他们的decoder已经没用了，都不需要了）。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a194cab95cd.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><strong><span style="color: #3f3f3f"><em style="font-weight: normal">3）有监督微调：</em></span></strong></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">经过上面的方法，我们就可以得到很多层了。至于需要多少层（或者深度需要多少，这个目前本身就没有一个科学的评价方法）需要自己试验调了。每一层都会得到原始输入的不同的表达。当然了，我们觉得它是越抽象越好了，就像人的视觉系统一样。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">到这里，这个AutoEncoder还不能用来分类数据，因为它还没有学习如何去连结一个输入和一个类。它只是学会了如何去重构或者复现它的输入而已。或者说，它只是学习获得了一个可以良好代表输入的特征，这个特征可以最大程度上代表原输入信号。那么，为了实现分类，我们就可以在AutoEncoder的最顶的编码层添加一个分类器（例如罗杰斯特回归、SVM等），然后通过标准的多层神经网络的监督训练方法（梯度下降法）去训练。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">也就是说，这时候，我们需要将最后层的特征code输入到最后的分类器，通过有标签样本，通过监督学习进行微调，这也分两种，一个是只调整分类器（黑色部分）：</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a194cbd0665.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">另一种：通过有标签样本，微调整个系统：（如果有足够多的数据，这个是最好的。end-to-end learning端对端学习）</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a194cced803.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">一旦监督训练完成，这个网络就可以用来分类了。神经网络的最顶层可以作为一个线性分类器，然后我们可以用一个更好性能的分类器去取代它。在研究中可以发现，如果在原有的特征中加入这些自动学习得到的特征可以大大提高精确度，甚至在分类问题中比目前最好的分类算法效果还要好！</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">AutoEncoder存在一些变体，这里简要介绍下两个：</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><strong><span style="color: #3f3f3f"><em style="font-weight: normal">Sparse AutoEncoder稀疏自动编码器：</em></span></strong></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">当然，我们还可以继续加上一些约束条件得到新的Deep Learning方法，如：如果在AutoEncoder的基础上加上L1的Regularity限制（L1主要是约束每一层中的节点中大部分都要为0，只有少数不为0，这就是Sparse名字的来源），我们就可以得到Sparse AutoEncoder法。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a194ce144bc.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">如上图，其实就是限制每次得到的表达code尽量稀疏。因为稀疏的表达往往比其他的表达要有效（人脑好像也是这样的，某个输入只是刺激某些神经元，其他的大部分的神经元是受到抑制的）。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #3f3f3f"><em>Denoising AutoEncoders降噪自动编码器：</em></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">降噪自动编码器DA是在自动编码器的基础上，训练数据加入噪声，所以自动编码器必须学习去去除这种噪声而获得真正的没有被噪声污染过的输入。因此，这就迫使编码器去学习输入信号的更加鲁棒的表达，这也是它的泛化能力比一般编码器强的原因。DA可以通过梯度下降算法去训练。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a197a4a7398.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #0c0c0c">9.2、Sparse Coding稀疏编码</span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">如果我们把输出必须和输入相等的限制放松，同时利用线性代数中基的概念，即O = a1*&Phi;1&nbsp;+ a2*&Phi;2+&hellip;.+ an*&Phi;n， &Phi;i是基，ai是系数，我们可以得到这样一个优化问题：</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">Min &#124;I &ndash; O&#124;，其中I表示输入，O表示输出。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">通过求解这个最优化式子，我们可以求得系数ai和基&Phi;i，这些系数和基就是输入的另外一种近似表达。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a197a5a2f6d.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><br /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">因此，它们可以用来表达输入I，这个过程也是自动学习得到的。如果我们在上述式子上加上L1的Regularity限制，得到：</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">Min &#124;I &ndash; O&#124; + u*(&#124;a1&#124; + &#124;a2&#124; + &hellip; + &#124;an&nbsp;&#124;)</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">这种方法被称为Sparse Coding。通俗的说，就是将一个信号表示为一组基的线性组合，而且要求只需要较少的几个基就可以将信号表示出来。&ldquo;稀疏性&rdquo;定义为：只有很少的几个非零元素或只有很少的几个远大于零的元素。要求系数 ai&nbsp;是稀疏的意思就是说：对于一组输入向量，我们只想有尽可能少的几个系数远大于零。选择使用具有稀疏性的分量来表示我们的输入数据是有原因的，因为绝大多数的感官数据，比如自然图像，可以被表示成少量基本元素的叠加，在图像中这些基本元素可以是面或者线。同时，比如与初级视觉皮层的类比过程也因此得到了提升（人脑有大量的神经元，但对于某些图像或者边缘只有很少的神经元兴奋，其他都处于抑制状态）。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">稀疏编码算法是一种无监督学习方法，它用来寻找一组&ldquo;超完备&rdquo;基向量来更高效地表示样本数据。虽然形如主成分分析技术（PCA）能使我们方便地找到一组&ldquo;完备&rdquo;基向量，但是这里我们想要做的是找到一组&ldquo;超完备&rdquo;基向量来表示输入向量（也就是说，基向量的个数比输入向量的维数要大）。超完备基的好处是它们能更有效地找出隐含在输入数据内部的结构与模式。然而，对于超完备基来说，系数ai不再由输入向量唯一确定。因此，在稀疏编码算法中，我们另加了一个评判标准&ldquo;稀疏性&rdquo;来解决因超完备而导致的退化（degeneracy）问题。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a197a6a6c41.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">比如在图像的Feature Extraction的最底层要做Edge Detector的生成，那么这里的工作就是从Natural Images中randomly选取一些小patch，通过这些patch生成能够描述他们的&ldquo;基&rdquo;，也就是右边的8*8=64个basis组成的basis，然后给定一个test patch, 我们可以按照上面的式子通过basis的线性组合得到，而sparse matrix就是a，下图中的a中有64个维度，其中非零项只有3个，故称&ldquo;sparse&rdquo;。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">这里可能大家会有疑问，为什么把底层作为Edge Detector呢？上层又是什么呢？这里做个简单解释大家就会明白，之所以是Edge Detector是因为不同方向的Edge就能够描述出整幅图像，所以不同方向的Edge自然就是图像的basis了&hellip;&hellip;而上一层的basis组合的结果，上上层又是上一层的组合basis&hellip;&hellip;（就是上面第四部分的时候咱们说的那样）</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #0c0c0c">Sparse coding分为两个部分：</span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #3f3f3f"><strong><em style="font-weight: normal">1）Training阶段：给定一系列的样本图片[x1, x 2, &hellip;]，我们需要学习得到一组基[&Phi;1, &Phi;2, &hellip;]，也就是字典。</em></strong></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">稀疏编码是k-means算法的变体，其训练过程也差不多（EM算法的思想：如果要优化的目标函数包含两个变量，如L(W, B)，那么我们可以先固定W，调整B使得L最小，然后再固定B，调整W使L最小，这样迭代交替，不断将L推向最小值。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">训练过程就是一个重复迭代的过程，按上面所说，我们交替的更改a和&Phi;使得下面这个目标函数最小。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a197b2a6c53.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #1d1b10"><em>每次迭代分两步：</em></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #262626"><em>a）固定字典&Phi;[k]，然后调整a[k]，使得上式，即目标函数最小（即解LASSO问题）。</em></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #262626"><em>b）然后固定住a [k]，调整&Phi; [k]，使得上式，即目标函数最小（即解凸QP问题）。</em></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #262626"><em>不断迭代，直至收敛。这样就可以得到一组可以良好表示这一系列x的基，也就是字典。</em></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><strong><span style="color: #3f3f3f"><em style="font-weight: normal">2）Coding阶段：给定一个新的图片x，由上面得到的字典，通过解一个LASSO问题得到稀疏向量a。这个稀疏向量就是这个输入向量x的一个稀疏表达了。</em></span></strong></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><span style="color: #974806"><em><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a197b3d1705.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></em></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">例如：</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a1997696e8b.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><strong><span style="color: #0c0c0c">9.3、Restricted Boltzmann Machine (RBM)限制波尔兹曼机</span></strong></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">假设有一个二部图，每一层的节点之间没有链接，一层是可视层，即输入数据层（v)，一层是隐藏层(h)，如果假设所有的节点都是随机二值变量节点（只能取0或者1值），同时假设全概率分布p(v,h)满足Boltzmann 分布，我们称这个模型是Restricted BoltzmannMachine (RBM)。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a197b64304c.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">下面我们来看看为什么它是Deep Learning方法。首先，这个模型因为是二部图，所以在已知v的情况下，所有的隐藏节点之间是条件独立的（因为节点之间不存在连接），即p(h&#124;v)=p(h1&#124;v)&hellip;p(hn&#124;v)。同理，在已知隐藏层h的情况下，所有的可视节点都是条件独立的。同时又由于所有的v和h满足Boltzmann 分布，因此，当输入v的时候，通过p(h&#124;v) 可以得到隐藏层h，而得到隐藏层h之后，通过p(v&#124;h)又能得到可视层，通过调整参数，我们就是要使得从隐藏层得到的可视层v1与原来的可视层v如果一样，那么得到的隐藏层就是可视层另外一种表达，因此隐藏层可以作为可视层输入数据的特征，所以它就是一种Deep Learning方法。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a197b776f90.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">如何训练呢？也就是可视层节点和隐节点间的权值怎么确定呢？我们需要做一些数学分析。也就是模型了。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a19a3c4c75c.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">联合组态（jointconfiguration）的能量可以表示为：</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a197b8bce11.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">而某个组态的联合概率分布可以通过Boltzmann 分布（和这个组态的能量）来确定：</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a197b9d50e4.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">因为隐藏节点之间是条件独立的（因为节点之间不存在连接），即：</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a197bacf97d.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">然后我们可以比较容易（对上式进行因子分解Factorizes）得到在给定可视层v的基础上，隐层第j个节点为1或者为0的概率：</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a197bbaaf91.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">同理，在给定隐层h的基础上，可视层第i个节点为1或者为0的概率也可以容易得到：</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a197bc9b886.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">给定一个满足独立同分布的样本集：D=&#123;v(1),&nbsp;v(2),&hellip;,&nbsp;v(N)&#125;，我们需要学习参数&theta;=&#123;W,a,b&#125;。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">我们最大化以下对数似然函数（最大似然估计：对于某个概率模型，我们需要选择一个参数，让我们当前的观测样本的概率最大）：</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a197bd86eae.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">也就是对最大对数似然函数求导，就可以得到L最大时对应的参数W了。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a197be89ab4.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">&nbsp;如果，我们把隐藏层的层数增加，我们可以得到Deep Boltzmann Machine(DBM)；如果我们在靠近可视层的部分使用贝叶斯信念网络（即有向图模型，当然这里依然限制层中节点之间没有链接），而在最远离可视层的部分使用Restricted Boltzmann Machine，我们可以得到DeepBelief Net（DBN）。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a197c0203fc.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #0c0c0c">9.4、Deep Belief Networks深信度网络</span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">DBNs是一个概率生成模型，与传统的判别模型的神经网络相对，生成模型是建立一个观察数据和标签之间的联合分布，对P(Observation&#124;Label)和 P(Label&#124;Observation)都做了评估，而判别模型仅仅而已评估了后者，也就是P(Label&#124;Observation)。对于在深度神经网络应用传统的BP算法的时候，DBNs遇到了以下问题：</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #7f7f7f"><em>（1）需要为训练提供一个有标签的样本集；</em></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #7f7f7f"><em>（2）学习过程较慢；</em></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #7f7f7f"><em>（3）不适当的参数选择会导致学习收敛于局部最优解。</em></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><span style="color: #7f7f7f"><em><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a197c1a2824.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></em></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">DBNs由多个限制玻尔兹曼机（Restricted Boltzmann Machines）层组成，一个典型的神经网络类型如图三所示。这些网络被&ldquo;限制&rdquo;为一个可视层和一个隐层，层间存在连接，但层内的单元间不存在连接。隐层单元被训练去捕捉在可视层表现出来的高阶数据的相关性。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">首先，先不考虑最顶构成一个联想记忆（associative memory）的两层，一个DBN的连接是通过自顶向下的生成权值来指导确定的，RBMs就像一个建筑块一样，相比传统和深度分层的sigmoid信念网络，它能易于连接权值的学习。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">最开始的时候，通过一个非监督贪婪逐层方法去预训练获得生成模型的权值，非监督贪婪逐层方法被Hinton证明是有效的，并被其称为对比分歧（contrastive divergence）。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">在这个训练阶段，在可视层会产生一个向量v，通过它将值传递到隐层。反过来，可视层的输入会被随机的选择，以尝试去重构原始的输入信号。最后，这些新的可视的神经元激活单元将前向传递重构隐层激活单元，获得h（在训练过程中，首先将可视向量值映射给隐单元；然后可视单元由隐层单元重建；这些新可视单元再次映射给隐单元，这样就获取新的隐单元。执行这种反复步骤叫做吉布斯采样）。这些后退和前进的步骤就是我们熟悉的Gibbs采样，而隐层激活单元和可视层输入之间的相关性差别就作为权值更新的主要依据。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">训练时间会显著的减少，因为只需要单个步骤就可以接近最大似然学习。增加进网络的每一层都会改进训练数据的对数概率，我们可以理解为越来越接近能量的真实表达。这个有意义的拓展，和无标签数据的使用，是任何一个深度学习应用的决定性的因素。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/740_740/201608/57a197c334a3c.png?imageMogr2/format/jpg/quality/80" border="0" alt="​大牛的《深度学习》笔记，Deep Learning速成教程" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">在最高两层，权值被连接到一起，这样更低层的输出将会提供一个参考的线索或者关联给顶层，这样顶层就会将其联系到它的记忆内容。而我们最关心的，最后想得到的就是判别性能，例如分类任务里面。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">在预训练后，DBN可以通过利用带标签数据用BP算法去对判别性能做调整。在这里，一个标签集将被附加到顶层（推广联想记忆），通过一个自下向上的，学习到的识别权值获得一个网络的分类面。这个性能会比单纯的BP算法训练的网络好。这可以很直观的解释，DBNs的BP算法只需要对权值参数空间进行一个局部的搜索，这相比前向神经网络来说，训练是要快的，而且收敛的时间也少。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">DBNs的灵活性使得它的拓展比较容易。一个拓展就是卷积DBNs（Convolutional Deep Belief Networks(CDBNs)）。DBNs并没有考虑到图像的2维结构信息，因为输入是简单的从一个图像矩阵一维向量化的。而CDBNs就是考虑到了这个问题，它利用邻域像素的空域关系，通过一个称为卷积RBMs的模型区达到生成模型的变换不变性，而且可以容易得变换到高维图像。DBNs并没有明确地处理对观察变量的时间联系的学习上，虽然目前已经有这方面的研究，例如堆叠时间RBMs，以此为推广，有序列学习的dubbed temporal convolutionmachines，这种序列学习的应用，给语音信号处理问题带来了一个让人激动的未来研究方向。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">目前，和DBNs有关的研究包括堆叠自动编码器，它是通过用堆叠自动编码器来替换传统DBNs里面的RBMs。这就使得可以通过同样的规则来训练产生深度多层神经网络架构，但它缺少层的参数化的严格要求。与DBNs不同，自动编码器使用判别模型，这样这个结构就很难采样输入采样空间，这就使得网络更难捕捉它的内部表达。但是，降噪自动编码器却能很好的避免这个问题，并且比传统的DBNs更优。它通过在训练过程添加随机的污染并堆叠产生场泛化性能。训练单一的降噪自动编码器的过程和RBMs训练生成模型的过程一样。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><strong><span style="font-size: 24px; color: #ff0000">&#124;</span><span style="color: #000000">十、总结与展望</span></strong></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><strong><span style="color: #3f3f3f">1）Deep learning总结</span></strong></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">深度学习是关于自动学习要建模的数据的潜在（隐含）分布的多层（复杂）表达的算法。换句话来说，深度学习算法自动的提取分类需要的低层次或者高层次特征。高层次特征，一是指该特征可以分级（层次）地依赖其他特征，例如：对于机器视觉，深度学习算法从原始图像去学习得到它的一个低层次表达，例如边缘检测器，小波滤波器等，然后在这些低层次表达的基础上再建立表达，例如这些低层次表达的线性或者非线性组合，然后重复这个过程，最后得到一个高层次的表达。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">Deep learning能够得到更好地表示数据的feature，同时由于模型的层次、参数很多，capacity足够，因此，模型有能力表示大规模数据，所以对于图像、语音这种特征不明显（需要手工设计且很多没有直观物理含义）的问题，能够在大规模训练数据上取得更好的效果。此外，从模式识别特征和分类器的角度，deep learning框架将feature和分类器结合到一个框架中，用数据去学习feature，在使用中减少了手工设计feature的巨大工作量（这是目前工业界工程师付出努力最多的方面），因此，不仅仅效果可以更好，而且，使用起来也有很多方便之处，因此，是十分值得关注的一套框架，每个做ML的人都应该关注了解一下。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">当然，deep learning本身也不是完美的，也不是解决世间任何ML问题的利器，不应该被放大到一个无所不能的程度。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #3f3f3f"><strong>2）Deep learning未来</strong></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">深度学习目前仍有大量工作需要研究。目前的关注点还是从机器学习的领域借鉴一些可以在深度学习使用的方法特别是降维领域。例如：目前一个工作就是稀疏编码，通过压缩感知理论对高维数据进行降维，使得非常少的元素的向量就可以精确的代表原来的高维信号。另一个例子就是半监督流行学习，通过测量训练样本的相似性，将高维数据的这种相似性投影到低维空间。另外一个比较鼓舞人心的方向就是evolutionary programming approaches（遗传编程方法），它可以通过最小化工程能量去进行概念性自适应学习和改变核心架构。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><strong><span style="color: #3f3f3f">Deep learning还有很多核心的问题需要解决：</span></strong></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #3f3f3f"><em>（1）对于一个特定的框架，对于多少维的输入它可以表现得较优（如果是图像，可能是上百万维）？</em></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #3f3f3f"><em>（2）对捕捉短时或者长时间的时间依赖，哪种架构才是有效的？</em></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #3f3f3f"><em>（3）如何对于一个给定的深度学习架构，融合多种感知的信息？</em></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #3f3f3f"><em>（4）有什么正确的机理可以去增强一个给定的深度学习架构，以改进其鲁棒性和对扭曲和数据丢失的不变性？</em></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><span style="color: #3f3f3f"><em>（5）模型方面是否有其他更为有效且有理论依据的深度模型学习算法？</em></span></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">探索新的特征提取模型是值得深入研究的内容。此外有效的可并行训练算法也是值得研究的一个方向。当前基于最小批处理的随机梯度优化算法很难在多计算机中进行并行训练。通常办法是利用图形处理单元加速学习过程。然而单个机器GPU对大规模数据识别或相似任务数据集并不适用。在深度学习应用拓展方面，如何合理充分利用深度学习在增强传统学习算法的性能仍是目前各领域的研究重点。</p>
]]>
</description>
</item><item>
<link>http://i.renjihe.com/blog/read.php?7434</link>
<title><![CDATA[视觉SLAM漫谈 (三): 研究点介绍]]></title> 
<author>renjihe1988 &lt;admin@yourname.com&gt;</author>
<category><![CDATA[AR&amp;AI&amp;模式识别]]></category>
<pubDate>Wed, 27 Jul 2016 12:43:47 +0000</pubDate> 
<guid>http://i.renjihe.com/blog/read.php?7434</guid> 
<description>
<![CDATA[ 
	<h1 style="margin: 10px 0px 5px; padding: 0px; line-height: 26px; font-size: 28px; font-family: verdana, sans-serif">1.　　前言</h1><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">　　读者朋友们大家好！（很久很久）之前，我们为大家介绍了SLAM的基本概念和方法。相信大家对SLAM，应该有了基本的认识。在忙完一堆写论文、博士开题的事情之后，我准备回来继续填坑：为大家介绍SLAM研究的方方面面。如果前两篇文章算是&quot;初识&quot;，接下来几篇就是&quot;渐入佳境&quot;了。在第三篇中，我们要谈谈SLAM中的各个研究点，为研究生们（应该是博客的多数读者吧）作一个提纲挈领的摘要。然后，我们再就各个小问题，讲讲经典的算法与分类。我有耐心讲，你是否有耐心听呢？</span></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">　　在《SLAM for Dummy》中，有一句话说的好：&quot;SLAM并不是一种算法，而是一个概念。（SLAM is more like a concept than a single algorithm.）&quot;所以，你可以和导师、师兄弟（以及师妹，如果有的话）说你在研究SLAM，但是，作为同行，我可能更关心：你在研究SLAM中的哪一个问题。有些研究者专注于实现一个具体的SLAM系统，而更多的人则是在研究SLAM里某些方法的改进。做应用和做理论的人往往彼此看不起，不过二者对科研都是有贡献的。作为研究生，我还是建议各位抓住SLAM中一个小问题，看看能否对现有的算法进行改进或者比较。不要觉得这种事情肤浅，它是对研究有实际帮助和意义的。同时，我也有一些朋友，做了一个基于滤波器/图优化的SLAM实现。程序是跑起来了，但他/她不知道自己有哪些贡献，钻研了哪个问题，写论文的时候就很头疼。所以，作为研究生，我建议你选择SLAM中的一个问题，改进其中的算法，而不是先找一堆程序跑起来再说。</span></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">　　那么问题来了：SLAM方面究竟有哪些可以研究的地方呢？我为大家上一个脑图。</span></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px; text-align: center"><img style="border: 0px; max-width: 100%; width: 764px" src="http://images.cnitblog.com/blog/606958/201501/120939313547280.jpg" border="0" /></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">　　这个图是从我笔记本上拍下来的（请勿吐槽字和对焦）。可以看到，以SLAM为中心，有五个圈连接到它。我称它为Basic Theory（基础理论）、Sensor（传感器）、Mapping（建图）、Loop Detection（回环检测）、Advanced Topic（高级问题）。这可以说是SLAM的研究方向。下面我们&quot;花开五朵，各表一枝&quot;。</span></p><h1 style="margin: 10px 0px 5px; padding: 0px; line-height: 26px; font-size: 28px; font-family: verdana, sans-serif"><a style="color: #ca0000" name="t1"></a>2.　　基本理论</h1><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">　　SLAM的基本理论，是指它的<span style="color: red">数学建模</span>。也就是你如何用数学模型来表达这个问题。为什么说它&quot;基本&quot;呢？因为数学模型影响着整个系统的性能，决定了其他问题的处理方法。在早先的研究中（86年提出<span style="color: #080000">[1]</span>至21世纪前期<span style="color: #080000">[2]</span>），是使用卡尔曼滤波器的数学模型的。那里的机器人，就是一个位姿的时间序列；而地图，就是一堆路标点的集合。什么是路标点的集合？就是用<span style="display: inline; line-height: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; padding: 0px; margin: 0px" class="MathJax"><span class="math"><span class="mrow"><span class="mo">(</span><span class="mi">x</span><span class="mo">,</span><span class="mi">y</span><span class="mo">,</span><span class="mi">z</span><span class="mo">)</span></span></span></span>表示每一个路标，然后在滤波器更新的过程中，让这三个数慢慢收敛。</span></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">　　那么，请问这样的模型好不好？</span></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">　　好处是可以直接套用滤波器的求解方法。卡尔曼滤波器是很成熟的理论，比较靠谱。</span></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">　　缺点呢？首先，滤波器有什么缺点，基于它的SLAM就有什么缺点。所以EKF的线性化假设啊，必须存储协方差矩阵带来的资源消耗啊，都成了缺点（之后的文章里会介绍）。然后呢，最直观的就是，用<span style="display: inline; line-height: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; padding: 0px; margin: 0px" class="MathJax"><span class="math"><span class="mrow"><span class="mo">(</span><span class="mi">x</span><span class="mo">,</span><span class="mi">y</span><span class="mo">,</span><span class="mi">z</span><span class="mo">)</span></span></span></span>表示路标？万一路标变了怎么办？平时我们不就把屋里的桌子椅子挪来挪去的吗？那时候滤波器就挂了。所以啊，它也不适用于动态的场合。</span></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">　　这种局限性就是数学模型本身带来的，和其他的算法无关。如果你希望在动态环境中跑SLAM，就要使用其他模型或改进现有的模型了。</span></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">　　SLAM的基本理论，向来分为<span style="color: red">滤波器和优化方法</span>两类。滤波器有扩展卡尔曼滤波（EKF）、粒子滤波（PF），FastSLAM等，较早出现。而优化方向用姿态图（Pose Graph），其思想在先前的文章中介绍过。近年来用优化的逐渐增多，而滤波器方面则在13年出现了基于Random Finite Set的方法<span style="color: #080000">[3]</span>，也是一个新兴的浪潮<span style="color: #080000">[4]</span>。关于这些方法的详细内容，我们在今后的文章中再进行讨论。</span></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">　　作为SLAM的研究人员，应该对各种基本理论以及优缺点有一个大致的了解，尽管它们的实现可能非常复杂。</span></p><h1 style="margin: 10px 0px 5px; padding: 0px; line-height: 26px; font-size: 28px; font-family: verdana, sans-serif"><a style="color: #ca0000" name="t2"></a>3.　　传感器</h1><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">　　传感器是机器人感知世界的方式。<span style="color: red">传感器的选择和安装方式，决定了观测方程的具体形式，也在很大程度上影响着SLAM问题的难度</span>。早期的SLAM多使用激光传感器（Laser Range Finder），而现在则多使用视觉相机、深度相机、声呐（水下）以及传感器融合。我觉得该方向可供研究点有如下几个：</span></p><ul style="margin-left: 45px; padding-left: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><li style="list-style: inherit !important"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">如何使用新兴传感器进行SLAM。&nbsp;&nbsp;&nbsp;&nbsp;要知道传感器在不断发展，总有新式的东西会出来，所以这方面研究肯定不会断。</span></li><li style="list-style: inherit !important"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">不同的安装方式对SLAM的影响。&nbsp;&nbsp;&nbsp;&nbsp;举例来说，比如相机，顶视（看天花板）和下视（看地板）的SLAM问题要比平视容易很多。为什么容易呢？因为顶/下视的数据非常稳定，不像平视，要受各种东西的干扰。当然，你也可以研究其他的安装方式。</span></li><li style="list-style: inherit !important"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">改进传统传感器的数据处理。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这部分就有些困难了，因为经常传感器已经有很多人在使用，你做的改进，未必比现有的成熟方法更好。</span></li></ul><h1 style="margin: 10px 0px 5px; padding: 0px; line-height: 26px; font-size: 28px; font-family: verdana, sans-serif"><a style="color: #ca0000" name="t3"></a>4.　　建图</h1><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">　　建图，顾名思议，就是如何画地图呗。其实，如果知道了机器人的真实轨迹，画地图是很简单的一件事。不过，地图的具体形式也是研究点之一。比如说常见的有以下几种：</span></p><ul style="margin-left: 45px; padding-left: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><li style="list-style: inherit !important"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">路标地图。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></li></ul><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">　　地图由一堆路标点组成。EKF中的地图就是这样的。但是，也有人说，这真的是地图吗（这些零零碎碎的点都是什么啊喂）？所以路标图尽管很方便，但多数人对这种地图是不满意的，至少看上去不像个地图啊。于是就有了密集型地图（Dense map）。</span></p><ul style="margin-left: 45px; padding-left: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><li style="list-style: inherit !important"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">度量地图（Metric map）&nbsp;&nbsp;&nbsp;&nbsp;</span></li></ul><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">　　通常指2D/3D的网格地图，也就是大家经常见的那种黑白的/点云式地图。点云地图比较酷炫，很有种高科技的感觉。它的优点是精度比较高，比如2D地图可以用0-1表示某个点是否可通过，对导航很有用。缺点是相当吃存储空间，特别是3D，把所有空间点都存起来了，然而大多数角角落落里的点除了好看之外都没什么意义&hellip;&hellip;</span></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px; text-align: center"><img style="border: 0px; max-width: 100%" src="http://images.cnitblog.com/blog/606958/201504/111157268521016.png" border="0" /><img style="border: 0px; max-width: 100%" src="http://images.cnitblog.com/blog/606958/201504/111157286181742.png" border="0" /></p><ul style="margin-left: 45px; padding-left: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><li style="list-style: inherit !important"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">拓扑地图（Topological map）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></li></ul><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">　　拓扑地图是比度量地图更紧凑的一种地图。它将地图抽象为图论中的&quot;点&quot;和&quot;边&quot;，使之更符合人类的思维。比如说我要去五道口，不知道路，去问别人。那人肯定不会说，你先往前走621米，向左拐94.2度，再走1035米&hellip;&hellip;（这是疯子吧）。正常人肯定会说，往前走到第二个十字路口，左拐，走到下一个红绿灯，等等。这就是拓扑地图。</span></p><ul style="margin-left: 45px; padding-left: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><li style="list-style: inherit !important"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">混合地图。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></li></ul><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">　　既然有人要分类，就肯定有人想把各类的好处揉到一起。这个就不多说了吧。</span></p><h1 style="margin: 10px 0px 5px; padding: 0px; line-height: 26px; font-size: 28px; font-family: verdana, sans-serif"><a style="color: #ca0000" name="t4"></a>5.　　回环检测</h1><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 宋体"><span style="font-family: 'Microsoft YaHei'">　　回环检测，又称闭环检测（Loop closure detection），是指机器人识别曾到达场景的能力。如果检测成功，可以显著地减小累积误差。</span></span></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px; text-align: center"><img style="border: 0px; max-width: 100%" src="http://images.cnitblog.com/blog/606958/201504/111157297438298.png" border="0" /></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">　　回环检测目前多采用词袋模型（Bag-of-Word），研究计算机视觉的同学肯定不会陌生。它实质上是一个检测观测数据相似性的问题。在词袋模型中，我们提取每张图像中的特征，把它们的特征向量（descriptor）进行聚类，建立类别数据库。比如说，眼睛、鼻子、耳朵、嘴等等（实际当中没那么高级，基本上是一些边缘和角）。假设有10000个类吧。然后，对于每一个图像，可以分析它含有数据库中哪几个类。以1表示有，以0表示没有。那么，这个图像就可用10000维的一个向量来表达。而不同的图像，只要比较它们的向量即可。</span></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 宋体"><span style="font-family: 'Microsoft YaHei'">　　回环检测也可以建成一个模型识别问题，所以你也可以使用各种<a style="color: #df3434; text-decoration: none; font-weight: bold" href="http://lib.csdn.net/base/2" target="_blank" title="undefined" class="replace_word">机器学习</a>的方法来做，比如什么决策树/SVM，也可以试试Deep Learning。不过实际当中要求实时检测，没有那么多时间让你训练分类器。所以SLAM更侧重在线的学习方法。</span></span></p><h1 style="margin: 10px 0px 5px; padding: 0px; line-height: 26px; font-size: 28px; font-family: verdana, sans-serif"><a style="color: #ca0000" name="t5"></a>6.　　高级话题</h1><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">　　前面的都是基础的SLAM，只有&quot;定位&quot;和&quot;建图&quot;两件事。这两件事在今天已经做的比较完善了。近几年的RGB-D SLAM<span style="color: #080000">[5]</span>, SVO<span style="color: #080000">[6]</span>, Kinect Fusion<span style="color: #080000">[7]</span>等等，都已经做出了十分炫的效果。但是SLAM还未走进人们的实际生活。为什么呢？</span></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 宋体"><span style="font-family: 'Microsoft YaHei'">　　因为实际环境往往非常复杂。灯光会变，太阳东升西落，不断的有人从门里面进进出出，并不是一间安安静静的空屋子，让一个机器人以2cm/s的速度慢慢逛。论文中看起来酷炫的算法，在实际环境中往往捉襟见肘，处处碰壁。向实际环境挑战，是SLAM技术的主要发展方向，也就是我们所说的高级话题。主要有：动态场景、语义地图、多机器人协作等等。</span></span></p><h1 style="margin: 10px 0px 5px; padding: 0px; line-height: 26px; font-size: 28px; font-family: verdana, sans-serif"><a style="color: #ca0000" name="t6"></a><span style="font-family: 宋体">7.　　小结</span></h1><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">　　本文向大家介绍了SLAM中的各个研究点。我并不想把它写成综述，因为不一定有人愿意看一堆的参考文献，我更想把它写成小故事的形式。</span></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">　　最后，让我们想象一下未来SLAM的样子吧：</span></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><span style="font-size: 15px; font-family: 'Microsoft YaHei'">　　有一天，小萝卜被领进了一家新的实验楼。在短暂的自我介绍之后，他飞快地在楼里逛了一圈，记住了哪里是走廊，哪儿是房间。他刻意地观察各个房间特有的物品，以便区分这些看起来很相似的房间。然后，他回到了科学家身边，协助他的研究。有时，科学家会让他去各个屋里找人，找资料，有时，也带着他去认识新安装的仪器和设备。在闲着没事时，小萝卜也会在楼里逛逛，看看那些屋里都有什么变化。每当新的参观人员到来，小萝卜会给他们看楼里的平面图，向他们介绍各个楼层的方位与状况，为他们导航。大家都很喜欢小萝卜。而小萝卜明白，这一切，都是过去几十年里SLAM研究人员不断探索的结果。</span></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px; text-align: center"><img style="border: 0px; max-width: 100%" src="http://images.cnitblog.com/blog/606958/201504/111157306496856.jpg" border="0" /></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px; text-align: center"><span style="font-family: 'Times New Roman'"><span style="font-size: 20pt"><strong>References:</strong></span></span></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px; text-align: justify"><span style="font-family: 'Times New Roman'"><span style="font-size: 10pt">[1].&nbsp;&nbsp;&nbsp;&nbsp;Smith, R.C. and P. Cheeseman, On the Representation and Estimation of Spatial Uncertainty. International Journal of Robotics Research, 1986. 5(4): p. 56--68.</span></span></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px; text-align: justify"><span style="font-family: 'Times New Roman'"><span style="font-size: 10pt">[2].&nbsp;&nbsp;&nbsp;&nbsp;Se, S., D. Lowe and J. Little, Mobile robot localization and mapping with uncertainty using scale-invariant visual landmarks. The international Journal of robotics Research, 2002. 21(8): p. 735--758.</span></span></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px; text-align: justify"><span style="font-family: 'Times New Roman'"><span style="font-size: 10pt">[3].&nbsp;&nbsp;&nbsp;&nbsp;Mullane, J., et al., A Random-Finite-Set Approach to Bayesian SLAM. IEEE Transactions on Robotics, 2011.</span></span></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px; text-align: justify"><span style="font-family: 'Times New Roman'"><span style="font-size: 10pt">[4].&nbsp;&nbsp;&nbsp;&nbsp;Adams, M., et al., SLAM Gets a PHD: New Concepts in Map Estimation. IEEE Robotics Automation Magazine, 2014. 21(2): p. 26--37.</span></span></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px; text-align: justify"><span style="font-family: 'Times New Roman'"><span style="font-size: 10pt">[5].&nbsp;&nbsp;&nbsp;&nbsp;Endres, F., et al., 3-D Mapping With an RGB-D Camera. IEEE Transactions on Robotics, 2014. 30(1): p. 177--187.</span></span></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px; text-align: justify"><span style="font-family: 'Times New Roman'"><span style="font-size: 10pt">[6].&nbsp;&nbsp;&nbsp;&nbsp;Forster, C., M. Pizzoli and D. Scaramuzza, SVO: Fast semi-direct monocular visual odometry. 2014, IEEE. p. 15--22.</span></span></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px; text-align: justify"><span style="font-family: 'Times New Roman'"><span style="font-size: 10pt">[7].&nbsp;&nbsp;&nbsp;&nbsp;Newcombe, R.A., et al., KinectFusion: Real-time dense surface mapping and tracking. 2011, IEEE. p. 127--136.</span></span></p>
]]>
</description>
</item><item>
<link>http://i.renjihe.com/blog/read.php?7433</link>
<title><![CDATA[视觉SLAM漫谈（二）:图优化理论与g2o的使用]]></title> 
<author>renjihe1988 &lt;admin@yourname.com&gt;</author>
<category><![CDATA[AR&amp;AI&amp;模式识别]]></category>
<pubDate>Wed, 27 Jul 2016 12:43:27 +0000</pubDate> 
<guid>http://i.renjihe.com/blog/read.php?7433</guid> 
<description>
<![CDATA[ 
	<h1 style="margin: 10px 0px 5px; padding: 0px; line-height: 26px; font-size: 28px; font-family: verdana, sans-serif; text-align: center">视觉SLAM漫谈（二）:图优化理论与g2o的使用</h1><h2 style="margin: 10px 0px 3px; padding: 0px; line-height: 26px; font-size: 21px; font-family: verdana, sans-serif"><a style="color: #ca0000" name="t1"></a><span style="font-family: 楷体">1&nbsp;&nbsp;&nbsp; 前言以及回顾</span></h2><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　各位朋友，自从上一篇《视觉SLAM漫谈》写成以来已经有一段时间了。我收到几位热心读者的邮件。有的希望我介绍一下当前视觉SLAM程序的实用程度，更多的人希望了解一下前文提到的g2o优化库。因此我另写一篇小文章来专门介绍这个新玩意。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　在开始本篇文章正文以前，我们先来回顾一下图优化SLAM问题的提法。至于SLAM更基础的内容，例如SLAM是什么东西等等，请参见上一篇文章。我们直接进入较深层次的讨论。首先，关于我们要做的事情，你可以这样想：</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　l&nbsp; &nbsp;已知的东西：传感器数据（图像，点云，惯性测量设备等）。我们的传感器主要是一个Kinect，因此数据就是一个视频序列，说的再详细点就是一个RGB位图序列与一个深度图序列。至于惯性测量设备，可以有也可以没有。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　l&nbsp;&nbsp; 待求的东西：机器人的运动轨迹，地图的描述。运动轨迹，画出来应该就像是一条路径。而地图的描述，通常是点云的描述。但是点云描述是否可用于导航、规划等后续问题，还有待研究。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　这两个点之间还是有挺长的路要走的。如果我们使用图优化，往往会在整个视频序列中，定义若干个关键帧：</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><img style="border: 0px; max-width: 100%; display: block; margin-left: auto; margin-right: auto" src="http://images.cnitblog.com/i/606958/201406/081236469895899.jpg" border="0" width="347" height="277" /></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　这个图着实画的有点丑，请大家不要吐槽&hellip;&hellip;不管怎么说，它表达出我想表达的意思。在这张图中，我们有一个路标点（五角星），并在各个关键帧中都看到了这个点。于是，我们就能用PnP或ICP求解相邻关键点的运动方向。这些在上篇文章都介绍过了，包括特征选择，匹配及计算等等。那么，这个过程中有什么问题呢？</p><h2 style="margin: 10px 0px 3px; padding: 0px; line-height: 26px; font-size: 21px; font-family: verdana, sans-serif"><a style="color: #ca0000" name="t2"></a><span style="font-family: 楷体">2&nbsp;&nbsp;&nbsp; 为什么要用全局优化</span></h2><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　你一定已经注意到，理想的计算总和实际有差距的。好比说理想的科研就是&ldquo;看论文&mdash;&mdash;产生想法&mdash;&mdash;做实验&mdash;&mdash;发文章&rdquo;，那么现实的科研就是&ldquo;看论文&mdash;&mdash;产生想法&mdash;&mdash;做实验&mdash;&mdash;发现该想法在二十年前就有人做过了&rdquo;，这样一个过程。实际当中，仅通过帧间运动（ego-motion）来计算机器人轨迹是远远不够的。如下图所示：</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　<img style="border: 0px; max-width: 100%; display: block; margin-left: auto; margin-right: auto" src="http://images.cnitblog.com/i/606958/201406/081239410836912.jpg" border="0" width="405" height="324" /></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　如果你只用帧间匹配，那么每一帧的误差将对后面所有的运动轨迹都要产生影响。例如第二帧往右偏了0.1，那么后面第三、四、五帧都要往右偏0.1，还要加上它们自己的估算误差。所以结果就是：当程序跑上十几秒之后早就不知道飞到哪儿去了。这是经典的SLAM现象，在EKF实现中，也会发现，当机器人不断运动时，不确定性会不断增长。当然不是我们所希望的结果。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　那么怎么办才好呢？想象你到了一个陌生的城市，安全地走出了火车站，并在附近游荡了一会儿。当你走的越远，看到许多未知的建筑。你就越搞不清楚自己在什么地方。如果是你，你会怎么办？</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　通常的做法是认准一个标志性建筑物，在它周围转上几圈，弄清楚附近的环境。然后再一点点儿扩大我们走过的范围。在这个过程中，我们会时常回到之前已经见过的场景，因此对它周围的景象就会很熟悉。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　机器人的情形也差不多，除了大多数时候是人在遥控它行走。因而我们希望，机器人不要仅和它上一个帧进行比较，而是和更多先前的帧比较，找出其中的相似之处。这就是所谓的回环检测（Loop closure detection）。用下面的示意图来说明：</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><img style="border: 0px; max-width: 100%; display: block; margin-left: auto; margin-right: auto" src="http://images.cnitblog.com/i/606958/201406/081240335523415.jpg" border="0" width="571" height="457" /></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　没有回环时，由于误差对后续帧产生影响，机器人路径估计很不稳定。加上一些局部回环，几个相邻帧就多了一些约束，因而误差就减少了。你可以把它看成一个由弹簧连起来的链条（质点-弹簧模型）。当机器人经过若干时间，回到最初地方时，检测出了大回环时，整个环内的结构都会变得稳定很多。我们就可以籍此知道一个房间是方的还是圆的，面前这堵墙对应着以前哪一堵墙，等等。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　相信讲到这里，大家对回环检测都有了一个感性的认识。那么，这件事情具体是怎么建模，怎么计算，怎么编程呢？下面我们就一步步来介绍。</p><h2 style="margin: 10px 0px 3px; padding: 0px; line-height: 26px; font-size: 21px; font-family: verdana, sans-serif"><a style="color: #ca0000" name="t3"></a><span style="font-family: 楷体">3&nbsp;&nbsp;&nbsp; 图优化的数学模型</span></h2><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　SLAM问题的优化模型可以有几种不同的建模方式。我们挑选其中较简单的一种进行介绍，即FrameSLAM，在2008年提出。它的特点是只用位姿约束而不用特征约束，减少了很多计算量，表达起来也比较直观。下面我们给出一种6自由度的3D SLAM建模方法。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　符号：</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><img style="border: 0px; max-width: 100%; display: block; margin-left: auto; margin-right: auto" src="http://images.cnitblog.com/i/606958/201406/081242094278158.jpg" border="0" /></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><img style="border: 0px; max-width: 100%; display: block; margin-left: auto; margin-right: auto" src="http://images.cnitblog.com/i/606958/201406/081242458021146.jpg" border="0" /></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　注意到这里的建模与前文有所不同，是一个简化版的模型。因为我们假设帧间匹配时得到了相邻帧的变换矩阵，而不是把所有特征也放到优化问题里面来。所以这个模型看上去相对简单。但是它很实用，因为不用引入特征，所以结点和边的数量大大减少，要知道在图像里提特征动辄成百上千的。</p><h2 style="margin: 10px 0px 3px; padding: 0px; line-height: 26px; font-size: 21px; font-family: verdana, sans-serif"><a style="color: #ca0000" name="t4"></a><span style="font-family: 楷体">4 &nbsp; &nbsp;g2o是什么</span></h2><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　g2o，就是对上述问题的一个求解器。它原理上是一个通用的求解器，并不限定于某些SLAM问题。你可以用它来求SLAM，也可以用ICP, PnP以及其他你能想到的可以用图来表达的优化问题。它的代码很规范，就是有一个缺点：文档太少。唯一的说明文档还有点太装叉（个人感觉）了，有点摆弄作者数学水平的意思，反正那篇文档很难懂就是了。话说程序文档不应该是告诉我怎么用才对么&hellip;&hellip;</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　言归正传。如果你想用g2o，请去它的github上面下载：<a style="color: #444444; text-decoration: none; outline: none" href="https://github.com/RainerKuemmerle/g2o" target="_blank">https://github.com/RainerKuemmerle/g2o</a></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　它的API在：<a style="color: #444444; text-decoration: none; outline: none" href="http://www.rock-robotics.org/stable/api/slam/g2o/classg2o_1_1HyperGraph.html" target="_blank">http://www.rock-robotics.org/stable/api/slam/g2o/classg2o_1_1HyperGraph.html</a></p><h3 style="margin: 0px; padding: 0px; line-height: 26px; font-size: 16px; font-family: verdana, sans-serif"><a style="color: #ca0000" name="t5"></a>4.1&nbsp;&nbsp;&nbsp; &nbsp;安装</h3><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　g2o是一个用cmake管理的C++工程，我是用Linux编译的，所以不要问我怎么在win下面用g2o，因为我也不会&hellip;&hellip;不管怎么说，你下载了它的zip包或者用git拷下来之后，里面有一个README文件。告诉你它的依赖项。在ubuntu下，直接键入命令：</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　sudo apt-get install cmake libeigen3-dev libsuitesparse-dev libqt4-dev qt4-qmake libqglviewer-qt4-dev</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　我个人感觉还要 libcsparse-dev和freeglut3这两个库，反正多装了也无所谓。注意libqglviewer-qt4-dev只在ubuntu 12.04库里有，14.04 里换成另一个库了。g2o的可视化工具g2o_viewer是依赖这个库的，所以，如果你在14.04下面编，要么是去把12.04那个deb（以及它的依赖项）找出来装好，要么用ccmake，把build apps一项给去掉，这样就不编译这个工具了。否则编译过不去。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　解开zip后，新建一个build文件夹，然后就是：</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　cmake ..</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　make</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　sudo make install</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　这样g2o就装到了你的/usr/local/lib和/usr/local/include下面。你可以到这两个地方去看它的库文件与头文件。</p><h3 style="margin: 0px; padding: 0px; line-height: 26px; font-size: 16px; font-family: verdana, sans-serif"><a style="color: #ca0000" name="t6"></a>4.2&nbsp;&nbsp;&nbsp; &nbsp;学习g2o的使用</h3><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　因为g2o的文档真的很装叉（不能忍），所以建议你直接看它的源代码，耐心看，应该比文档好懂些。它的example文档夹下有一些示例代码，其中有一个tutorial_slam2d文件夹下有2d slam仿真的一个程序。值得仔细阅读。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　使用g2o来实现图优化还是比较容易的。它帮你把节点和边的类型都定义好了，基本上只需使用它内置的类型而不需自己重新定义。要构造一个图，要做以下几件事：</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　l&nbsp;&nbsp; 定义一个SparseOptimizer. 编写方式参见tutorial_slam2d的声明方式。你还要写明它使用的算法。通常是Gauss-Newton或LM算法。个人觉得后者更好一些。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　l&nbsp;&nbsp; 定义你要用到的边、节点的类型。例如我们实现一个3D SLAM。那么就要看它的g2o/types/slam3d下面的头文件。节点头文件都以vertex_开头，而边则以edge_开头。在我们上面的模型中，可以选择vertex_se3作为节点，edge_se3作为边。这两个类型的节点和边的数据都可以直接来自于Eigen::Isometry，即上面讲到过的变换矩阵T。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　l&nbsp;&nbsp; 编写一个帧间匹配程序，通过两张图像算出变换矩阵。这个用opencv, pcl都可以做。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　l&nbsp;&nbsp; 把你得到的关键帧作为节点，变换矩阵作为边，加入到optimizer中。同时设定节点的估计值（如果没有惯性测量就设成零）与边的约束（变换矩阵）。此外，每条边还需设定一个信息矩阵（协方差矩阵之逆）作为不确定性的度量。例如你觉得帧间匹配精度在0.1m，那么把信息矩阵设成100的对角阵即可。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　l&nbsp;&nbsp; 在程序运行过程中不断作帧间检测，维护你的图。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　l&nbsp;&nbsp; 程序结束时调用optimizer.optimize( steps )进行优化。优化完毕后读取每个节点的估计值，此时就是优化后的机器人轨迹。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　代码这种东西展开来说会变得像字典一样枯燥，所以具体的东西需要大家自己去看，自己去体会。这里有我自己写的一个程序，可以供大家参考。不过这个程序需要带着数据集才能跑，学习g2o的同学只需参考里面代码的写法即可：<a style="color: #444444; text-decoration: none; outline: none" href="https://github.com/gaoxiang12/slam3d_gx" target="_blank">https://github.com/gaoxiang12/slam3d_gx</a></p><h2 style="margin: 10px 0px 3px; padding: 0px; line-height: 26px; font-size: 21px; font-family: verdana, sans-serif"><a style="color: #ca0000" name="t7"></a><span style="font-family: 楷体">5 &nbsp; &nbsp;效果</span></h2><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　最近我跑了几个公开数据集（<a style="color: #444444; text-decoration: none; outline: none" href="http://vision.in.tum.de/data/datasets/rgbd-dataset" target="_blank">http://vision.in.tum.de/data/datasets/rgbd-dataset</a>）上的例子（fr1_desk, fr2_slam)(，感觉效果还不错。有些数据集还是挺难的。最后一张图是g2o_viewer，可以看到那些关键路径点与边的样子。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><img style="border: 0px; max-width: 100%; display: block; margin-left: auto; margin-right: auto" src="http://images.cnitblog.com/i/606958/201406/081245195361647.png" border="0" width="814" height="448" /></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px; text-align: center"><img style="border: 0px; max-width: 100%" src="http://images.cnitblog.com/i/606958/201406/081245355834877.png" border="0" /></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px; text-align: center"><img style="border: 0px; max-width: 100%" src="http://images.cnitblog.com/i/606958/201406/081245480055281.png" border="0" /></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px; text-align: center">&nbsp;</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　以上，如有什么问题，欢迎与我交流：gaoxiang12@mails.tsinghua.edu.cn</p>
]]>
</description>
</item><item>
<link>http://i.renjihe.com/blog/read.php?7432</link>
<title><![CDATA[视觉SLAM漫谈]]></title> 
<author>renjihe1988 &lt;admin@yourname.com&gt;</author>
<category><![CDATA[AR&amp;AI&amp;模式识别]]></category>
<pubDate>Wed, 27 Jul 2016 12:42:57 +0000</pubDate> 
<guid>http://i.renjihe.com/blog/read.php?7432</guid> 
<description>
<![CDATA[ 
	<h1 style="margin: 10px 0px 5px; padding: 0px; text-align: center"><span style="font-family: verdana, sans-serif"><span style="font-size: 18.6667px; line-height: 26px">http://blog.csdn.net/lcj_cjfykx/article/details/46407875<br /></span></span><span style="font-size: 14pt; line-height: 26px; font-family: verdana, sans-serif">视觉SLAM漫谈</span></h1><h2 style="margin: 10px 0px 3px; padding: 0px; line-height: 26px; font-size: 21px; font-family: verdana, sans-serif"><a style="color: #ca0000" name="t1"></a>1.&nbsp;&nbsp;&nbsp;&nbsp;前言</h2><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　开始做SLAM（机器人同时定位与建图）研究已经近一年了。从一年级开始对这个方向产生兴趣，到现在为止，也算是对这个领域有了大致的了解。然而越了解，越觉得这个方向难度很大。总体来讲有以下几个原因：</p><ul style="margin-left: 45px; padding-left: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px"><li class="ListParagraph" style="list-style: inherit !important">入门资料很少。虽然国内也有不少人在做，但这方面现在没有太好的入门教程。《SLAM for dummies》可以算是一篇。中文资料几乎没有。</li><li class="ListParagraph" style="list-style: inherit !important"><span style="line-height: 1.5">SLAM研究已进行了三十多年，从上世纪的九十年代开始。其中又有若干历史分枝和争论，要把握它的走向就很费工夫。</span></li><li class="ListParagraph" style="list-style: inherit !important"><span style="line-height: 1.5">难以实现。SLAM是一个完整的系统，由许多个分支模块组成。现在经典的方案是&ldquo;图像前端，优化后端，闭环检测&rdquo;的三部曲，很多文献看完了自己实现不出来。</span></li><li class="ListParagraph" style="list-style: inherit !important"><span style="line-height: 1.5">自己动手编程需要学习大量的先决知识。首先你要会C和C++，网上很多代码还用了11标准的C++。第二要会用Linux。第三要会cmake，vim/emacs及一些编程工具。第四要会用openCV, PCL, Eigen等第三方库。只有学会了这些东西之后，你才能真正上手编一个SLAM系统。如果你要跑实际机器人，还要会ROS。</span></li></ul><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　当然，困难多意味着收获也多，坎坷的道路才能锻炼人（比如说走着走着才发现Linux和C++才是我的真爱之类的。）鉴于目前网上关于视觉SLAM的资料极少，我于是想把自己这一年多的经验与大家分享一下。说的不对的地方请大家批评指正。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　这篇文章关注视觉SLAM，专指用摄像机，Kinect等深度像机来做导航和探索，且主要关心室内部分。到目前为止，室内的视觉SLAM仍处于研究阶段，远未到实际应用的程度。一方面，编写和使用视觉SLAM需要大量的专业知识，算法的实时性未达到实用要求；另一方面，视觉SLAM生成的地图（多数是点云）还不能用来做机器人的路径规划，需要科研人员进一步的探索和研究。以下，我会介绍SLAM的<strong>历史、理论以及实现的方式，且主要介绍视觉（Kinect）的实现方式。</strong></p><h2 style="margin: 10px 0px 3px; padding: 0px; line-height: 26px; font-size: 21px; font-family: verdana, sans-serif"><a style="color: #ca0000" name="t2"></a>2.&nbsp;&nbsp;&nbsp;&nbsp;SLAM问题</h2><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　SLAM，全称叫做Simultaneous Localization and Mapping，中文叫做同时定位与建图。啊不行，这么讲下去，这篇文章肯定没有人读，所以我们换一个讲法。</p><h2 style="margin: 10px 0px 3px; padding: 0px; line-height: 26px; font-size: 21px; font-family: verdana, sans-serif"><a style="color: #ca0000" name="t3"></a>3.&nbsp;&nbsp;&nbsp;&nbsp;小萝卜的故事</h2><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　从前，有一个机器人叫&ldquo;小萝卜&rdquo;。它长着一双乌黑发亮的大眼睛，叫做Kinect。有一天，它被邪恶的科学家关进了一间空屋子，里面放满了杂七杂八的东西。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px" align="center"><img style="border: 0px; max-width: 100%" src="http://images.cnitblog.com/i/606958/201404/281100466891028.jpg" border="0" width="541" height="338" />&nbsp;</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　小萝卜感到很害怕，因为这个地方他从来没来过，一点儿也不了解。让他感到害怕的主要是三个问题：</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　1.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;自己在哪里？</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　2.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这是什么地方？</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　3.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;怎么离开这个地方？</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　在SLAM理论中，第一个问题称为定位&nbsp;(Localization)，第二个称为建图&nbsp;(Mapping)，第三个则是随后的路径规划。我们希望借助Kinect工具，帮小萝卜解决这个难题。各位同学有什么思路呢？</p><h2 style="margin: 10px 0px 3px; padding: 0px; line-height: 26px; font-size: 21px; font-family: verdana, sans-serif"><a style="color: #ca0000" name="t4"></a>4.&nbsp;&nbsp;&nbsp;&nbsp;Kinect数据</h2><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　要打败敌人，首先要了解你的武器。不错，我们先介绍一下Kinect。众所周知这是一款深度相机，你或许还听说过别的牌子，但Kinect的价格便宜，测量范围在3m-12m之间，精度约3cm，较适合于小萝卜这样的室内机器人。它采到的图像是这个样子的（从左往右依次为rgb图，深度图与点云图）：</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px" align="center"><img style="border: 0px; max-width: 100%" src="http://images.cnitblog.com/i/606958/201404/281101374082023.jpg" border="0" />&nbsp;</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　Kinect的一大优势在于能比较廉价地获得每个像素的深度值，不管是从时间上还是从经济上来说。OK，有了这些信息，小萝卜事实上可以知道它采集到的图片中，每一个点的3d位置。只要我们事先标定了Kinect，或者采用出厂的标定值。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　我们把坐标系设成这个样子，这也是openCV中采用的默认坐标系。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px" align="center"><img style="border: 0px; max-width: 100%" src="http://images.cnitblog.com/i/606958/201404/281101523452119.png" border="0" width="317" height="302" />&nbsp;</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　o&rsquo;-uv是图片坐标系，o-xyz是Kinect的坐标系。假设图片中的点为(u,v)，对应的三维点位置在(x,y,z)，那么它们之间的转换关系是这样的：</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px" align="center">&nbsp;<img style="border: 0px; max-width: 100%" src="http://images.cnitblog.com/i/606958/201404/281102277677973.png" border="0" /></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　或者更简单的：</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px" align="center"><img style="border: 0px; max-width: 100%" src="http://images.cnitblog.com/i/606958/201404/281102357209336.png" border="0" />&nbsp;</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　后一个公式给出了计算三维点的方法。先从深度图中读取深度数据（Kinect给的是16位无符号整数），除掉z方向的缩放因子，这样你就把一个整数变到了以米为单位的数据。然后，x,y用上面的公式算出。一点都不难，就是一个中心点位置和一个焦距而已。f代表焦距，c代表中心。如果你没有自己标定你的Kinect，也可以采用默认的值：s=5000, cx = 320, cy=240, fx=fy=525。实际值会有一点偏差，但不会太大。</p><h2 style="margin: 10px 0px 3px; padding: 0px; line-height: 26px; font-size: 21px; font-family: verdana, sans-serif"><a style="color: #ca0000" name="t5"></a>5.&nbsp;&nbsp;&nbsp;&nbsp;定位问题</h2><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　知道了Kinect中每个点的位置后，接下来我们要做的，就是根据两帧图像间的差别计算小萝卜的位移。比如下面两张图，后一张是在前一张之后1秒采集到的：</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px" align="center">&nbsp;&nbsp;&nbsp;<img style="border: 0px; max-width: 100%" src="http://images.cnitblog.com/i/606958/201404/281102542054751.jpg" border="0" /></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　你肯定可以看出，小萝卜往右转过了一定的角度。但究竟转过多少度呢？这就要靠计算机来求解了。这个问题称为相机相对姿态估计，经典的算法是ICP（Iterative Closest Point，迭代最近点）。这个算法要求知道这两个图像间的一组匹配点，说的通俗点，就是左边图像哪些点和右边是一样的。你当然看见那块黑白相间的板子同时出现在两张图像中。在小萝卜看来，这里牵涉到两个简单的问题：特征点的提取和匹配。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　如果你熟悉计算机视觉，那你应该听说过SIFT, SURF之类的特征。不错，要解决定位问题，首先要得到两张图像的一个匹配。匹配的基础是图像的特征，下图就是SIFT提取的关键点与匹配结果：</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px" align="center"><img style="border: 0px; max-width: 100%" src="http://images.cnitblog.com/i/606958/201404/281104007981229.png" border="0" width="489" height="384" />&nbsp;&nbsp;</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px" align="center"><img style="border: 0px; max-width: 100%; width: 1149px" src="http://images.cnitblog.com/i/606958/201404/281104219556359.png" border="0" /></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　对实现代码感兴趣的同学请Google&ldquo;opencv&nbsp;匹配&rdquo;即可，在openCV的教程上也有很明白的例子。上面的例子可以看出，我们找到了一些匹配，但其中有些是对的（基本平等的匹配线），有些是错的。这是由于图像中存在周期性出现的纹理（黑白块），所以容易搞错。但这并不是问题，在接下来的处理中我们会将这些影响消去。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　得到了一组匹配点后，我们就可以计算两个图像间的转换关系，也叫PnP问题。它的模型是这样的：</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px" align="center"><img style="border: 0px; max-width: 100%" src="http://images.cnitblog.com/i/606958/201404/281104432672303.png" border="0" />&nbsp;</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　R为相机的姿态，C为相机的标定矩阵。R是不断运动的，而C则是随着相机做死的。ICP的模型稍有不同，但原理上也是计算相机的姿态矩阵。原则上，只要有四组匹配点，就可以算这个矩阵。你可以调用openCV的SolvePnPRANSAC函数或者PCL的ICP算法来求解。openCV提供的算法是RANSAC（Random Sample Consensus，随机采样一致性）架构，可以剔除错误匹配。所以代码实际运行时，可以很好地找到匹配点。以下是一个结果的示例。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px" align="center"><img style="border: 0px; max-width: 100%; width: 1149px" src="http://images.cnitblog.com/i/606958/201404/281105007677315.png" border="0" />&nbsp;</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　上面两张图转过了16.63度，位移几乎没有。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　有同学会说，那只要不断匹配下去，定位问题不就解决了吗？表面上看来，的确是这样的，只要我们引入一个关键帧的结构（发现位移超过一个固定值时，定义成一个关键帧）。然后，把新的图像与关键帧比较就行了。至于建图，就是把这些关键帧的点云拼起来，看着还有模有样，煞有介事的：</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px" align="center"><img style="border: 0px; max-width: 100%" src="http://images.cnitblog.com/i/606958/201404/281105230804133.png" border="0" width="1148" height="723" />&nbsp;</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px" align="center">1－200帧的匹配结果</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　然而，如果事情真这么简单，SLAM理论就不用那么多人研究三十多年了（它是从上世纪90年代开始研究的）（上面讲的那些东西简直随便哪里找个小硕士就能做出来&hellip;&hellip;）。那么，问题难在什么地方呢？</p><h2 style="margin: 10px 0px 3px; padding: 0px; line-height: 26px; font-size: 21px; font-family: verdana, sans-serif"><a style="color: #ca0000" name="t6"></a>6.&nbsp;&nbsp;&nbsp;&nbsp;SLAM端优化理论</h2><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　最麻烦的问题，就是&ldquo;噪声&rdquo;。这种渐近式的匹配方式，和那些惯性测量设备一样，存在着累积噪声。因为我们在不断地更新关键帧，把新图像与最近的关键帧比较，从而获得机器人的位移信息。但是你要想到，如果有一个关键帧出现了偏移，那么剩下的位移估计都会多出一个误差。这个误差还会累积，因为后面的估计都基于前面的机器人位置&hellip;&hellip;哇！这后果简直不堪设想啊（例如，你的机器人往右转了30度，再往左转了30度回到原来的位置。然而由于误差，你算成了向右转29度，再向左转31度，这样你构建的地图中，会出现初始位置的两个&ldquo;重影&rdquo;）。我们能不能想办法消除这个该死的误差呢？</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　朋友们，这才是SLAM的研究，前面的可以说是&ldquo;图像前端&rdquo;的处理方法。我们的解决思路是：如果你和最近的关键帧相比，会导致累计误差。那么，我们最好是和更前面的关键帧相比，而且多比较几个帧，不要只比较一次。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　我们用数学来描述这个问题。设：</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px" align="center"><img style="border: 0px; max-width: 100%" src="http://images.cnitblog.com/i/606958/201404/281107284396698.png" border="0" />&nbsp;</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　不要怕，只有借助数学才能把这个问题讲清楚。上面的公式中，xp是机器人小萝卜的位置，我们假定由n个帧组成。xL则是路标，在我们的图像处理过程中就是指SIFT提出来的关键点。如果你做2D SLAM，那么机器人位置就是x, y加一个转角theta。如果是3D SLAM，就是x,y,z加一个四元数姿态（或者rpy姿态）。这个过程叫做参数化（Parameterization）。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　不管你用哪种参数，后面两个方程你都需要知道。前一个叫运动方程，描述机器人怎样运动。u是机器人的输入，w是噪声。这个方程最简单的形式，就是你能通过什么方式（码盘等）获得两帧间的位移差，那么这个方程就直接是上一帧与u相加即得。另外，你也可以完全不用惯性测量设备，这样我们就只依靠图像设备来估计，这也是可以的。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　后一个方程叫观测方程，描述那些路标是怎么来的。你在第i帧看到了第j个路标，产生了一个测量值，就是图像中的横纵坐标。最后一项是噪声。偷偷告诉你，这个方程形式上和上一页的那个方程是一模一样的。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　在求解SLAM问题前，我们要看到，我们拥有的数据是什么？在上面的模型里，我们知道的是运动信息u以及观测z。用示意图表示出来是这样的：</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px" align="center"><img style="border: 0px; max-width: 100%" src="http://images.cnitblog.com/i/606958/201404/281107477838540.jpg" border="0" />&nbsp;</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　我们要求解的，就是根据这些u和z，确定所有的xp和xL。这就是SLAM问题的理论。从SLAM诞生开始科学家们就一直在解决这个问题。最初，我们用Kalman滤波器，所以上面的模型（运动方程和观测方程）被建成这个样子。直到21世纪初，卡尔曼滤波器仍在SLAM系统占据最主要的地位，Davison经典的单目SLAM就是用EKF做的。但是后来，出现了基于图优化的SLAM方法，渐渐有取而代之的地位[1]。我们在这里不介绍卡尔曼滤波器，有兴趣的同学可以在wiki上找卡尔曼滤波器，另有一篇中文的《卡尔曼滤波器介绍》也很棒。由于滤波器方法存储n个路标要消耗n平方的空间，在计算量上有点对不住大家。尽管08年有人提出分治法的滤波器能把复杂度弄到O(n) [2]，但实现手段比较复杂。我们要介绍那种新兴的方法: Graph-based SLAM。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　图优化方法把SLAM问题做成了一个优化问题。学过运筹学的同学应该明白，优化问题对我们有多么重要。我们不是要求解机器人的位置和路标位置吗？我们可以先做一个猜测，猜想它们大概在什么地方。这其实是不难的。然后呢，将猜测值与运动模型／观测模型给出的值相比较，可以算出误差：</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px" align="center">&nbsp;<img style="border: 0px; max-width: 100%" src="http://images.cnitblog.com/i/606958/201404/281108447836354.png" border="0" /></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　通俗一点地讲，例如，我猜机器人第一帧在(0,0,0)，第二帧在(0,0,1)。但是u1告诉我机器人往z方向（前方）走了0.9米，那么运动方程就出现了0.1m的误差。同时，第一帧中机器人发现了路标1，它在该机器人图像的正中间；第二帧却发现它在中间偏右的位置。这时我们猜测机器人只是往前走，也是存在误差的。至于这个误差是多少，可以根据观测方程算出来。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　我们得到了一堆误差，把这些误差平方后加起来（因为单纯的误差有正有负，然而平方误差可以改成其他的范数，只是平方更常用），就得到了平方误差和。我们把这个和记作phi，就是我们优化问题的目标函数。而优化变量就是那些个xp, xL。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px" align="center"><img style="border: 0px; max-width: 100%" src="http://images.cnitblog.com/i/606958/201404/281108133148174.png" border="0" />&nbsp;</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　改变优化变量，误差平方和（目标函数）就会相应地变大或变小，我们可以用数值方法求它们的梯度和二阶梯度矩阵，然后用梯度下降法求最优值。这些东西学过优化的同学都懂的。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px" align="center"><img style="border: 0px; max-width: 100%" src="http://images.cnitblog.com/i/606958/201404/281108587201279.png" border="0" />&nbsp;</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　注意到，一次机器人SLAM过程中，往往会有成千上万帧。而每一帧我们都有几百个关键点，一乘就是几百万个优化变量。这个规模的优化问题放到小萝卜的机载小破本上可解吗？是的，过去的同学都以为，Graph-based SLAM是无法计算的。但就在21世纪06，07年后，有些同学发现了，这个问题规模没有想象的那么大。上面的J和H两个矩阵是&ldquo;稀疏矩阵&rdquo;，于是呢，我们可以用稀疏代数的方法来解这个问题。&ldquo;稀疏&rdquo;的原因，在于每一个路标，往往不可能出现在所有运动过程中，通常只出现在一小部分图像里。正是这个稀疏性，使得优化思路成为了现实。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　优化方法利用了所有可以用到的信息（称为full-SLAM, global SLAM），其精确度要比我们一开始讲的帧间匹配高很多。当然计算量也要高一些。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　由于优化的稀疏性，人们喜欢用&ldquo;图&rdquo;来表达这个问题。所谓图，就是由节点和边组成的东西。我写成G=&#123;V,E&#125;，大家就明白了。V是优化变量节点，E表示运动/观测方程的约束。什么，更糊涂了吗？那我就上一张图，来自[3]。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px" align="center"><img style="border: 0px; max-width: 100%" src="http://images.cnitblog.com/i/606958/201404/281109171273435.png" border="0" />&nbsp;</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　图有点模糊，而且数学符号和我用的不太一样，我用它来给大家一个图优化的直观形象。上图中，p是机器人位置，l是路标，z是观测，t是位移。其中呢，p, l是优化变量，而z,t是优化的约束。看起来是不是像一些弹簧连接了一些质点呢？因为每个路标不可能出现在每一帧中，所以这个图是蛮稀疏的。不过，&ldquo;图&rdquo;优化只是优化问题的一个表达形式，并不影响优化的含义。实际解起来时还是要用数值法找梯度的。这种思路在计算机视觉里，也叫做Bundle Adjustment。它的具体方法请参见一篇经典文章[4]。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　不过，BA的实现方法太复杂，不太建议同学们拿C来写。好在2010年的ICRA上，其他的同学们提供了一个通用的开发包：g2o [5]。它是有图优化通用求解器，很好用，我改天再详细介绍这个软件包。总之，我们只要把观测和运动信息丢到求解器里就行。这个优化器会为我们求出机器人的轨迹和路标位置。如下图，红点是路标，蓝色箭头是机器人的位置和转角（2D SLAM）。细心的同学会发现它往右偏转了一些。：</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px; text-align: center">&nbsp;<img style="border: 0px; max-width: 100%" src="http://images.cnitblog.com/i/606958/201404/281110316584506.jpg" border="0" /></p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">&nbsp;</p><h2 style="margin: 10px 0px 3px; padding: 0px; line-height: 26px; font-size: 21px; font-family: verdana, sans-serif"><a style="color: #ca0000" name="t7"></a>7.&nbsp;&nbsp;&nbsp;&nbsp;闭环检测</h2><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　上面提到，仅用帧间匹配最大的问题在于误差累积，图优化的方法可以有效地减少累计误差。然而，如果把所有测量都丢进g2o，计算量还是有点儿大的。根据我自己测试，约10000多条边，g2o跑起来就有些吃力了。这样，就有同学说，能把这个图构造地简洁一些吗？我们用不着所有的信息，只需要把有用的拿出来就行了。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　事实上，小萝卜在探索房间时，经常会左转一下，右转一下。如果在某个时刻他回到了以前去过的地方，我们就直接与那时候采集的关键帧做比较，可以吗？我们说，可以，而且那是最好的方法。这个问题叫做闭环检测。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　闭环检测是说，新来一张图像时，如何判断它以前是否在图像序列中出现过？有两种思路：一是根据我们估计的机器人位置，看是否与以前某个位置邻近；二是根据图像的外观，看它是否和以前关键帧相似。目前主流方法是后一种，因为很多科学家认为前一种依靠有噪声的位置来减少位置的噪声，有点循环论证的意思。后一种方法呢，本质上是个模式识别问题（非监督聚类，分类），常用的是Bag-of-Words (BOW)。但是BOW需要事先对字典进行训练，因此SLAM研究者仍在探讨有没有更合适的方法。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　在Kinect SLAM经典大作中[6]，作者采用了比较简单的闭环方法：在前面n个关键帧中随机采k个，与当前帧两两匹配。匹配上后认为出现闭环。这个真是相当的简单实用，效率也过得去。</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　高效的闭环检测是SLAM精确求解的基础。这方面还有很多工作可以做。</p><h2 style="margin: 10px 0px 3px; padding: 0px; line-height: 26px; font-size: 21px; font-family: verdana, sans-serif"><a style="color: #ca0000" name="t8"></a>8.&nbsp;&nbsp;&nbsp;&nbsp;小结</h2><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">　　本文我们介绍了SLAM的基本概念，重点介绍了图优化解决SLAM问题的思路。我最近正在编写SLAM程序，它是一个Linux下基于cmake的工程。目前仍在开发当中。欢迎感兴趣的同学来交流研究心得，我的邮件是：gaoxiang12@mails.tsinghua.edu.cn。</p><h3 style="margin: 0px; padding: 0px; line-height: 26px; font-size: 16px; font-family: verdana, sans-serif"><a style="color: #ca0000" name="t9"></a>参考文献</h3><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">[1] Visual SLAM: Why filter? Strasdat et. al., Image and Vision Computing, 2012.</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">[2] Divide and Conquer: EKF SLAM in O(n), Paz Lina M et al., IEEE Transaction on Robotics, 2008</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">[3] Relative bundle adjustment, Sibley, Gabe, 2009</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">[4] Bundle adjustment - a Modern Synthesis. Triggs B et. el., Springer, 2000</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">[5] g2o: A General Framework for Graph Optimization, Kummerle Rainer, et. al., ICRA, 2011</p><p style="margin: 10px auto; padding: 0px; font-family: verdana, sans-serif; font-size: 13px; line-height: 15.6px">[6] 3-D Mapping with an RGB-D Camera, IEEE Transaction on Robotics, Endres et al., 2014</p>
]]>
</description>
</item><item>
<link>http://i.renjihe.com/blog/read.php?7427</link>
<title><![CDATA[现象级应用带动AR/VR行业发展 谁是下一个PokemonGo]]></title> 
<author>renjihe1988 &lt;admin@yourname.com&gt;</author>
<category><![CDATA[AR&amp;AI&amp;模式识别]]></category>
<pubDate>Wed, 27 Jul 2016 06:40:59 +0000</pubDate> 
<guid>http://i.renjihe.com/blog/read.php?7427</guid> 
<description>
<![CDATA[ 
	<p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">[市场调研公司Digi-Capital的一组数据显示，到2020年，AR的市场规模将达到1200亿美元，远高于VR的300亿美元。]</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　由<span><a style="text-decoration: none; outline: none; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: #2e8ed9" href="http://stock.finance.sina.com.cn/usstock/quotes/NTDOY.html" target="_blank" class="keyword f_st">任天堂</a></span>、Pokemon公司和<span><a style="text-decoration: none; outline: none; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: #2e8ed9" href="http://stock.finance.sina.com.cn/usstock/quotes/GOOG.html" target="_blank" class="keyword f_st">谷歌</a></span>的NianticLabs公司联合制作开发的AR手游PokemonGo（口袋妖怪）一夜风靡全球，使得任天堂的市值三天增加621亿元，也让AR概念受到前所未有的关注。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　<strong>更为广阔的市场前景</strong></p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　这也显现出AR的优势，即相较于VR而言，AR更易普及也更具市场潜力。市场调研公司Digi-Capital的一组数据显示，到2020年，AR的市场规模将达到1200亿美元，远高于VR的300亿美元。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　&ldquo;从台式机到将整个世界装在口袋里，AR技术一定会推动交互体验范式的转移，用户不会被屏幕的尺寸所限制。&rdquo;Meta公司战略副总裁RyanPamplin向《第一财经日报》记者表示。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　Meta是一家硅谷增强现实公司，已经完成B轮5000万美元融资，其中不乏<span><a style="text-decoration: none; outline: none; -webkit-tap-highlight-color: rgba(0, 0, 0, 0); color: #2e8ed9" href="http://stock.finance.sina.com.cn/hkstock/quotes/00700.html" target="_blank" class="keyword f_st">腾讯</a></span>、联想、高榕资本等中国投资者的身影。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　从交互体验而言，VR让用户置身于一个想象出来或者复制的世界，用户在体验VR时需要戴上全封闭的头盔，不便于行走，这将该技术的体验限制在了客厅、办公室或者座位上。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　与VR不同，AR是将计算机生成的虚拟世界嵌在现实世界上，即把数字想象世界加在真实世界之上。如果人们戴上一款轻便、通透性好的AR产品，就可以随意走动，这就像是移动游戏机与主机游戏之间的差距。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　虚拟与现实的融合，实时交互的实现以及三维注册体验（&ldquo;注册&rdquo;可以理解为跟踪和定位的意思，将计算机产生的虚拟物体与真实环境进行一一对应，当用户在真实环境中运动时，也将继续维持正确的对准关系）都让AR技术拥有更为庞大的用户基数和更为广泛的实际应用价值。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun"><strong>　　场景成功不意味着技术成熟</strong></p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　事实上从严格意义而言，PokemonGo并非真正意义上的AR，而是一种类AR应用，这类应用在国内很早之前就已经出现，例如央数文化推出的小熊尼奥早教型卡片类AR游戏。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　虽然实现了现实场景和虚拟影像的结合，但目前更多是借助手机摄像头加图像识别技术，而真正的AR要打造虚拟影像和现实的交互体验，对硬件以及计算机视觉、空间定位、运动追踪等有着更高的要求。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　&ldquo;现象级应用会一定程度带动AR/VR行业的发展，但是目前看来AR和VR的商用和普及都还需要一定的时间。整个行业还在早期阶段。&rdquo;高榕资本创始合伙人岳斌表示。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　虽然AR具有更大的发展潜力，但目前来看，市场上的AR产品种类和数量都很少，价格比较昂贵，大部分还处于研发阶段，未进入量产，不具备销售的可能性。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　智能手机是AR大众市场最具前景的平台，但AR应用在智能手机上的大规模部署仍然存在着重大障碍。已经有不少玩家反映PokemonGo这款游戏耗电量巨大，对网速要求较高，而且特别消耗流量。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　首先，在相机质量与成像处理方面，智能手机的相机标准还达不到AR后期算法的要求。其次运行功能强大的AR应用会让电池迅速耗干，目前的手机电池还达不到相应的续航水平，同时手机屏幕的大小和交互机制也是AR落地实现所面临的重要挑战。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　&ldquo;在VR时代，移动终端这一属性的认知或许不会那么强烈，但到了AR时代，新型移动智能终端的形态必将会出现，它将是对当下手机形态的更迭。&rdquo;北京行云时空科技有限公司CEO王洪亮告诉记者。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　在其看来，实际上AR在手机上一直没有办法摆脱服务器也没有普及的原因，还在于芯片、传感器、宽带、陀螺仪以及屏幕的视角等。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun"><strong>　　中国的硬件研发者</strong></p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　在VR市场还未成熟之下，一批公司已经投入到匹配AR的新型移动智能终端的开发，王洪亮便是其中一员。2015年该团队已经做出VR头盔，但随后调整方向放弃VR转战AR市场，就在一周前其刚刚发布了旗下AR品牌&ldquo;简观&rdquo;，并推出了简观AR眼镜。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　无独有偶，AR硬件公司影创也基本在同时期发布了四款VR/AR新品，其中一款混合现实概念头盔Halo可以实现AR和VR间的一键切换，赚足了大众的眼球。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　在王洪亮看来，上一代平台是手机，交互上是触摸屏，再上一代是PC，是鼠标和视窗操作系统，而在VR/AR时代，尤其是AR，所有的应用是要基于交互的，交互方式的突破会是行业的拐点。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　&ldquo;交互是整个生态产业链里面的核心。所以交互方式是打通软件和硬件的核心，这点解决了，再去兼容硬件和软件、操控。&rdquo;王洪亮解释道。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　PokemonGo的成功并不是完全基于AR技术的发展，还受益于LBS技术、游戏行业本身的热度、社交产品形态的高接受度以及社交网络的普及等等。&ldquo;口袋游戏并不是AR完整技术形态的呈现，它只是截取了AR技术中相对比较成熟的一个部分，结合了LBS技术呈现出的一个产品。&rdquo;王洪亮向《第一财经日报》表示。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　AR技术包含计算机图形学、计算机视觉、机器人技术和光学技术。在行云时空联合创始人、首席科学家王鹏杰看来，其中一项技术难点是基于视觉的SLAM方法的稳定性对场景特征的依赖较大，不得不在定位效率和定位精度之间取得平衡，很多时候需牺牲精度换得定位效率。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　同时基于视觉的交互会存在注册跟踪的误差，这种误差会导致交互有错误及延迟，而当前渲染显示技术还很难营造逼真的虚实融合，从而降低了交互的效率。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　RyanPamplin也表示公司将大量精力用于精确手势驱动跟踪功能的研发，即要设计出非常精确的传感器去追踪用户的手势驱动并不容易。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun"><strong>　　如何打造下一个AR爆款</strong></p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　硬件之外，PokemonGo能否为AR技术大规模商业化指一条明路，并带动国内大量AR游戏出现，而又如何打造下一个AR爆款？在昆仑万维CEO陈芳看来，PokemonGo应该会引发一批跟风和模仿者的短暂热潮，但很快会像&ldquo;部落冲突&rdquo;或&ldquo;皇室战争&rdquo;的跟风者一样，发现很难成功，然后热潮退却。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　据了解目前国内从事AR应用开发的企业有200多家，相较于数万家游戏企业而言，这个量级仍比较小。蓝港互动副总裁王世颖表示，国内之前上线的AR游戏比较少，在其做发行看过的产品中，平均200~300款产品里有一款AR产品。而且这些AR游戏产品，也没有取得特别好的经济效益，基本上是上线就死了，或者根本没有看到上线。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　&ldquo;我其实不太认同这是AR游戏的火爆，而是PokemonGO的火爆。这包含了Pokemon的IP、LBS、AR几大元素，除了任天堂以外，也不要忽略Niantic以及社交网络的贡献。&rdquo;陈芳直言。</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　新科技碰撞新玩法带来前所未有的游戏体验，可以预见在未来一段时间会有更多的大IP被引入AR游戏的开发中。游族网络COO陈礼标认为，从玩法上看，游戏与AR技术的结合，一是位置服务，二是图像识别，三是数据处理。从这三个方面看，&ldquo;AR游戏可能的引爆点就是朝着完善情景交互体验的方向发展。&rdquo;</p><p style="margin: 0px 0px 20px; padding: 0px; line-height: 32px; font-size: 18px; font-family: 'Microsoft Yahei', Simsun">　　不管是对于简观AR抑或其他AR公司而言，PokemonGo火爆都是一个积极信号，在面向大众的市场上面，&ldquo;AR将会是一个不断出现颠覆性创新的市场，有无数个未知的产品形态会突然出现，从而加速大众对于AR的认识，最终缩短AR技术深入到人们日常生活中的时间周期。&rdquo;王洪亮说道。</p>
]]>
</description>
</item><item>
<link>http://i.renjihe.com/blog/read.php?7426</link>
<title><![CDATA[虚拟现实(VR)产业深度报告 虚拟世界这么大，我想去看看]]></title> 
<author>renjihe1988 &lt;admin@yourname.com&gt;</author>
<category><![CDATA[AR&amp;AI&amp;模式识别]]></category>
<pubDate>Wed, 27 Jul 2016 06:39:09 +0000</pubDate> 
<guid>http://i.renjihe.com/blog/read.php?7426</guid> 
<description>
<![CDATA[ 
	<p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important">本篇报告深入分析了虚拟现实技术及产品的发展脉络,指出巨头及各路资本纷纷抢滩预示着产业已迎来引爆点,且VR将成为下一代计算平台,解决用户对&ldquo;距离&rdquo;的痛点,创造新的交互方式,未来商业化空间巨大,产业链较充分受益。</p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important">2016,虚拟现实(VR)爆发元年。虚拟现实(VR)泛指通过计算机技术模拟创造出虚拟世界,实现对现实世界的模拟。其具备沉浸性、交互性和构想性三大特征,早在20世纪60年代就已出现,当前在B端有广泛的应用,随着2C产品出现进入全新发展阶段,2016年国内外产业领先者都将陆续推出消费级新产品,同时大量资本涌入,我们认为产业发展已迎来爆发点。</p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important">虚拟现实(VR):下一代计算平台,解决距离痛点。iphone为代表的智能手机大规模普及带来移动互联网的爆发,其通过提升便捷性在一定程度上解决人们&ldquo;距离&rdquo;痛点,VR将成为下一代计算平台,进一步解决&ldquo;距离&rdquo;痛点。</p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important">其第一阶演进是优化过程体验,将&ldquo;虚拟&rdquo;变得更&ldquo;现实&rdquo;,让用户身临其境,从视角、情节、交互方式上全方位构建内容;第二阶演进则是强化虚拟与现实之间的连接与互动,真正实现对现实世界的模拟,从而极大缩短人与人的距离。VR将创造人人交互模式,AR将成为发展方向,空间巨大。</p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important">虚拟现实(VR)商业化大空间将开启。当前VR已有完整产业链,硬件与内容的结合是建立产业链优势的关键。预计2016年全球VR设备出货量超过500万台,2020年达到3000万台,2020年VR/AR市场规模超过1500亿美元,且内容收入占比将逐步提高。随着硬件放量和优质内容付费越来越普遍,VR首先在游戏、影视、直播等领域迎来商业化大空间,后续在电商、社交等领域都将产业多样化的商业模式。从商业模式上,最终将从产业链局部环节PK上升到跨硬件、平台、内容,辐射周边领域的整个生态圈的竞争。</p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><strong style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; vertical-align: baseline; color: inherit">以下为《产业深度报告（一）：虚拟世界这么大，我想去看看》告全文：</strong></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/df0004ef6e4006e8ce"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/df0004ef6e4006e8ce" border="0" alt="df0004ef6e4006e8c" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/db00111eddf3672ad6"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/db00111eddf3672ad6" border="0" alt="db00111eddf3672ad" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/df0004ef7138107382"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/df0004ef7138107382" border="0" alt="df0004ef713810738" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/dc0004ec563c36a69d"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/dc0004ec563c36a69d" border="0" alt="dc0004ec563c36a69" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/dd0004ebf95b499934"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/dd0004ebf95b499934" border="0" alt="dd0004ebf95b49993" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/dd0004ebfc0e476b73"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/dd0004ebfc0e476b73" border="0" alt="dd0004ebfc0e476b7" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/db00111ee57749c2e6"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/db00111ee57749c2e6" border="0" alt="db00111ee57749c2e" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/dd0004ec0185d2c044"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/dd0004ec0185d2c044" border="0" alt="dd0004ec0185d2c04" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/df0004ef7e7ee63ca5"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/df0004ef7e7ee63ca5" border="0" alt="df0004ef7e7ee63ca" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/de0004f00d2d5074c8"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/de0004f00d2d5074c8" border="0" alt="de0004f00d2d5074c" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/db00111eea50ddbdec"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/db00111eea50ddbdec" border="0" alt="db00111eea50ddbde" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/de0004f01005b3c8b9"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/de0004f01005b3c8b9" border="0" alt="de0004f01005b3c8b" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/dd0004ec05e401937c"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/dd0004ec05e401937c" border="0" alt="dd0004ec05e401937" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/df0004ef84940b4a61"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/df0004ef84940b4a61" border="0" alt="df0004ef84940b4a6" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/df0004ef86e95a1414"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/df0004ef86e95a1414" border="0" alt="df0004ef86e95a141" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/dd0004ec089b80e469"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/dd0004ec089b80e469" border="0" alt="dd0004ec089b80e46" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/dd0004ec09b1b582b3"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/dd0004ec09b1b582b3" border="0" alt="dd0004ec09b1b582b" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/dd0004ec0bec46aad3"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/dd0004ec0bec46aad3" border="0" alt="dd0004ec0bec46aad" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/de0004f0169f3b1f34"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/de0004f0169f3b1f34" border="0" alt="de0004f0169f3b1f3" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/de0004f0173a486779"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/de0004f0173a486779" border="0" alt="de0004f0173a48677" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/db00111ef923bd04d3"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/db00111ef923bd04d3" border="0" alt="db00111ef923bd04d" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/df0004ef8a797fbd95"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/df0004ef8a797fbd95" border="0" alt="df0004ef8a797fbd9" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/db00111efd28052f78"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/db00111efd28052f78" border="0" alt="db00111efd28052f7" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/dd0004ec1392a62a8e"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/dd0004ec1392a62a8e" border="0" alt="dd0004ec1392a62a8" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/dc0004ec70ac2cee5a"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/dc0004ec70ac2cee5a" border="0" alt="dc0004ec70ac2cee5" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/db00111f000c8375f3"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/db00111f000c8375f3" border="0" alt="db00111f000c8375f" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #336699; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/df0004ef9689e78437"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/df0004ef9689e78437" border="0" alt="df0004ef9689e7843" width="640" height="905" /></a></p><p style="margin: 0px 0px 1.5em; padding: 0px; border: 0px; vertical-align: baseline; color: #555555; font-family: 'Microsoft YaHei', 微软雅黑, STHeiti, 'WenQuanYi Micro Hei', SimSun, sans-serif, 'Open Sans', Arial; font-size: 1.2em !important; line-height: 2em !important"><a style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; outline: none; color: #e00000; text-decoration: none" href="http://www.199it.com/wp-content/uploads/2016/01/dc0004ec743fa28b4a"><img style="margin: 0px; padding: 0px; border: 0px; font-size: 17.28px; font-weight: inherit; vertical-align: baseline; width: auto; max-width: 100%; height: auto; display: block" class="attachment-full size-full" src="http://www.199it.com/wp-content/uploads/2016/01/dc0004ec743fa28b4a" border="0" alt="dc0004ec743fa28b4" width="640" height="905" /></a></p><div><br /></div>
]]>
</description>
</item><item>
<link>http://i.renjihe.com/blog/read.php?7425</link>
<title><![CDATA[实例亲授：教你如何创建AR应用]]></title> 
<author>renjihe1988 &lt;admin@yourname.com&gt;</author>
<category><![CDATA[AR&amp;AI&amp;模式识别]]></category>
<pubDate>Wed, 27 Jul 2016 06:37:35 +0000</pubDate> 
<guid>http://i.renjihe.com/blog/read.php?7425</guid> 
<description>
<![CDATA[ 
	<p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">我们曾经介绍过许多AR应用中的&nbsp;<a style="cursor: pointer; color: #0066cc; text-decoration: none" href="http://www.csdn.net/article/2014-07-16/2820690-10-best-AR-App" target="_blank">最新典型案例</a>和&nbsp;<a style="cursor: pointer; color: #0066cc; text-decoration: none" href="http://www.csdn.net/article/2014-08-07/2821092-10-educational-ar-apps" target="_blank">教育类应用</a>，他们利用Vuforia与现实进行交互，创造出更加新奇的体验。本文作者是一位刚刚接触AR开发的年轻开发者，他将教你如何在现实世界和虚拟世界中加入虚拟按钮，形成交互。</p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px; text-align: center"><a style="cursor: pointer; color: #0066cc; text-decoration: none" href="http://cms.csdnimg.cn/article/201409/09/540e74376a51a.jpg" target="_blank"><img style="vertical-align: middle; border: none" src="http://cms.csdnimg.cn/article/201409/09/540e74376a51a_middle.jpg" border="0" /></a><br /></p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"><strong>译文如下：</strong></p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"><span style="background-color: initial">在这个教程中，我们会再我的</span>&nbsp;<a style="cursor: pointer; color: #0066cc; text-decoration: none; background-color: initial" href="http://www.marcofolio.net/other/introduction_into_augmented_reality_with_vuforia.html"></a><a style="cursor: pointer; color: #0066cc; text-decoration: none" href="http://www.marcofolio.net/other/introduction_into_augmented_reality_with_vuforia.htmlhttp://www.marcofolio.net/other/introduction_into_augmented_reality_with_vuforia.html" target="_blank">前一篇</a>&nbsp;<span style="background-color: initial">关于虚拟现实（augmented）的教程基础上再增加一些很酷的玩意。对我来说：增强现实（AR）本身已经非常棒了，但是这次，我们会在现实世界和虚拟世界中加更多的交互。我们通过添加虚拟按钮来实现这个功能，也就是说只需要简单的在AR世界中添加一个按钮，我们就能在真实世界中点击他。这真真是酷毙了！</span></p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px; text-align: center"><span style="background-color: initial"><a style="cursor: pointer; color: #0066cc; text-decoration: none" href="http://cms.csdnimg.cn/article/201409/09/540e65d84b31f.jpg" target="_blank"><img style="vertical-align: middle; border: none" src="http://cms.csdnimg.cn/article/201409/09/540e65d84b31f.jpg" border="0" /></a><br /></span></p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px; text-align: center">图：最终效果</p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"></p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">因为我们是基于上一篇教程，所以我们会使用同样的技术Vuforia。这个技术让我们能够简单的达到这个效果。我们这就开始吧！</p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">这里有一段&nbsp;<a style="cursor: pointer; color: #0066cc; text-decoration: none" href="http://youtu.be/oEcIbx8YvUc" target="_blank">小视频演示</a>（youtube视频）我们通过这片教程可以创造的效果。<span style="background-color: initial">不得不说：这简直太酷了。虽然我必须承认，并不是所有的情况下都能像这样工作良好，不过对于简单的按钮，看起来工作的不错。让我们来看看怎样创建一个像这样的程序。</span></p><h3 style="margin: 0.75em 0px; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; line-height: 24px"><strong>准备工作</strong></h3><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">为了能让你的应用程序像这样工作，你需要具备下面几项条件：</p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"></p><ul style="margin: 0px 0px 1em 20px; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"><li style="margin: 0px; padding: 0px; list-style: disc"><span style="background-color: initial">任意一个可以运行的AR应用程序，比如示例程序</span></li><li style="margin: 0px; padding: 0px; list-style: disc"><span style="background-color: initial">C#的基本支持，这个是Unity使用的语言，我们将用他来实现我们的虚拟按钮</span></li><li style="margin: 0px; padding: 0px; list-style: disc"><span style="background-color: initial">另一个用于render（呈现）的3D模型，这样我们才能在几个不同的模型间切换，我会使用</span>&nbsp;<a style="cursor: pointer; color: #0066cc; text-decoration: none; background-color: initial" href="http://en.wikipedia.org/wiki/Tekken_Tag_Tournament"></a><a style="cursor: pointer; color: #0066cc; text-decoration: none" href="http://en.wikipedia.org/wiki/Tekken_Tag_Tournament" target="_blank">铁拳游戏</a>&nbsp;<span style="background-color: initial">中的几个</span>&nbsp;<a style="cursor: pointer; color: #0066cc; text-decoration: none; background-color: initial" href="http://www.models-resource.com/psx_ps2_ps3/tekkentagtournament/"></a><a style="cursor: pointer; color: #0066cc; text-decoration: none" href="http://www.models-resource.com/psx_ps2_ps3/tekkentagtournament/" target="_blank">模型</a>&nbsp;<span style="background-color: initial">。</span></li></ul><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"></p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">当你一切准备就绪，就让我们进行接下来的步骤。</p><h3 style="margin: 0.75em 0px; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; line-height: 24px"><strong>导入模型</strong></h3><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">就像前一个教程讲的那样，你可以这样导入你的模型：</p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"></p><ul style="margin: 0px 0px 1em 20px; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"><li style="margin: 0px; padding: 0px; list-style: disc"><span style="background-color: initial">右键单击Project（项目Tab页）中的Assets文件夹</span></li><li style="margin: 0px; padding: 0px; list-style: disc"><span style="background-color: initial">选择&ldquo;Reveal in Finder&rdquo;(在Window上也有可能是&ldquo;Reveal in Explorer&rdquo;）</span></li><li style="margin: 0px; padding: 0px; list-style: disc"><span style="background-color: initial">打开Assets文件夹</span></li><li style="margin: 0px; padding: 0px; list-style: disc"><span style="background-color: initial">创建一个名叫Models新的文件夹（或者可以取别的合乎逻辑的名字）</span></li><li style="margin: 0px; padding: 0px; list-style: disc"><span style="background-color: initial">把模型（包括所有的纹理（Texture）等等）放入到这个文件夹中</span></li><li style="margin: 0px; padding: 0px; list-style: disc"><span style="background-color: initial">返回Unity</span></li></ul><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"></p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">Unity会检测到你对Assets文件夹所做的改动，并会使用最新的信息更新自己的显示。<span style="background-color: initial">现在把你的模型拖入到增强显示场景中，放在前一个模型的上面。确保他在层次结构（Hierarchy）中被的放置在正确的ImageTarget下面。我也拷贝了上一个模型一样的Transform属性，所以他们的大小应该相同（只是旋转角度不同），最终你会得到类似下面的效果。</span></p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px; text-align: center"><span style="background-color: initial"><a style="cursor: pointer; color: #0066cc; text-decoration: none" href="http://cms.csdnimg.cn/article/201409/09/540e6735781ae.jpg" target="_blank"><img style="vertical-align: middle; border: none" src="http://cms.csdnimg.cn/article/201409/09/540e6735781ae.jpg" border="0" /></a><br /></span></p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"></p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">现在看起来稍微有点怪，不用担心，使用我们的虚拟按钮，我们能够确保显示和隐藏正确的模型，让他们互相不会重叠。</p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">现在花时间看一眼model的名称，待会可能会用到他们。在分级窗口（Hierarchy）里可以找到他们，在我的项目里他们分别是：jin1u和yosi1u</p><h3 style="margin: 0.75em 0px; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; line-height: 24px">添加虚拟按钮</h3><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">现在我们需要在场景中加入虚拟按钮，在你的Project窗口中，打开Assets/Qualcomm Augmented Reality/Prefabs-folder.这里面能看到VirtualButton;把他拖动到你的场景中，在Hierarchy（分级窗口）里位于你的ImageTarget之下。本质上讲，当我们查看ImageTarget的时候，虚拟按钮不能被看到，也就是处于不可见（invisible）状态。在Unity中透明物体的默认颜色是蓝色，所以当你在场景中添加虚拟按钮时，也应该同样是蓝色的。</p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">虚拟按钮的形状默认是矩形的，你可以将他变形（Transform）到你的点击区需要的样子和位置。只用确定按钮区域足够覆盖ImageTarget上的一些特征区域；如果探测到这些特征区域被挡住，Vuforia就会认为按钮被点击。下面是我的代码效果。</p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px; text-align: center"><a style="cursor: pointer; color: #0066cc; text-decoration: none" href="http://cms.csdnimg.cn/article/201409/09/540e68be20073.jpg" target="_blank"><img style="vertical-align: middle; border: none" src="http://cms.csdnimg.cn/article/201409/09/540e68be20073_middle.jpg" border="0" /></a><br /></p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"></p><h3 style="margin: 0.75em 0px; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; line-height: 24px">编写按钮脚本</h3><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">按钮现在还什么也不能做，我们需要为他添加响应代码。这就需要为他创建一段脚本：</p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"></p><ul style="margin: 0px 0px 1em 20px; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"><li style="margin: 0px; padding: 0px; list-style: disc"><span style="background-color: initial">右键单击Project中Assets文件夹</span></li><li style="margin: 0px; padding: 0px; list-style: disc"><span style="background-color: initial">选择&ldquo;Reveal in Finder&rdquo;(在Windows中也可能是&ldquo;Reveal in Explore&rdquo;）</span></li><li style="margin: 0px; padding: 0px; list-style: disc"><span style="background-color: initial">打开Assets文件夹</span></li><li style="margin: 0px; padding: 0px; list-style: disc"><span style="background-color: initial">创建一个叫做script的文件夹（或者其他合理的名字）</span></li></ul><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"></p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">在文件夹中，创建一个新的空文件，叫做TekkenVirtualButtonEventHandler.cs（或者其他什么你觉得合适的名称），代码的框架如下：</p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"></p><pre style="margin-top: 0px; padding: 10px; list-style: none; overflow: hidden; white-space: pre-wrap; border: 1px solid #dddddd; color: #333333; font-size: 14px; line-height: 24px; background: #f7f7f7">using UnityEngine; &nbsp; public class TekkenVirtualButtonEventHandler : MonoBehaviour, IVirtualButtonEventHandler &#123;&nbsp;&nbsp;&nbsp;&nbsp; /// &lt;summary&gt;&nbsp;&nbsp;&nbsp;&nbsp; /// Called when the scene is loaded&nbsp;&nbsp;&nbsp;&nbsp; /// &lt;/summary&gt;&nbsp;&nbsp;&nbsp;&nbsp; void Start() &#123; &#125;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /// &lt;summary&gt;&nbsp;&nbsp;&nbsp;&nbsp; /// Called when the virtual button has just been pressed:&nbsp;&nbsp;&nbsp;&nbsp; /// &lt;/summary&gt;&nbsp;&nbsp;&nbsp;&nbsp; public void OnButtonPressed(VirtualButtonAbstractBehaviour vb) &#123; &#125;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /// &lt;summary&gt;&nbsp;&nbsp;&nbsp;&nbsp; /// Called when the virtual button has just been released:&nbsp;&nbsp;&nbsp;&nbsp; /// &lt;/summary&gt;&nbsp;&nbsp;&nbsp;&nbsp; public void OnButtonReleased(VirtualButtonAbstractBehaviour vb) &#123; &#125; &#125;</pre><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"></p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">该类中最重要的就是IVirtualButtonEventHandler接口，这个接口保证类实现OnButtonPressed 和 OnButtonReleased两个方法。在这个教程里，我们不会实现OnButtonRelease方法，因为我们暂时用不到他，不过因为接口的原因，类里面必须要有这个方法。这个脚本待会就回附加到ImageTarget上。</p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">首先，我们需要把Button注册为一个活动事件，我们会把下面的代码放到Start方法里（代码里加了注释）</p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"></p><pre style="margin-top: 0px; padding: 10px; list-style: none; overflow: hidden; white-space: pre-wrap; border: 1px solid #dddddd; color: #333333; font-size: 14px; line-height: 24px; background: #f7f7f7">// Search for all Children from this ImageTarget with type VirtualButtonBehaviour VirtualButtonBehaviour[] vbs = GetComponentsInChildren&lt;VirtualButtonBehaviour&gt;(); for (int i = 0; i &lt; vbs.Length; ++i) &#123;&nbsp;&nbsp;&nbsp;&nbsp; // Register with the virtual buttons TrackableBehaviour&nbsp;&nbsp;&nbsp;&nbsp; vbs[i].RegisterEventHandler(this); &#125;</pre><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"></p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">接下来要做的，就是在场景中找到和存储模型（代码中的GameObject）。第一步我们要为类创建两个私有字段</p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"></p><pre style="margin-top: 0px; padding: 10px; list-style: none; overflow: hidden; white-space: pre-wrap; border: 1px solid #dddddd; color: #333333; font-size: 14px; line-height: 24px; background: #f7f7f7">private GameObject _modelJin; private GameObject _modelYoshimitsu;</pre><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"></p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">接着在Start方法里对这两个变量进行赋值，在Unity中你可以用Hieraychy下Model的名字来找到gameObject；</p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"></p><pre style="margin-top: 0px; padding: 10px; list-style: none; overflow: hidden; white-space: pre-wrap; border: 1px solid #dddddd; color: #333333; font-size: 14px; line-height: 24px; background: #f7f7f7">_modelJin = transform.FindChild(&quot;jin1u&quot;).gameObject; _modelYoshimitsu = transform.FindChild(&quot;yosi1u&quot;).gameObject;</pre><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">在程序开始的时候，我们希望Jin不显示，所以要先把他藏起来。这就是开始方法的最后一行需要做的事情:</p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"></p><pre style="margin-top: 0px; padding: 10px; list-style: none; overflow: hidden; white-space: pre-wrap; border: 1px solid #dddddd; color: #333333; font-size: 14px; line-height: 24px; background: #f7f7f7">_modelJin.SetActive(false);</pre><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"></p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">现在我们开始搞定OnButtonPressed方法！可以看出这个方法的第一个也是唯一一个参数就是被点击的按钮。利用这个参数，可以显示和隐藏模型，这里我们要用到开始设定的按钮名称，实现如下</p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"></p><pre style="margin-top: 0px; padding: 10px; list-style: none; overflow: hidden; white-space: pre-wrap; border: 1px solid #dddddd; color: #333333; font-size: 14px; line-height: 24px; background: #f7f7f7">switch(vb.VirtualButtonName) &#123;&nbsp;&nbsp;&nbsp;&nbsp; case &quot;btnYoshimitsu&quot;:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; _modelJin.SetActive(false);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; _modelYoshimitsu.SetActive(true);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;&nbsp;&nbsp;&nbsp;&nbsp; case &quot;btnJin&quot;:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; _modelJin.SetActive(true);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; _modelYoshimitsu.SetActive(false);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;&nbsp;&nbsp;&nbsp;&nbsp; default:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; throw new UnityException(&quot;Button not supported: &quot; + vb.VirtualButtonName);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break; &#125;</pre><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"></p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">也许你想整理一下我的代码，没有关系，我只希望你能理解我的思路。记得保存你的代码。这个类的完整实现可以<a style="cursor: pointer; color: #0066cc; text-decoration: none" href="http://www.marcofolio.net/images/stories/useful/other/ar_button/TekkenVirtualButtonEventHandler.cs"></a><a style="cursor: pointer; color: #0066cc; text-decoration: none" href="http://www.marcofolio.net/images/stories/useful/other/ar_button/TekkenVirtualButtonEventHandler.cs" target="_blank">在这里找到</a>&nbsp;。</p><h3 style="margin: 0.75em 0px; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; line-height: 24px">附加脚本到ImageTarget</h3><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">现在回到Unity，程序会自动找到你创建的script文件夹以及你创建的TekkenVirtualButtonEventHandler 。只需把脚本拖拽到Hierarchy里的ImageTarget上方，关联就会自动建立，你能通过选择Inspector中的ImageTarget来验证关联是否正确；如果关联正确建立，就能够看到按钮事件处理器被附加在了按钮上。</p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"></p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">这个方法太有用了吧！现在编译你的解决方案，并在你的移动设备上运行（如何运行参考我的上一篇教程）。现在你应该准备好了吧，祝你好运！</p><h3 style="margin: 0.75em 0px; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; line-height: 24px">小结</h3><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">截止目前为止，我们已经为虚拟按钮准备好了可以工作的点击区，由于他们不可见，你也许想要加入下面的东西：</p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"></p><ul style="margin: 0px 0px 1em 20px; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"><li style="margin: 0px; padding: 0px; list-style: disc"><span style="background-color: initial">把你的ImageTarget换成已打印按钮（这样就能在真实世界里看见他）或者</span></li><li style="margin: 0px; padding: 0px; list-style: disc"><span style="background-color: initial">在VirtualButton上添加多个Pane（这样就能在增强现实世界里看到他）</span></li></ul><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"></p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">我使用第二个方法，所以我不需要再次打印ImageTarget，但是这样做不好的一面是，你的手在AR世界显示在按钮的下面，除此之外一切正常。</p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">关于ImageTarget更多高级的例子，我推荐阅读《<a style="cursor: pointer; color: #0066cc; text-decoration: none" href="https://developer.vuforia.com/resources/dev-guide/virtual-buttons-unity" target="_blank">在Unity中使用虚拟按钮的官方教程</a>》。</p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">他在如何在运行时创建和删除虚拟按钮给出更多的细节，以及如何把按钮和其他的游戏对象（game object）相连。</p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">大家觉得怎么样？在我看来，一旦你熟悉了相关操作，使用Vuforia向增强现实（Augmented Reality）中添加虚拟按钮就变得非常简单。最终的成果也很有趣！当然你肯定知道，除了简单的显示和隐藏模型，你也可以让他们动起来，旋转，变化纹理。</p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px">那么下一步你会做什么？</p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"><strong>原文地址：<a style="cursor: pointer; color: #0066cc; text-decoration: none" href="http://www.marcofolio.net/other/virtual_buttons_in_augmented_reality_with_vuforia.html" target="_blank">Marcofolio</a></strong></p><p style="margin: 0px 0px 1.5em; padding: 0px; list-style: none; color: #333333; font-family: Helvetica, Tahoma, Arial, sans-serif; font-size: 14px; line-height: 24px"><strong>了解更多AR技术信息，欢迎访问<a style="cursor: pointer; color: #0066cc; text-decoration: none" href="http://qualcomm.csdn.net/" target="_blank">Qualcomm开发者专区</a></strong></p>
]]>
</description>
</item><item>
<link>http://i.renjihe.com/blog/read.php?7424</link>
<title><![CDATA[学习笔记：使用 OpenCV 识别 QRCode]]></title> 
<author>renjihe1988 &lt;admin@yourname.com&gt;</author>
<category><![CDATA[AR&amp;AI&amp;模式识别]]></category>
<pubDate>Wed, 27 Jul 2016 06:36:19 +0000</pubDate> 
<guid>http://i.renjihe.com/blog/read.php?7424</guid> 
<description>
<![CDATA[ 
	http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/<br /><br /><h2 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 20px; color: #555555; text-align: justify">背景</h2><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">识别二维码的项目数不胜数，每次都是开箱即用，方便得很。</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">这次想用 OpenCV 从零识别二维码，主要是温习一下图像处理方面的基础概念，熟悉 OpenCV 的常见操作，以及了解二维码识别和编码的基本原理。</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">作者本人在图像处理方面还是一名新手，采用的方法大多原始粗暴，如果有更好的解决方案欢迎指教。</p><h2 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 20px; color: #555555; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/#QRCode" title="QRCode" class="headerlink"></a>QRCode</h2><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">二维码有很多种，这里我选择的是比较常见的 QRCode 作为探索对象。QRCode 全名是 Quick Response Code，是一种可以快速识别的二维码。</p><h3 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 18px; color: #555555; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/#尺寸" title="尺寸" class="headerlink"></a>尺寸</h3><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">QRCode 有不同的 Version ，不同的 Version 对应着不同的尺寸。将最小单位的黑白块称为 module ，则 QRCode 尺寸的公式如下：</p><blockquote style="margin: 0px; padding: 0px 15px; color: #666666; border-left-width: 4px; border-left-style: solid; border-left-color: #dddddd; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><p style="margin: 0px 0px 25px">Version V = ((V-1)*4 + 21) ^ 2 modules</p></blockquote><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">常见的 QRCode 一共有40种尺寸：</p><ul style="list-style: none; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><li style="list-style: circle">Version 1 : 21 * 21 modules</li><li style="list-style: circle">Version 2 : 25 * 25 modules</li><li style="list-style: circle">&hellip;</li><li style="list-style: circle">Version 40: 177 * 177 modules</li></ul><h3 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 18px; color: #555555; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/#分类" title="分类" class="headerlink"></a>分类</h3><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">QRCode 分为 Model 1、Model 2、Micro QR 三类：</p><ul style="list-style: none; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><li style="list-style: circle">Model 1 ：是 Model 2 和 Micro QR 的原型，有 Version 1 到 Version 14 共14种尺寸。</li><li style="list-style: circle">Model 2 ：是 Model 1 的改良版本，添加了对齐标记，有 Version 1 到 Version 40 共40种尺寸。</li><li style="list-style: circle">Micro QR ：只有一个定位标记，最小尺寸是 11*11 modules 。</li></ul><h3 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 18px; color: #555555; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/#组成" title="组成" class="headerlink"></a>组成</h3><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="group" href="http://ww1.sinaimg.cn/large/61d238c7jw1f33jbzaxkxj21e00xcq5b.jpg" class="fancybox"><img style="border: 1px solid #dddddd; margin: 0px auto; max-width: 100%; height: auto; cursor: -webkit-zoom-in; box-sizing: border-box; padding: 3px; display: block !important" src="http://ww1.sinaimg.cn/large/61d238c7jw1f33jbzaxkxj21e00xcq5b.jpg" border="0" /></a></p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">QRCode 主要由以下部分组成：</p><ul style="list-style: none; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><li style="list-style: circle">1 - Position Detection Pattern：位于三个角落，可以快速检测二维码位置。</li><li style="list-style: circle">2 - Separators：一个单位宽的分割线，提高二维码位置检测的效率。</li><li style="list-style: circle">3 - Timing Pattern：黑白相间，用于修正坐标系。</li><li style="list-style: circle">4 - Alignment Patterns：提高二维码在失真情况下的识别率。</li><li style="list-style: circle">5 - Format Information：格式信息，包含了错误修正级别和掩码图案。</li><li style="list-style: circle">6 - Data：真正的数据部分。</li><li style="list-style: circle">7 - Error Correction：用于错误修正，和 Data 部分格式相同。</li></ul><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">具体的生成原理和识别细节可以阅读文末的参考文献，比如耗子叔的这篇《<a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="http://coolshell.cn/articles/10590.html" target="_blank">二维码的生成细节和原理</a>》。</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">由于二维码的解码步骤比较复杂，而本次学习重点是数字图像处理相关的内容，所以本文主要是解决二维码的识别定位问题，数据解码的工作交给第三方库（比如&nbsp;<a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="https://github.com/ZBar/ZBar" target="_blank">ZBAR</a>）完成。</p><h2 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 20px; color: #555555; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/#OpenCV" title="OpenCV" class="headerlink"></a>OpenCV</h2><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">在开始识别二维码之前，还需要补补课，了解一些图像处理相关的基本概念。</p><h3 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 18px; color: #555555; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/#contours" title="contours" class="headerlink"></a>contours</h3><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">轮廓（contour）可以简单理解为一段连续的像素点。比如一个长方形的边，比如一条线，比如一个点，都属于轮廓。而轮廓之间有一定的层级关系，以下图为例：</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="group" href="http://ww1.sinaimg.cn/large/61d238c7jw1f341rc2qogj21e00xcgms.jpg" class="fancybox"><img style="border: 1px solid #dddddd; margin: 0px auto; max-width: 100%; height: auto; cursor: -webkit-zoom-in; box-sizing: border-box; padding: 3px; display: block !important" src="http://ww1.sinaimg.cn/large/61d238c7jw1f341rc2qogj21e00xcgms.jpg" border="0" /></a></p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">主要说明以下概念：</p><ul style="list-style: none; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><li style="list-style: circle">external &amp; internal：对于最大的包围盒而言，2 是外部轮廓（external），2a 是内部轮廓（internal）。</li><li style="list-style: circle">parent &amp; child：2 是 2a 的父轮廓（parent），2a 是 2 的子轮廓（child），3 是 2a 的子轮廓，同理，3a 是 3 的子轮廓，4 和 5 都是 3a 的子轮廓。</li><li style="list-style: circle">external &#124; outermost：0、1、2 都属于最外围轮廓（outermost）。</li><li style="list-style: circle">hierarchy level：0、1、2 是同一层级（same hierarchy），都属于 hierarchy-0 ，它们的第一层子轮廓属于 hierarchy-1 。</li><li style="list-style: circle">first child：4 是 3a 的第一个子轮廓（first child）。实际上 5 也可以，这个看个人喜好了。</li></ul><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">在 OpenCV 中，通过一个数组表达轮廓的层级关系：</p><blockquote style="margin: 0px; padding: 0px 15px; color: #666666; border-left-width: 4px; border-left-style: solid; border-left-color: #dddddd; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><p style="margin: 0px 0px 25px">[Next, Previous, First_Child, Parent]</p></blockquote><ul style="list-style: none; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><li style="list-style: circle">Next：同一层级的下一个轮廓。在上图中， 0 的 Next 就是 1 ，1 的 Next 就是 2 ，2 的 Next 是 -1 ，表示没有下一个同级轮廓。</li><li style="list-style: circle">Previous：同一层级的上一个轮廓。比如 5 的 Previous 是 4， 1 的 Previous 就是 0 ，0 的 Previous 是 -1 。</li><li style="list-style: circle">First_Child：第一个子轮廓，比如 2 的 First_Child 就是 2a ，像 3a 这种有两个 Child ，只取第一个，比如选择 4 作为 First_Child 。</li><li style="list-style: circle">Parent：父轮廓，比如 4 和 5 的 Parent 都是 3a ，3a 的 Parent 是 3 。</li></ul><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">关于轮廓层级的问题，参考阅读：《<a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="http://docs.opencv.org/3.1.0/d9/d8b/tutorial_py_contours_hierarchy.html" target="_blank">Tutorial: Contours Hierarchy</a>》</p><h4 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; color: #555555; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/#findContours" title="findContours" class="headerlink"></a>findContours</h4><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">了解了 contour 相关的基础概念之后，接下来就是在 OpenCV 里的具体代码了。</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">findContours&nbsp;是寻找轮廓的函数，函数定义如下：</p><blockquote style="margin: 0px; padding: 0px 15px; color: #666666; border-left-width: 4px; border-left-style: solid; border-left-color: #dddddd; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><p style="margin: 0px 0px 25px">cv2.findContours(image, mode, method) &rarr; image, contours, hierarchy</p></blockquote><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">其中：</p><ul style="list-style: none; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><li style="list-style: circle">image：资源图片，8 bit 单通道，一般需要将普通的 BGR 图片通过 cvtColor 函数转换。</li><li style="list-style: circle">mode：边缘检测的模式，包括：<ul style="list-style: none"><li style="list-style: circle">CV_RETR_EXTERNAL：只检索最大的外部轮廓（extreme outer），没有层级关系，只取根节点的轮廓。</li><li style="list-style: circle">CV_RETR_LIST：检索所有轮廓，但是没有 Parent 和 Child 的层级关系，所有轮廓都是同级的。</li><li style="list-style: circle">CV_RETR_CCOMP：检索所有轮廓，并且按照二级结构组织：外轮廓和内轮廓。以前面的大图为例，0、1、2、3、4、5 都属于第0层，2a 和 3a 都属于第1层。</li><li style="list-style: circle">CV_RETR_TREE：检索所有轮廓，并且按照嵌套关系组织层级。以前面的大图为例，0、1、2 属于第0层，2a 属于第1层，3 属于第2层，3a 属于第3层，4、5 属于第4层。</li></ul></li><li style="list-style: circle">method：边缘近似的方法，包括：<ul style="list-style: none"><li style="list-style: circle">CV_CHAIN_APPROX_NONE：严格存储所有边缘点，即：序列中任意两个点的距离均为1。</li><li style="list-style: circle">CV_CHAIN_APPROX_SIMPLE：压缩边缘，通过顶点绘制轮廓。</li></ul></li></ul><h4 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; color: #555555; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/#drawContours" title="drawContours" class="headerlink"></a>drawContours</h4><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">drawContours&nbsp;是绘制边缘的函数，可以传入&nbsp;findContours&nbsp;函数返回的轮廓结果，在目标图像上绘制轮廓。函数定义如下：</p><blockquote style="margin: 0px; padding: 0px 15px; color: #666666; border-left-width: 4px; border-left-style: solid; border-left-color: #dddddd; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><p style="margin: 0px 0px 25px">Python: cv2.drawContours(image, contours, contourIdx, color) &rarr; image</p></blockquote><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">其中：</p><ul style="list-style: none; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><li style="list-style: circle">image：目标图像，直接修改目标的像素点，实现绘制。</li><li style="list-style: circle">contours：需要绘制的边缘数组。</li><li style="list-style: circle">contourIdx：需要绘制的边缘索引，如果全部绘制则为 -1。</li><li style="list-style: circle">color：绘制的颜色，为 BGR 格式的 Scalar 。</li><li style="list-style: circle">thickness：可选，绘制的密度，即描绘轮廓时所用的画笔粗细。</li><li style="list-style: circle">lineType: 可选，连线类型，分为以下几种：<ul style="list-style: none"><li style="list-style: circle">LINE_4：4-connected line，只有相邻的点可以连接成线，一个点有四个相邻的坑位。</li><li style="list-style: circle">LINE_8：8-connected line，相邻的点或者斜对角相邻的点可以连接成线，一个点有四个相邻的坑位和四个斜对角相邻的坑位，所以一共有8个坑位。</li><li style="list-style: circle">LINE_AA：antialiased line，抗锯齿连线。</li></ul></li><li style="list-style: circle">hierarchy：可选，如果需要绘制某些层级的轮廓时作为层级关系传入。</li><li style="list-style: circle">maxLevel：可选，需要绘制的层级中的最大级别。如果为1，则只绘制最外层轮廓，如果为2，绘制最外层和第二层轮廓，以此类推。</li></ul><h3 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 18px; color: #555555; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/#moments" title="moments" class="headerlink"></a>moments</h3><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">矩（moment）起源于物理学的力矩，最早由阿基米德提出，后来发展到统计学，再后来到数学进行归纳。本质上来讲，物理学和统计学的矩都是数学上矩的特例。</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">物理学中的矩表示作用力促使物体绕着支点旋转的趋向，通俗理解就像是拧螺丝时用的扭转的力，由矢量和作用力组成。</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">数学中的矩用来描述数据分布特征的一类数字特征，例如：算术平均数、方差、标准差、平均差，这些值都是矩。在实数域上的实函数 f(x) 相对于值 c 的 n 阶矩为：</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="group" href="https://upload.wikimedia.org/math/9/0/f/90ffd165ffed509a09057c505a660c66.png" class="fancybox"><img style="border: 1px solid #dddddd; margin: 0px auto; max-width: 100%; height: auto; cursor: -webkit-zoom-in; box-sizing: border-box; padding: 3px; display: block !important" src="https://upload.wikimedia.org/math/9/0/f/90ffd165ffed509a09057c505a660c66.png" border="0" /></a></p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">常用的矩有两类：</p><ul style="list-style: none; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><li style="list-style: circle">原点矩（raw moment）：相对原点的矩，即当 c 为 0 的时候。1阶原点矩为期望，也成为中心。</li><li style="list-style: circle">中心矩（central moment）：相对于中心点的矩，即当 c 为 E(x) 的时候。1阶中心矩为0，2阶中心矩为方差。</li></ul><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">到了图像处理领域，对于灰度图（单通道，每个像素点由一个数值来表示）而言，把坐标看成二维变量 (X, Y)，那么图像可以用二维灰度密度函数 I(x, y) 来表示。</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">简单来讲，图像的矩就是图像的像素相对于某个点的分布情况统计，是图像的一种特征描述。</p><h4 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; color: #555555; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/#raw-moment" title="raw moment" class="headerlink"></a>raw moment</h4><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">图像的原点矩（raw moment）是相对于原点的矩，公式为：</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="group" href="https://upload.wikimedia.org/math/2/2/e/22ebb2a58ea6d43753b1f5885530c114.png" class="fancybox"><img style="border: 1px solid #dddddd; margin: 0px auto; max-width: 100%; height: auto; cursor: -webkit-zoom-in; box-sizing: border-box; padding: 3px; display: block !important" src="https://upload.wikimedia.org/math/2/2/e/22ebb2a58ea6d43753b1f5885530c114.png" border="0" /></a></p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">对于图像的原点矩而言：</p><ul style="list-style: none; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><li style="list-style: circle">M<span style="font-size: 12px; line-height: 0; position: relative; vertical-align: baseline; bottom: -0.25em">00</span>&nbsp;相当于权重系数为 1 。将所有 I(x, y) 相加，对于二值图像而言，相当于将每个点记为 1 然后求和，也就是图像的面积；对于灰度图像而言，则是图像的灰度值的和。</li><li style="list-style: circle">M<span style="font-size: 12px; line-height: 0; position: relative; vertical-align: baseline; bottom: -0.25em">10</span>&nbsp;相当于权重为 x 。对二值图像而言，相当于将所有的 x 坐标相加。</li><li style="list-style: circle">M<span style="font-size: 12px; line-height: 0; position: relative; vertical-align: baseline; bottom: -0.25em">01</span>&nbsp;相当于权重为 y 。对二值图像而言，相当于将所有的 y 坐标相加。</li><li style="list-style: circle">图像的几何中心（centroid）等于 (M<span style="font-size: 12px; line-height: 0; position: relative; vertical-align: baseline; bottom: -0.25em">10</span>&nbsp;/ M<span style="font-size: 12px; line-height: 0; position: relative; vertical-align: baseline; bottom: -0.25em">00</span>&nbsp;, M<span style="font-size: 12px; line-height: 0; position: relative; vertical-align: baseline; bottom: -0.25em">01</span>&nbsp;/ M<span style="font-size: 12px; line-height: 0; position: relative; vertical-align: baseline; bottom: -0.25em">00</span>)。</li></ul><h4 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; color: #555555; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/#central-moment" title="central moment" class="headerlink"></a>central moment</h4><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">图像的中心矩（central moment）是相对于几何中心的矩，公式为：</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="group" href="https://upload.wikimedia.org/math/0/7/e/07ee9a5a28d49bda17ea47ff4499b2fb.png" class="fancybox"><img style="border: 1px solid #dddddd; margin: 0px auto; max-width: 100%; height: auto; cursor: -webkit-zoom-in; box-sizing: border-box; padding: 3px; display: block !important" src="https://upload.wikimedia.org/math/0/7/e/07ee9a5a28d49bda17ea47ff4499b2fb.png" border="0" /></a></p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">可以看到，中心矩表现的是图像相对于几何中心的分布情况。一个通用的描述中心矩和原点矩关系的公式是：</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="group" href="https://upload.wikimedia.org/math/1/0/0/100a93ef0d9f869abe36164a0369f9fa.png" class="fancybox"><img style="border: 1px solid #dddddd; margin: 0px auto; max-width: 100%; height: auto; cursor: -webkit-zoom-in; box-sizing: border-box; padding: 3px; display: block !important" src="https://upload.wikimedia.org/math/1/0/0/100a93ef0d9f869abe36164a0369f9fa.png" border="0" /></a></p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">中心矩在图像处理中的一个应用便是寻找不变矩（invariant moments），这是一个高度浓缩的图像特征。</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">所谓的不变性有三种，分别对应图像处理中的三种仿射变换：</p><ul style="list-style: none; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><li style="list-style: circle">平移不变性（translation invariants）：中心矩本身就具有平移不变性，因为它是相对于自身的中心的分布统计，相当于是采用了相对坐标系，而平移改变的是整体坐标。</li><li style="list-style: circle">缩放不变性（scale invariants）：为了实现缩放不变性，可以构造一个规格化的中心矩，即将中心矩除以 (1+(i+j)/2) 阶的0阶中心矩，具体公式见 《<a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="https://en.wikipedia.org/wiki/Image_moment#Scale_invariants" target="_blank">Wiki: scale invariants</a>》。</li><li style="list-style: circle">旋转不变性（rotation invariants）：通过2阶和3阶的规格化中心矩可以构建7个不变矩组，构成的特征量具有旋转不变性。具体可以看 《<a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="https://en.wikipedia.org/wiki/Image_moment#Rotation_invariants" target="_blank">Wiki: rotation invariants</a>》。</li></ul><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">Hu moment 和 Zernike moment 之类的内容就不继续展开了，感兴趣的可以翻阅相关文章。</p><h2 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 20px; color: #555555; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/#OpenCV-QRCode" title="OpenCV + QRCode" class="headerlink"></a>OpenCV + QRCode</h2><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">接下来就是将 QRCode 和 OpenCV 结合起来的具体使用了。</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">初步构想的识别步骤如下：</p><ul style="list-style: none; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><li style="list-style: circle">加载图像，并且进行一些预处理，比如通过高斯模糊去噪。</li><li style="list-style: circle">通过 Canny 边缘检测算法，找出图像中的边缘</li><li style="list-style: circle">寻找边缘中的轮廓，将嵌套层数大于 4 的边缘找出，得到 Position Detection Pattern 。</li><li style="list-style: circle">如果上一步得到的结果不为 3 ，则通过 Timing Pattern 去除错误答案。</li><li style="list-style: circle">计算定位标记的最小矩形包围盒，获得三个最外围顶点，算出第四个顶点，从而确定二维码的区域。</li><li style="list-style: circle">计算定位标记的几何中心，连线组成三角形，从而修正坐标，得到仿射变换前的 QRCode 。</li></ul><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">在接下来的内容里，将会尝试用 OpenCV 识别下图中的二维码：</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="group" href="http://ww1.sinaimg.cn/large/61d238c7jw1f35ewx12r0j20zk0qo41q.jpg" class="fancybox"><img style="border: 1px solid #dddddd; margin: 0px auto; max-width: 100%; height: auto; cursor: -webkit-zoom-in; box-sizing: border-box; padding: 3px; display: block !important" src="http://ww1.sinaimg.cn/large/61d238c7jw1f35ewx12r0j20zk0qo41q.jpg" border="0" /></a></p><h3 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 18px; color: #555555; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/#加载图像" title="加载图像" class="headerlink"></a>加载图像</h3><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">首先加载图像，并通过&nbsp;matplotlib&nbsp;显示图像查看效果：</p><table border="0" style="border-collapse: collapse; border-spacing: 0px; margin: 0px; width: auto; border: none; font-size: 14px; table-layout: fixed"><tbody><tr style="background-color: #f9f9f9"><td class="code" style="padding: 0px; vertical-align: middle; border: none"><pre style="overflow: auto; font-family: consolas, Menlo, 'PingFang SC', 'Microsoft YaHei', monospace; font-size: 13px; margin-top: 0px; margin-bottom: 0px; padding: 1px; color: #4d4d4c; line-height: 1.6; border: none; background: #f7f7f7"><div class="line" style="height: 20px">%matplotlib inline</div><div class="line" style="height: 20px"><span style="color: #8959a8" class="keyword">import</span> cv2</div><div class="line" style="height: 20px"><span style="color: #8959a8" class="keyword">from</span> matplotlib <span style="color: #8959a8" class="keyword">import</span> pyplot <span style="color: #8959a8" class="keyword">as</span> plt</div><div class="line" style="height: 20px"><span style="color: #8959a8" class="keyword">import</span> numpy <span style="color: #8959a8" class="keyword">as</span> np</div><div class="line" style="height: 20px"><span style="color: #4271ae" class="function"><span style="color: #8959a8" class="keyword">def</span> <span style="color: #3e999f" class="title">show</span><span style="color: #f5871f" class="params">(img, code=cv2.COLOR_BGR2RGB)</span>:</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;cv_rgb = cv2.cvtColor(img, code)</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;fig, ax = plt.subplots(figsize=(<span style="color: #718c00" class="number">16</span>, <span style="color: #718c00" class="number">10</span>))</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;ax.imshow(cv_rgb)</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;fig.show()</div><div class="line" style="height: 20px">img = cv2.imread(<span style="color: #718c00" class="string">'1.jpg'</span>)</div><div class="line" style="height: 20px">show(img)</div></pre></td></tr></tbody></table><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">OpenCV 中默认是 BGR 通道，通过&nbsp;cvtColor&nbsp;函数将原图转换成灰度图：</p><table border="0" style="border-collapse: collapse; border-spacing: 0px; margin: 0px; width: auto; border: none; font-size: 14px; table-layout: fixed"><tbody><tr style="background-color: #f9f9f9"><td class="code" style="padding: 0px; vertical-align: middle; border: none"><pre style="overflow: auto; font-family: consolas, Menlo, 'PingFang SC', 'Microsoft YaHei', monospace; font-size: 13px; margin-top: 0px; margin-bottom: 0px; padding: 1px; color: #4d4d4c; line-height: 1.6; border: none; background: #f7f7f7"><div class="line" style="height: 20px">img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</div></pre></td></tr></tbody></table><h3 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 18px; color: #555555; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/#边缘检测" title="边缘检测" class="headerlink"></a>边缘检测</h3><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">有了灰度图之后，接下来用 Canny 边缘检测算法检测边缘。</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">Canny 边缘检测算法主要是以下几个步骤：</p><ul style="list-style: none; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><li style="list-style: circle">用高斯滤波器平滑图像去除噪声干扰（低通滤波器消除高频噪声）。</li><li style="list-style: circle">生成每个点的亮度梯度图（intensity gradients），以及亮度梯度的方向。</li><li style="list-style: circle">通过非极大值抑制（non-maximum suppression）缩小边缘宽度。非极大值抑制的意思是，只保留梯度方向上的极大值，删除其他非极大值，从而实现锐化的效果。</li><li style="list-style: circle">通过双阈值法（double threshold）寻找潜在边缘。大于高阈值为强边缘（strong edge），保留；小于低阈值则删除；不大不小的为弱边缘（weak edge），待定。</li><li style="list-style: circle">通过迟滞现象（Hysteresis）处理待定边缘。弱边缘有可能是边缘，也可能是噪音，判断标准是：如果一个弱边缘点附近的八个相邻点中，存在一个强边缘，则此弱边缘为强边缘，否则排除。</li></ul><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">在 OpenCV 中可以直接使用&nbsp;Canny&nbsp;函数，不过在那之前要先用&nbsp;GaussianBlur&nbsp;函数进行高斯模糊：</p><table border="0" style="border-collapse: collapse; border-spacing: 0px; margin: 0px; width: auto; border: none; font-size: 14px; table-layout: fixed"><tbody><tr style="background-color: #f9f9f9"><td class="code" style="padding: 0px; vertical-align: middle; border: none"><pre style="overflow: auto; font-family: consolas, Menlo, 'PingFang SC', 'Microsoft YaHei', monospace; font-size: 13px; margin-top: 0px; margin-bottom: 0px; padding: 1px; color: #4d4d4c; line-height: 1.6; border: none; background: #f7f7f7"><div class="line" style="height: 20px">img_gb = cv2.GaussianBlur(img_gray, (<span style="color: #718c00" class="number">5</span>, <span style="color: #718c00" class="number">5</span>), <span style="color: #718c00" class="number">0</span>)</div></pre></td></tr></tbody></table><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">接下来使用&nbsp;Canny&nbsp;函数检测边缘，选择 100 和 200 作为高低阈值：</p><table border="0" style="border-collapse: collapse; border-spacing: 0px; margin: 0px; width: auto; border: none; font-size: 14px; table-layout: fixed"><tbody><tr style="background-color: #f9f9f9"><td class="code" style="padding: 0px; vertical-align: middle; border: none"><pre style="overflow: auto; font-family: consolas, Menlo, 'PingFang SC', 'Microsoft YaHei', monospace; font-size: 13px; margin-top: 0px; margin-bottom: 0px; padding: 1px; color: #4d4d4c; line-height: 1.6; border: none; background: #f7f7f7"><div class="line" style="height: 20px">edges = cv2.Canny(img_gray, <span style="color: #718c00" class="number">100</span> , <span style="color: #718c00" class="number">200</span>)</div></pre></td></tr></tbody></table><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">执行结果如下：</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="group" href="http://ww1.sinaimg.cn/large/61d238c7jw1f35lyz7rmtj20lp0gfwgz.jpg" class="fancybox"><img style="border: 1px solid #dddddd; margin: 0px auto; max-width: 100%; height: auto; cursor: -webkit-zoom-in; box-sizing: border-box; padding: 3px; display: block !important" src="http://ww1.sinaimg.cn/large/61d238c7jw1f35lyz7rmtj20lp0gfwgz.jpg" border="0" /></a></p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">可以看到图像中的很多噪音都被处理掉了，只剩下了边缘部分。</p><h3 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 18px; color: #555555; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/#寻找定位标记" title="寻找定位标记" class="headerlink"></a>寻找定位标记</h3><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">有了边缘之后，接下来就是通过轮廓定位图像中的二维码。二维码的 Position Detection Pattern 在寻找轮廓之后，应该是有6层（因为一条边缘会被识别出两个轮廓，外轮廓和内轮廓）：</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="group" href="http://ww1.sinaimg.cn/large/61d238c7jw1f35n5f1l1qj218g0xcaei.jpg" class="fancybox"><img style="border: 1px solid #dddddd; margin: 0px auto; max-width: 100%; height: auto; cursor: -webkit-zoom-in; box-sizing: border-box; padding: 3px; display: block !important" src="http://ww1.sinaimg.cn/large/61d238c7jw1f35n5f1l1qj218g0xcaei.jpg" border="0" /></a></p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">所以，如果简单处理的话，只要遍历图像的层级关系，然后嵌套层数大于等于5的取出来就可以了：</p><table border="0" style="border-collapse: collapse; border-spacing: 0px; margin: 0px; width: auto; border: none; font-size: 14px; table-layout: fixed"><tbody><tr style="background-color: #f9f9f9"><td class="code" style="padding: 0px; vertical-align: middle; border: none"><pre style="overflow: auto; font-family: consolas, Menlo, 'PingFang SC', 'Microsoft YaHei', monospace; font-size: 13px; margin-top: 0px; margin-bottom: 0px; padding: 1px; color: #4d4d4c; line-height: 1.6; border: none; background: #f7f7f7"><div class="line" style="height: 20px">img_fc, contours, hierarchy = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)</div><div class="line" style="height: 20px">hierarchy = hierarchy[<span style="color: #718c00" class="number">0</span>]</div><div class="line" style="height: 20px">found = []</div><div class="line" style="height: 20px"><span style="color: #8959a8" class="keyword">for</span> i <span style="color: #8959a8" class="keyword">in</span> range(len(contours)):</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;k = i</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;c = <span style="color: #718c00" class="number">0</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8959a8" class="keyword">while</span> hierarchy[k][<span style="color: #718c00" class="number">2</span>] != <span style="color: #718c00" class="number">-1</span>:</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;k = hierarchy[k][<span style="color: #718c00" class="number">2</span>]</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;c = c + <span style="color: #718c00" class="number">1</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8959a8" class="keyword">if</span> c &gt;= <span style="color: #718c00" class="number">5</span>:</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;found.append(i)</div><div class="line" style="height: 20px"><span style="color: #8959a8" class="keyword">for</span> i <span style="color: #8959a8" class="keyword">in</span> found:</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;img_dc = img.copy()</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;cv2.drawContours(img_dc, contours, i, (<span style="color: #718c00" class="number">0</span>, <span style="color: #718c00" class="number">255</span>, <span style="color: #718c00" class="number">0</span>), <span style="color: #718c00" class="number">3</span>)</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;show(img_dc)</div></pre></td></tr></tbody></table><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">绘制结果如下：</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="group" href="http://ww2.sinaimg.cn/large/61d238c7jw1f35new9doej20lp0gfgpp.jpg" class="fancybox"><img style="border: 1px solid #dddddd; margin: 0px auto; max-width: 100%; height: auto; cursor: -webkit-zoom-in; box-sizing: border-box; padding: 3px; display: block !important" src="http://ww2.sinaimg.cn/large/61d238c7jw1f35new9doej20lp0gfgpp.jpg" border="0" /></a><br /><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="group" href="http://ww4.sinaimg.cn/large/61d238c7jw1f35nf2m0d4j20lp0gfae5.jpg" class="fancybox"><img style="border: 1px solid #dddddd; margin: 0px auto; max-width: 100%; height: auto; cursor: -webkit-zoom-in; box-sizing: border-box; padding: 3px; display: block !important" src="http://ww4.sinaimg.cn/large/61d238c7jw1f35nf2m0d4j20lp0gfae5.jpg" border="0" /></a><br /><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="group" href="http://ww2.sinaimg.cn/large/61d238c7jw1f35nf83semj20lp0gfn19.jpg" class="fancybox"><img style="border: 1px solid #dddddd; margin: 0px auto; max-width: 100%; height: auto; cursor: -webkit-zoom-in; box-sizing: border-box; padding: 3px; display: block !important" src="http://ww2.sinaimg.cn/large/61d238c7jw1f35nf83semj20lp0gfn19.jpg" border="0" /></a><br /><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="group" href="http://ww1.sinaimg.cn/large/61d238c7jw1f35nfczlvmj20lp0gf78d.jpg" class="fancybox"><img style="border: 1px solid #dddddd; margin: 0px auto; max-width: 100%; height: auto; cursor: -webkit-zoom-in; box-sizing: border-box; padding: 3px; display: block !important" src="http://ww1.sinaimg.cn/large/61d238c7jw1f35nfczlvmj20lp0gf78d.jpg" border="0" /></a></p><h3 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 18px; color: #555555; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/#定位筛选" title="定位筛选" class="headerlink"></a>定位筛选</h3><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">接下来就是把所有找到的定位标记进行筛选。如果刚好找到三个那就可以直接跳过这一步了。然而，因为这张图比较特殊，找出了四个定位标记，所以需要排除一个错误答案。</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">讲真，如果只靠三个 Position Detection Pattern 组成的直角三角形，是没办法从这四个当中排除错误答案的。因为，一方面会有形变的影响，比如斜躺着的二维码，本身三个顶点连线就不是直角三角形；另一方面，极端情况下，多余的那个标记如果位置比较凑巧的话，完全和正确结果一模一样，比如下面这种情况：</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="group" href="http://ww4.sinaimg.cn/large/61d238c7gw1f36r76ershj214l0l3abg.jpg" class="fancybox"><img style="border: 1px solid #dddddd; margin: 0px auto; max-width: 100%; height: auto; cursor: -webkit-zoom-in; box-sizing: border-box; padding: 3px; display: block !important" src="http://ww4.sinaimg.cn/large/61d238c7gw1f36r76ershj214l0l3abg.jpg" border="0" /></a></p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">所以我们需要 Timing Pattern 的帮助，也就是定位标记之间的黑白相间的那两条黑白相间的线。解决思路大致如下：</p><ul style="list-style: none; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><li style="list-style: circle">将4个定位标记两两配对</li><li style="list-style: circle">将他们的4个顶点两两连线，选出最短的那两根</li><li style="list-style: circle">如果两根线都不符合 Timing Pattern 的特征，则出局</li></ul><h4 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; color: #555555; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/#寻找定位标记的顶点" title="寻找定位标记的顶点" class="headerlink"></a>寻找定位标记的顶点</h4><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">找的的定位标记是一个轮廓结果，由许多像素点组成。如果想找到定位标记的顶点，则需要找到定位标记的矩形包围盒。先通过minAreaRect&nbsp;函数将检查到的轮廓转换成最小矩形包围盒，并且绘制出来：</p><table border="0" style="border-collapse: collapse; border-spacing: 0px; margin: 0px; width: auto; border: none; font-size: 14px; table-layout: fixed"><tbody><tr style="background-color: #f9f9f9"><td class="code" style="padding: 0px; vertical-align: middle; border: none"><pre style="overflow: auto; font-family: consolas, Menlo, 'PingFang SC', 'Microsoft YaHei', monospace; font-size: 13px; margin-top: 0px; margin-bottom: 0px; padding: 1px; color: #4d4d4c; line-height: 1.6; border: none; background: #f7f7f7"><div class="line" style="height: 20px">draw_img = img.copy()</div><div class="line" style="height: 20px"><span style="color: #8959a8" class="keyword">for</span> i <span style="color: #8959a8" class="keyword">in</span> found:</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;rect = cv2.minAreaRect(contours[i])</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;box = cv2.boxPoints(rect)</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;box = np.int0(box)</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;cv2.drawContours(draw_img,[box], <span style="color: #718c00" class="number">0</span>, (<span style="color: #718c00" class="number">0</span>,<span style="color: #718c00" class="number">0</span>,<span style="color: #718c00" class="number">255</span>), <span style="color: #718c00" class="number">2</span>)</div><div class="line" style="height: 20px">show(draw_img)</div></pre></td></tr></tbody></table><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">绘制如下：</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="group" href="http://ww2.sinaimg.cn/large/61d238c7gw1f35tm4ybi3j20lp0gfdk1.jpg" class="fancybox"><img style="border: 1px solid #dddddd; margin: 0px auto; max-width: 100%; height: auto; cursor: -webkit-zoom-in; box-sizing: border-box; padding: 3px; display: block !important" src="http://ww2.sinaimg.cn/large/61d238c7gw1f35tm4ybi3j20lp0gfdk1.jpg" border="0" /></a></p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">这个矩形包围盒的四个坐标点就是顶点，将它存储在 boxes 中：</p><table border="0" style="border-collapse: collapse; border-spacing: 0px; margin: 0px; width: auto; border: none; font-size: 14px; table-layout: fixed"><tbody><tr style="background-color: #f9f9f9"><td class="code" style="padding: 0px; vertical-align: middle; border: none"><pre style="overflow: auto; font-family: consolas, Menlo, 'PingFang SC', 'Microsoft YaHei', monospace; font-size: 13px; margin-top: 0px; margin-bottom: 0px; padding: 1px; color: #4d4d4c; line-height: 1.6; border: none; background: #f7f7f7"><div class="line" style="height: 20px">boxes = []</div><div class="line" style="height: 20px"><span style="color: #8959a8" class="keyword">for</span> i <span style="color: #8959a8" class="keyword">in</span> found:</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;rect = cv2.minAreaRect(contours[i])</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;box = cv2.boxPoints(rect)</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;box = np.int0(box)</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;box = map(tuple, box)</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;boxes.append(box)</div></pre></td></tr></tbody></table><h4 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; color: #555555; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/#定位标记的顶点连线" title="定位标记的顶点连线" class="headerlink"></a>定位标记的顶点连线</h4><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">接下来先遍历所有顶点连线，然后从中选择最短的两根，并将它们绘制出来：</p><table border="0" style="border-collapse: collapse; border-spacing: 0px; margin: 0px; width: auto; border: none; font-size: 14px; table-layout: fixed"><tbody><tr style="background-color: #f9f9f9"><td class="code" style="padding: 0px; vertical-align: middle; border: none"><pre style="overflow: auto; font-family: consolas, Menlo, 'PingFang SC', 'Microsoft YaHei', monospace; font-size: 13px; margin-top: 0px; margin-bottom: 0px; padding: 1px; color: #4d4d4c; line-height: 1.6; border: none; background: #f7f7f7"><div class="line" style="height: 20px"><span style="color: #4271ae" class="function"><span style="color: #8959a8" class="keyword">def</span> <span style="color: #3e999f" class="title">cv_distance</span><span style="color: #f5871f" class="params">(P, Q)</span>:</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8959a8" class="keyword">return</span> int(math.sqrt(pow((P[<span style="color: #718c00" class="number">0</span>] - Q[<span style="color: #718c00" class="number">0</span>]), <span style="color: #718c00" class="number">2</span>) + pow((P[<span style="color: #718c00" class="number">1</span>] - Q[<span style="color: #718c00" class="number">1</span>]),<span style="color: #718c00" class="number">2</span>)))</div><div class="line" style="height: 20px"><span style="color: #4271ae" class="function"><span style="color: #8959a8" class="keyword">def</span> <span style="color: #3e999f" class="title">check</span><span style="color: #f5871f" class="params">(a, b)</span>:</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8e908c" class="comment"># 存储 ab 数组里最短的两点的组合</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;s1_ab = ()</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;s2_ab = ()</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8e908c" class="comment"># 存储 ab 数组里最短的两点的距离，用于比较</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;s1 = np.iinfo(<span style="color: #718c00" class="string">'i'</span>).max</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;s2 = s1</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8959a8" class="keyword">for</span> ai <span style="color: #8959a8" class="keyword">in</span> a:</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8959a8" class="keyword">for</span> bi <span style="color: #8959a8" class="keyword">in</span> b:</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;d = cv_distance(ai, bi)</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8959a8" class="keyword">if</span> d &lt; s2:</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8959a8" class="keyword">if</span> d &lt; s1:</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;s1_ab, s2_ab = (ai, bi), s1_ab</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;s1, s2 = d, s1</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8959a8" class="keyword">else</span>:</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;s2_ab = (ai, bi)</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;s2 = d&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;a1, a2 = s1_ab[<span style="color: #718c00" class="number">0</span>], s2_ab[<span style="color: #718c00" class="number">0</span>]</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;b1, b2 = s1_ab[<span style="color: #718c00" class="number">1</span>], s2_ab[<span style="color: #718c00" class="number">1</span>]</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8e908c" class="comment"># 将最短的两个线画出来</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;cv2.line(draw_img, a1, b1, (<span style="color: #718c00" class="number">0</span>,<span style="color: #718c00" class="number">0</span>,<span style="color: #718c00" class="number">255</span>), <span style="color: #718c00" class="number">3</span>)</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;cv2.line(draw_img, a2, b2, (<span style="color: #718c00" class="number">0</span>,<span style="color: #718c00" class="number">0</span>,<span style="color: #718c00" class="number">255</span>), <span style="color: #718c00" class="number">3</span>)</div><div class="line" style="height: 20px"><span style="color: #8959a8" class="keyword">for</span> i <span style="color: #8959a8" class="keyword">in</span> range(len(boxes)):</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8959a8" class="keyword">for</span> j <span style="color: #8959a8" class="keyword">in</span> range(i+<span style="color: #718c00" class="number">1</span>, len(boxes)):</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;check(boxes[i], boxes[j])</div><div class="line" style="height: 20px">show(draw_img)</div></pre></td></tr></tbody></table><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">绘制结果如下：</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="group" href="http://ww1.sinaimg.cn/large/61d238c7gw1f36hijarwkj20lp0gf439.jpg" class="fancybox"><img style="border: 1px solid #dddddd; margin: 0px auto; max-width: 100%; height: auto; cursor: -webkit-zoom-in; box-sizing: border-box; padding: 3px; display: block !important" src="http://ww1.sinaimg.cn/large/61d238c7gw1f36hijarwkj20lp0gf439.jpg" border="0" /></a></p><h4 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; color: #555555; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/#获取连线上的像素值" title="获取连线上的像素值" class="headerlink"></a>获取连线上的像素值</h4><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">有了端点连线，接下来需要获取连线上的像素值，以便后面判断是否是 Timing Pattern 。</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">在这之前，为了更方便的判断黑白相间的情况，先对图像进行二值化：</p><table border="0" style="border-collapse: collapse; border-spacing: 0px; margin: 0px; width: auto; border: none; font-size: 14px; table-layout: fixed"><tbody><tr style="background-color: #f9f9f9"><td class="code" style="padding: 0px; vertical-align: middle; border: none"><pre style="overflow: auto; font-family: consolas, Menlo, 'PingFang SC', 'Microsoft YaHei', monospace; font-size: 13px; margin-top: 0px; margin-bottom: 0px; padding: 1px; color: #4d4d4c; line-height: 1.6; border: none; background: #f7f7f7"><div class="line" style="height: 20px">th, bi_img = cv2.threshold(img_gray, <span style="color: #718c00" class="number">100</span>, <span style="color: #718c00" class="number">255</span>, cv2.THRESH_BINARY)</div></pre></td></tr></tbody></table><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">接下来是获取连线像素值。由于 OpenCV3 的 Python 库中没有&nbsp;LineIterator&nbsp;，只好自己写一个。在《<a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="http://stackoverflow.com/a/32857432/3812779" target="_blank">OpenCV 3.0 Python LineIterator</a>》这个问答里找到了可用的直线遍历函数，可以直接使用。</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">以一条 Timing Pattern 为例：</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="group" href="http://ww1.sinaimg.cn/large/61d238c7gw1f36laln556j20lp0gfdjw.jpg" class="fancybox"><img style="border: 1px solid #dddddd; margin: 0px auto; max-width: 100%; height: auto; cursor: -webkit-zoom-in; box-sizing: border-box; padding: 3px; display: block !important" src="http://ww1.sinaimg.cn/large/61d238c7gw1f36laln556j20lp0gfdjw.jpg" border="0" /></a></p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">打印其像素点看下结果：</p><table border="0" style="border-collapse: collapse; border-spacing: 0px; margin: 0px; width: auto; border: none; font-size: 14px; table-layout: fixed"><tbody><tr style="background-color: #f9f9f9"><td class="code" style="padding: 0px; vertical-align: middle; border: none"><pre style="overflow: auto; font-family: consolas, Menlo, 'PingFang SC', 'Microsoft YaHei', monospace; font-size: 13px; margin-top: 0px; margin-bottom: 0px; padding: 1px; color: #4d4d4c; line-height: 1.6; border: none; background: #f7f7f7"><div class="line" style="height: 20px">[ <span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>]</div></pre></td></tr></tbody></table><h4 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; color: #555555; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/#修正端点位置" title="修正端点位置" class="headerlink"></a>修正端点位置</h4><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">照理说， Timing Pattern 的连线，像素值应该是黑白均匀相间才对，为什么是上面的这种一连一大片的结果呢？</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">仔细看下截图可以发现，由于取的是定位标记的外部包围盒的顶点，所以因为误差会超出定位标记的范围，导致没能正确定位到 Timing Pattern ，而是相邻的 Data 部分的像素点。</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">为了修正这部分误差，我们可以对端点坐标进行调整。因为 Position Detection Pattern 的大小是固定的，是一个 1-1-3-1-1 的黑白黑白黑相间的正方形，识别 Timing Pattern 的最佳端点应该是最靠里的黑色区域的中心位置，也就是图中的绿色虚线部分：</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="group" href="http://ww2.sinaimg.cn/large/61d238c7gw1f36lht551bj214l0l3jto.jpg" class="fancybox"><img style="border: 1px solid #dddddd; margin: 0px auto; max-width: 100%; height: auto; cursor: -webkit-zoom-in; box-sizing: border-box; padding: 3px; display: block !important" src="http://ww2.sinaimg.cn/large/61d238c7gw1f36lht551bj214l0l3jto.jpg" border="0" /></a></p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">所以我们需要对端点坐标进行调整。调整方式是，将一个端点的 x 和 y 值向另一个端点的 x 和 y 值靠近 1/14 个单位距离，代码如下：</p><table border="0" style="border-collapse: collapse; border-spacing: 0px; margin: 0px; width: auto; border: none; font-size: 14px; table-layout: fixed"><tbody><tr style="background-color: #f9f9f9"><td class="code" style="padding: 0px; vertical-align: middle; border: none"><pre style="overflow: auto; font-family: consolas, Menlo, 'PingFang SC', 'Microsoft YaHei', monospace; font-size: 13px; margin-top: 0px; margin-bottom: 0px; padding: 1px; color: #4d4d4c; line-height: 1.6; border: none; background: #f7f7f7"><div class="line" style="height: 20px">a1 = (a1[<span style="color: #718c00" class="number">0</span>] + (a2[<span style="color: #718c00" class="number">0</span>]-a1[<span style="color: #718c00" class="number">0</span>])*<span style="color: #718c00" class="number">1</span>/<span style="color: #718c00" class="number">14</span>, a1[<span style="color: #718c00" class="number">1</span>] + (a2[<span style="color: #718c00" class="number">1</span>]-a1[<span style="color: #718c00" class="number">1</span>])*<span style="color: #718c00" class="number">1</span>/<span style="color: #718c00" class="number">14</span>)</div><div class="line" style="height: 20px">b1 = (b1[<span style="color: #718c00" class="number">0</span>] + (b2[<span style="color: #718c00" class="number">0</span>]-b1[<span style="color: #718c00" class="number">0</span>])*<span style="color: #718c00" class="number">1</span>/<span style="color: #718c00" class="number">14</span>, b1[<span style="color: #718c00" class="number">1</span>] + (b2[<span style="color: #718c00" class="number">1</span>]-b1[<span style="color: #718c00" class="number">1</span>])*<span style="color: #718c00" class="number">1</span>/<span style="color: #718c00" class="number">14</span>)</div><div class="line" style="height: 20px">a2 = (a2[<span style="color: #718c00" class="number">0</span>] + (a1[<span style="color: #718c00" class="number">0</span>]-a2[<span style="color: #718c00" class="number">0</span>])*<span style="color: #718c00" class="number">1</span>/<span style="color: #718c00" class="number">14</span>, a2[<span style="color: #718c00" class="number">1</span>] + (a1[<span style="color: #718c00" class="number">1</span>]-a2[<span style="color: #718c00" class="number">1</span>])*<span style="color: #718c00" class="number">1</span>/<span style="color: #718c00" class="number">14</span>)</div><div class="line" style="height: 20px">b2 = (b2[<span style="color: #718c00" class="number">0</span>] + (b1[<span style="color: #718c00" class="number">0</span>]-b2[<span style="color: #718c00" class="number">0</span>])*<span style="color: #718c00" class="number">1</span>/<span style="color: #718c00" class="number">14</span>, b2[<span style="color: #718c00" class="number">1</span>] + (b1[<span style="color: #718c00" class="number">1</span>]-b2[<span style="color: #718c00" class="number">1</span>])*<span style="color: #718c00" class="number">1</span>/<span style="color: #718c00" class="number">14</span>)</div></pre></td></tr></tbody></table><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">调整之后的像素值就是正确的 Timing Pattern 了：</p><table border="0" style="border-collapse: collapse; border-spacing: 0px; margin: 0px; width: auto; border: none; font-size: 14px; table-layout: fixed"><tbody><tr style="background-color: #f9f9f9"><td class="code" style="padding: 0px; vertical-align: middle; border: none"><pre style="overflow: auto; font-family: consolas, Menlo, 'PingFang SC', 'Microsoft YaHei', monospace; font-size: 13px; margin-top: 0px; margin-bottom: 0px; padding: 1px; color: #4d4d4c; line-height: 1.6; border: none; background: #f7f7f7"><div class="line" style="height: 20px">[ <span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #718c00" class="number">0.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>&nbsp;&nbsp;<span style="color: #718c00" class="number">255.</span>]</div></pre></td></tr></tbody></table><h4 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; color: #555555; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/#验证是否是-Timing-Pattern" title="验证是否是 Timing Pattern" class="headerlink"></a>验证是否是 Timing Pattern</h4><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">像素序列拿到了，接下来就是判断它是否是 Timing Pattern 了。 Timing Pattern 的特征是黑白均匀相间，所以每段同色区域的计数结果应该相同，而且旋转拉伸平移都不会影响这个特征。</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">于是，验证方案是：</p><ul style="list-style: none; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><li style="list-style: circle">先除去数组中开头和结尾处连续的白色像素点。</li><li style="list-style: circle">对数组中的元素进行计数，相邻的元素如果值相同则合并到计数结果中。比如 [0,1,1,1,0,0] 的计数结果就是 [1,3,2] 。</li><li style="list-style: circle">计数数组的长度如果小于 5 ，则不是 Timing Pattern 。</li><li style="list-style: circle">计算计数数组的方差，看看分布是否离散，如果方差大于阈值，则不是 Timing Pattern 。</li></ul><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">代码如下：</p><table border="0" style="border-collapse: collapse; border-spacing: 0px; margin: 0px; width: auto; border: none; font-size: 14px; table-layout: fixed"><tbody><tr style="background-color: #f9f9f9"><td class="code" style="padding: 0px; vertical-align: middle; border: none"><pre style="overflow: auto; font-family: consolas, Menlo, 'PingFang SC', 'Microsoft YaHei', monospace; font-size: 13px; margin-top: 0px; margin-bottom: 0px; padding: 1px; color: #4d4d4c; line-height: 1.6; border: none; background: #f7f7f7"><div class="line" style="height: 20px"><span style="color: #4271ae" class="function"><span style="color: #8959a8" class="keyword">def</span> <span style="color: #3e999f" class="title">isTimingPattern</span><span style="color: #f5871f" class="params">(line)</span>:</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8e908c" class="comment"># 除去开头结尾的白色像素点</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8959a8" class="keyword">while</span> line[<span style="color: #718c00" class="number">0</span>] != <span style="color: #718c00" class="number">0</span>:</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;line = line[<span style="color: #718c00" class="number">1</span>:]</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8959a8" class="keyword">while</span> line[<span style="color: #718c00" class="number">-1</span>] != <span style="color: #718c00" class="number">0</span>:</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;line = line[:<span style="color: #718c00" class="number">-1</span>]</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8e908c" class="comment"># 计数连续的黑白像素点</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;c = []</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;count = <span style="color: #718c00" class="number">1</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;l = line[<span style="color: #718c00" class="number">0</span>]</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8959a8" class="keyword">for</span> p <span style="color: #8959a8" class="keyword">in</span> line[<span style="color: #718c00" class="number">1</span>:]:</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8959a8" class="keyword">if</span> p == l:</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;count = count + <span style="color: #718c00" class="number">1</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8959a8" class="keyword">else</span>:</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;c.append(count)</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;count = <span style="color: #718c00" class="number">1</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;l = p</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;c.append(count)</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8e908c" class="comment"># 如果黑白间隔太少，直接排除</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8959a8" class="keyword">if</span> len(c) &lt; <span style="color: #718c00" class="number">5</span>:</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8959a8" class="keyword">return</span> <span style="color: #8959a8" class="keyword">False</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8e908c" class="comment"># 计算方差，根据离散程度判断是否是 Timing Pattern</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;threshold = <span style="color: #718c00" class="number">5</span></div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8959a8" class="keyword">return</span> np.var(c) &lt; threshold</div></pre></td></tr></tbody></table><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">对前面的那条连线检测一下，计数数组为：</p><table border="0" style="border-collapse: collapse; border-spacing: 0px; margin: 0px; width: auto; border: none; font-size: 14px; table-layout: fixed"><tbody><tr style="background-color: #f9f9f9"><td class="code" style="padding: 0px; vertical-align: middle; border: none"><pre style="overflow: auto; font-family: consolas, Menlo, 'PingFang SC', 'Microsoft YaHei', monospace; font-size: 13px; margin-top: 0px; margin-bottom: 0px; padding: 1px; color: #4d4d4c; line-height: 1.6; border: none; background: #f7f7f7"><div class="line" style="height: 20px">[<span style="color: #718c00" class="number">11</span>, <span style="color: #718c00" class="number">12</span>, <span style="color: #718c00" class="number">11</span>, <span style="color: #718c00" class="number">12</span>, <span style="color: #718c00" class="number">11</span>, <span style="color: #718c00" class="number">12</span>, <span style="color: #718c00" class="number">11</span>, <span style="color: #718c00" class="number">13</span>, <span style="color: #718c00" class="number">11</span>]</div></pre></td></tr></tbody></table><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">方差为 0.47 。其他非 Timing Pattern 的连线方差均大于 10 。</p><h4 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; color: #555555; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/#找出错误的定位标记" title="找出错误的定位标记" class="headerlink"></a>找出错误的定位标记</h4><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">接下来就是利用前面的结果除去错误的定位标记了，只要两个定位标记的端点连线中能找到 Timing Pattern ，则这两个定位标记有效，把它们存进 set 里：</p><table border="0" style="border-collapse: collapse; border-spacing: 0px; margin: 0px; width: auto; border: none; font-size: 14px; table-layout: fixed"><tbody><tr style="background-color: #f9f9f9"><td class="code" style="padding: 0px; vertical-align: middle; border: none"><pre style="overflow: auto; font-family: consolas, Menlo, 'PingFang SC', 'Microsoft YaHei', monospace; font-size: 13px; margin-top: 0px; margin-bottom: 0px; padding: 1px; color: #4d4d4c; line-height: 1.6; border: none; background: #f7f7f7"><div class="line" style="height: 20px">valid = set()</div><div class="line" style="height: 20px"><span style="color: #8959a8" class="keyword">for</span> i <span style="color: #8959a8" class="keyword">in</span> range(len(boxes)):</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8959a8" class="keyword">for</span> j <span style="color: #8959a8" class="keyword">in</span> range(i+<span style="color: #718c00" class="number">1</span>, len(boxes)):</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8959a8" class="keyword">if</span> check(boxes[i], boxes[j]):</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;valid.add(i)</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;valid.add(j)</div><div class="line" style="height: 20px"><span style="color: #8959a8" class="keyword">print</span> valid</div></pre></td></tr></tbody></table><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">结果是：</p><table border="0" style="border-collapse: collapse; border-spacing: 0px; margin: 0px; width: auto; border: none; font-size: 14px; table-layout: fixed"><tbody><tr style="background-color: #f9f9f9"><td class="code" style="padding: 0px; vertical-align: middle; border: none"><pre style="overflow: auto; font-family: consolas, Menlo, 'PingFang SC', 'Microsoft YaHei', monospace; font-size: 13px; margin-top: 0px; margin-bottom: 0px; padding: 1px; color: #4d4d4c; line-height: 1.6; border: none; background: #f7f7f7"><div class="line" style="height: 20px">set([<span style="color: #718c00" class="number">1</span>, <span style="color: #718c00" class="number">2</span>, <span style="color: #718c00" class="number">3</span>])</div></pre></td></tr></tbody></table><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">好了，它们中出了一个叛徒，0、1、2、3 四个定位标记，0是无效的，1、2、3 才是需要识别的 QRCode 的定位标记。</p><h3 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 18px; color: #555555; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/#找出二维码" title="找出二维码" class="headerlink"></a>找出二维码</h3><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">有了定位标记之后，找出二维码就轻而易举了。只要找出三个定位标记轮廓的最小矩形包围盒，那就是二维码的位置了：</p><table border="0" style="border-collapse: collapse; border-spacing: 0px; margin: 0px; width: auto; border: none; font-size: 14px; table-layout: fixed"><tbody><tr style="background-color: #f9f9f9"><td class="code" style="padding: 0px; vertical-align: middle; border: none"><pre style="overflow: auto; font-family: consolas, Menlo, 'PingFang SC', 'Microsoft YaHei', monospace; font-size: 13px; margin-top: 0px; margin-bottom: 0px; padding: 1px; color: #4d4d4c; line-height: 1.6; border: none; background: #f7f7f7"><div class="line" style="height: 20px">contour_all = np.array([])</div><div class="line" style="height: 20px"><span style="color: #8959a8" class="keyword">while</span> len(valid) &gt; <span style="color: #718c00" class="number">0</span>:</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;c = found[valid.pop()]</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8959a8" class="keyword">for</span> sublist <span style="color: #8959a8" class="keyword">in</span> c:</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color: #8959a8" class="keyword">for</span> p <span style="color: #8959a8" class="keyword">in</span> sublist:</div><div class="line" style="height: 20px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;contour_all.append(p)</div><div class="line" style="height: 20px">rect = cv2.minAreaRect(contour_ALL)</div><div class="line" style="height: 20px">box = cv2.boxPoints(rect)</div><div class="line" style="height: 20px">box = np.array(box)</div><div class="line" style="height: 20px">draw_img = img.copy()</div><div class="line" style="height: 20px">cv2.polylines(draw_img, np.int32([box]), <span style="color: #8959a8" class="keyword">True</span>, (<span style="color: #718c00" class="number">0</span>, <span style="color: #718c00" class="number">0</span>, <span style="color: #718c00" class="number">255</span>), <span style="color: #718c00" class="number">10</span>)</div><div class="line" style="height: 20px">show(draw_img)</div></pre></td></tr></tbody></table><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">绘制结果如下：</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="group" href="http://ww4.sinaimg.cn/large/61d238c7gw1f36q0l76joj20lp0gf0wz.jpg" class="fancybox"><img style="border: 1px solid #dddddd; margin: 0px auto; max-width: 100%; height: auto; cursor: -webkit-zoom-in; box-sizing: border-box; padding: 3px; display: block !important" src="http://ww4.sinaimg.cn/large/61d238c7gw1f36q0l76joj20lp0gf0wz.jpg" border="0" /></a></p><h2 style="margin: 20px 0px 15px; padding: 10px 0px 0px; line-height: 1.5; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 20px; color: #555555; text-align: justify"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/#小结" title="小结" class="headerlink"></a>小结</h2><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">后面仿射变换后坐标修正的问题实在是写不动了，这篇就先到这里吧。</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">回头看看，是不是感觉绕了个大圈子？</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">『费了半天劲，只是为了告诉我第0个定位标记是无效的，我看图也看出来了啊！』</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">是的，不过代码里能看到的只是像素值和它们的坐标，为了排除这个错误答案确实花了不少功夫。</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">不过这也是我喜欢做数字图像处理的原因之一：可用函数数不胜数，专业概念层出不穷，同样的一个问题，不同的人去解决，就有着不同的答案，交流的过程便是学习的过程。</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">啊对了，如果有更好的解决方案，欢迎在评论里指出！</p><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">以及，文章里有一个红包彩蛋，你找到了吗 =。=</p><blockquote style="margin: 0px; padding: 0px 15px; color: #666666; border-left-width: 4px; border-left-style: solid; border-left-color: #dddddd; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><p style="margin: 0px 0px 25px">财富！名誉！地位！穷得叮当响的海贼汪，哥尔&middot;D&middot;汪海，他在临睡前的一句话让人们趋之若鹜奔向博客：『想要我的红包吗？想要的话可以全部给你，去找吧！我把所有红包都放在那里！』</p></blockquote><hr style="box-sizing: content-box; height: 3px; margin: 40px 0px; border: none; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify; background-image: repeating-linear-gradient(-45deg, rgb(255, 255, 255), rgb(255, 255, 255) 4px, transparent 4px, transparent 8px); background-color: #dddddd" /><p style="margin: 0px 0px 25px; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify">参考文献：</p><ul style="list-style: none; color: #555555; font-family: Lato, 'PingFang SC', 'Microsoft YaHei', sans-serif; font-size: 16px; line-height: 32px; text-align: justify"><li style="list-style: circle"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="http://coolshell.cn/articles/10590.html" target="_blank">二维码的生成细节和原理</a></li><li style="list-style: circle"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="http://www.keyence.com/ss/products/auto_id/barcode_lecture/basic_2d/qr/" target="_blank">What is a QR code?</a></li><li style="list-style: circle"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="http://www.swisseduc.ch/informatik/theoretische_informatik/qr_codes/docs/qr_standard.pdf" target="_blank">ISO/IEC 18004: QRCode Standard</a></li><li style="list-style: circle"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="http://qrcode.meetheed.com/question14.php" target="_blank">What Are The Different Sections In A QR Code?</a></li><li style="list-style: circle"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="http://blog.qartis.com/decoding-small-qr-codes-by-hand/" target="_blank">Decoding small QR codes by hand</a></li><li style="list-style: circle"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="http://www.explainthatstuff.com/how-data-matrix-codes-work.html" target="_blank">How data matrix codes work</a></li><li style="list-style: circle"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="http://www.thonky.com/qr-code-tutorial/" target="_blank">QR Code Tutorial</a></li><li style="list-style: circle"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="http://www.ams.org/samplings/feature-column/fc-2013-02" target="_blank">How to Read QR Symbols Without Your Mobile Telephone</a></li><li style="list-style: circle"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="http://dsynflo.blogspot.sg/2014/10/opencv-qr-code-detection-and-extraction.html" target="_blank">OpenCV: QRCode detection and extraction</a></li><li style="list-style: circle"><a style="color: #222222; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #222222; word-wrap: break-word; outline: 0px; background-color: transparent" rel="external" href="http://docs.opencv.org/3.1.0/d9/d8b/tutorial_py_contours_hierarchy.html" target="_blank">Tutorial Python: Contours Hierarchy</a></li><li style="list-style: circle"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="https://en.wikipedia.org/wiki/Pixel_connectivity" target="_blank">Wiki: Pixel Connectivity</a></li><li style="list-style: circle"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="https://www.cs.auckland.ac.nz/courses/compsci773s1c/lectures/ImageProcessing-html/topic3.htm#connect" target="_blank">Image Processing: Connect</a></li><li style="list-style: circle"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="https://en.wikipedia.org/wiki/Image_moment" target="_blank">Wiki: Image Moment</a></li><li style="list-style: circle"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="https://en.wikipedia.org/wiki/Moment_(mathematics" target="_blank">Wiki: Moment (Mathematics)</a>)</li><li style="list-style: circle"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="http://www.cnblogs.com/ronny/p/3985810.html" target="_blank">图像的矩特征</a></li><li style="list-style: circle"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="http://netclass.csu.edu.cn/NCourse/hep120/kj/3-3-1.htm" target="_blank">统计数据的形态特征</a></li><li style="list-style: circle"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="http://www.luohanjie.com/tech/%E5%9B%BE%E5%83%8F%E7%9A%84%E7%9F%A9-image-moments/" target="_blank">图像的矩（Image Moments）</a></li><li style="list-style: circle"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="http://docs.opencv.org/2.4/modules/imgproc/doc/structural_analysis_and_shape_descriptors.html" target="_blank">OpenCV Doc: Structural analysis and shape descriptors</a></li><li style="list-style: circle"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="http://www.sci.utah.edu/~gerig/CS7960-S2010/handouts/CS7960-AdvImProc-MomentInvariants.pdf" target="_blank">CS7960 AdvImProc MomentInvariants</a></li><li style="list-style: circle"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="http://docs.opencv.org/3.1.0/da/d22/tutorial_py_canny.html" target="_blank">OpenCV Doc: Canny</a></li><li style="list-style: circle"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="https://en.wikipedia.org/wiki/Canny_edge_detector" target="_blank">Wiki: Canny Edge Detector</a></li><li style="list-style: circle"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="https://en.wikipedia.org/wiki/Hysteresis" target="_blank">Wiki: Hysteresis</a></li><li style="list-style: circle"><a style="color: #555555; text-decoration: none; border-bottom-width: 1px; border-bottom-style: solid; border-bottom-color: #999999; word-wrap: break-word; background-color: transparent" rel="external" href="http://stackoverflow.com/a/32857432/3812779" target="_blank">OpenCV 3.0 Python LineIterator</a></li></ul>
]]>
</description>
</item><item>
<link>http://i.renjihe.com/blog/read.php?7423</link>
<title><![CDATA[AR 开发小记]]></title> 
<author>renjihe1988 &lt;admin@yourname.com&gt;</author>
<category><![CDATA[AR&amp;AI&amp;模式识别]]></category>
<pubDate>Wed, 27 Jul 2016 06:35:37 +0000</pubDate> 
<guid>http://i.renjihe.com/blog/read.php?7423</guid> 
<description>
<![CDATA[ 
	<p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa"><strong>背景</strong></p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">前段时间合伙人想做一个早教类的 AR 项目，并且扔给了我一个小册子：</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; text-align: center; background-color: #fafafa"><img style="border: 0px; max-width: 100%; margin: 5px 0px" src="http://cc.cocimg.com/api/uploads/20160527/1464344067476555.jpg" border="0" alt="1.jpg" title="1464344067476555.jpg" /></p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">大概的功能是：</p><ul class=" list-paddingleft-2" style="margin: 0px 0px 20px 2em; padding: 0px; list-style: none; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa"><li style="margin: 0px; padding: 0px; list-style: disc"><p style="margin: 0px; padding: 0px">iPad 扫瞄识别右侧的积木</p></li><li style="margin: 0px; padding: 0px; list-style: disc"><p style="margin: 0px; padding: 0px">屏幕上出现主角按照顺序执行操作</p></li><li style="margin: 0px; padding: 0px; list-style: disc"><p style="margin: 0px; padding: 0px">最后显示运行结果，闯关是否成功</p></li></ul><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">折腾了一段时间，基本做完了上述功能，可以在<a style="margin: 0px; padding: 0px; color: #eb6100; text-decoration: none" href="http://weibo.com/p/230444ad8565599fd6d8e3e14b195d71d27341" target="_self">这里</a>看到演示的效果。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">整个项目从第一次提交代码，到最后出演示效果，花了两天的时间，看了下 git commit 累计花了 25 小时（主要是炒股浪费了不少时间，也浪费了不少钱，此处略过不谈）。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">看上去最终的开发时间不多，不过前面还是做了不少功课，在此简单的记录一下。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">文章中不会涉及任何工具的具体使用过程，所有的基础操作在官方文档里都有详细的讲解。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa"><strong>了解</strong></p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">正式开发之前，先做了一些准备工作，主要是搜索 AR 相关的功能，看看有哪些工具可供使用。一番调研对比和测试之后整理了以下待选方案：</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa"><a style="margin: 0px; padding: 0px; color: #eb6100; text-decoration: none" href="http://opencv.org/" target="_self">OpenCV</a>：计算机视觉库，主要进行右侧积木的识别。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa"><a style="margin: 0px; padding: 0px; color: #eb6100; text-decoration: none" href="https://vuforia.com/" target="_self">Vuforia</a>：可以方便的在软件中实现 AR 功能，主要用于关卡识别和主角模型展示。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa"><a style="margin: 0px; padding: 0px; color: #eb6100; text-decoration: none" href="https://www.python.org/" target="_self">Python</a>：主要是围绕 OpenCV 的一系列科学运算工具，用于快速开发图像识别功能的原型。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa"><a style="margin: 0px; padding: 0px; color: #eb6100; text-decoration: none" href="https://unity3d.com/" target="_self">Unity3D</a>：一款 3D 游戏引擎，可以很方便的进行 3D 场景搭建。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa"><a style="margin: 0px; padding: 0px; color: #eb6100; text-decoration: none" href="https://developer.apple.com/library/ios/documentation/3DDrawing/Conceptual/OpenGLES_ProgrammingGuide/Introduction/Introduction.html" target="_self">OpenGL</a>：如果不用 Unity3D 就需要在 iOS 项目里基于 Vuforia 手写 OpenGL 实现 AR 功能。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa"><strong>积木识别测试</strong></p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">在正式开发之前，先使用 OpenCV for Python 开发图像识别原型，看看这个项目好不好搞。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">在 Jupyter Notebook 里开发图像识别项目真是一种非常流畅的体验：</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; text-align: center; background-color: #fafafa"><img style="border: 0px; max-width: 100%; margin: 5px 0px" src="http://cc.cocimg.com/api/uploads/20160527/1464344187102734.jpg" border="0" alt="2.jpg" title="1464344187102734.jpg" /></p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">加载图像之后，只需要在新的 Cell 里写图像识别相关的算法就可以了，图像数据已经被加载到了内存里，不需要每次运行都执行全部脚本。然后 OpenCV 进行图像处理， numpy 进行像素运算， matplotlib 展示图像，一条龙服务，十分方便。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">具体的图像识别算法不再赘述，上一篇《<a style="margin: 0px; padding: 0px; color: #eb6100; text-decoration: none" href="http://blog.callmewhy.com/2016/04/23/opencv-find-qrcode-position/" target="_self">使用 OpenCV 识别 QRCode</a>》里基本都已包含。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa"><strong>iOS App</strong></p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">搞定了积木识别之后，接下来就是做 AR 功能，主要有两个方案可供选择： iOS App 或者 Unity3D 。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">先用 iOS App 试一下效果。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">Vuforia 官方的&nbsp;<a style="margin: 0px; padding: 0px; color: #eb6100; text-decoration: none" href="https://developer.vuforia.com/downloads/samples" target="_self">Sample Code</a>&nbsp;里已经包含了一个可以完整运行的项目，可以下载体验一下。然后用 pod 'OpenCV' 就能装好 OpenCV for C++ ，基本的开发环境就齐全了。折腾了一段时间之后我决定放弃使用 iOS App 的方案，因为实在是太繁琐了。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">首先需要一个 ARSession 对象来管理 AR 的相关事务，里面包括了视频的渲染（需要等比拉伸并裁切之后渲染在屏幕上）、资源的回收和处理（比如手机退到后台）、线程切换（绘图需要在主线程）等等；然后需要一个 ARViewController 对象来负责具体页面的显示，里面包括基础资源的加载、识别模型的激活与切换、设备相关的事件监听等等；然后需要一个 ARImageTargetGLView 来渲染 AR 场景，包括 buffer 的维护、model 的加载、shader 的渲染等等。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">而最让我崩溃的，是 Swift、Objective-C、C++ 的混写，项目中大量这样的代码：</p><div style="margin: 0px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa"><div id="highlighter_86508" class="syntaxhighlighter&nbsp;&nbsp;js" style="padding: 0px; width: 703px; margin: 1em 0px !important; position: relative !important; overflow: auto !important; font-size: 1em !important; background-color: white !important"><table border="0" cellspacing="0" cellpadding="0" style="border-collapse: collapse; border-spacing: 0px; width: 846px; border: 0px !important; border-radius: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; margin: 0px !important; outline: 0px !important; overflow: visible !important; padding: 0px !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; box-sizing: content-box !important; font-family: Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important; font-size: 1em !important; min-height: auto !important; background: none !important"><tbody><tr style="border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; margin: 0px !important; outline: 0px !important; overflow: visible !important; padding: 0px !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; background: none !important"><td class="gutter" style="margin: 0px !important; padding: 0px !important; border: 0px !important; border-radius: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-family: Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important; font-size: 1em !important; min-height: auto !important; color: #afafaf !important; background: none !important"><div class="line number1 index0 alt2" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">1</div><div class="line number2 index1 alt1" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">2</div><div class="line number3 index2 alt2" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">3</div><div class="line number4 index3 alt1" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">4</div><div class="line number5 index4 alt2" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">5</div><div class="line number6 index5 alt1" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">6</div><div class="line number7 index6 alt2" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">7</div><div class="line number8 index7 alt1" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">8</div><div class="line number9 index8 alt2" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">9</div><div class="line number10 index9 alt1" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">10</div><div class="line number11 index10 alt2" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">11</div></td><td class="code" style="width: 806px; margin: 0px !important; padding: 0px !important; border: 0px !important; border-radius: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; box-sizing: content-box !important; font-family: Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important; font-size: 1em !important; min-height: auto !important; background: none !important"><div class="container" style="margin: 0px !important; padding: 0px !important; min-height: auto !important; height: auto !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: relative !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; background: none !important"><div class="line number1 index0 alt2" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">[self&nbsp;setFramebuffer];</div><div class="line number2 index1 alt1" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">glVertexAttribPointer(vertexHandle,&nbsp;3,&nbsp;GL_FLOAT,&nbsp;GL_FALSE,&nbsp;0,&nbsp;(const&nbsp;GLvoid*)buildingModel.vertices);</div><div class="line number3 index2 alt2" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">glEnableVertexAttribArray(textureCoordHandle);</div><div class="line number4 index3 alt1" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">if&nbsp;(offTargetTrackingEnabled)&nbsp;&#123;</div><div class="line number5 index4 alt2" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">glBindTexture(GL_TEXTURE_2D,&nbsp;augmentationTexture[3].textureID);</div><div class="line number6 index5 alt1" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">&#125;&nbsp;else&nbsp;&#123;</div><div class="line number7 index6 alt2" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">glBindTexture(GL_TEXTURE_2D,&nbsp;augmentationTexture[targetIndex].textureID);</div><div class="line number8 index7 alt1" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">&#125;</div><div class="line number9 index8 alt2" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">glUniformMatrix4fv(mvpMatrixHandle,&nbsp;1,&nbsp;GL_FALSE,&nbsp;(const&nbsp;GLfloat*)&amp;modelViewProjection.data[0]);</div><div class="line number10 index9 alt1" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">glUniform1i(texSampler2DHandle,&nbsp;0);</div><div class="line number11 index10 alt2" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">glDisableVertexAttribArray(textureCoordHandle);</div></div></td></tr></tbody></table></div></div><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">最后发现写了上千行代码，几十个文件，才只是搭建好了一个基础的 AR 开发环境，还不包括自定义的 3D 效果和自己的业务代码，细思恐极，赶紧放弃。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa"><strong>Unity3D</strong></p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">接下来就是转投 Unity3D 的怀抱。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">遇到的第一个问题是如何集成 OpenCV ，通过买买买这个&nbsp;<a style="margin: 0px; padding: 0px; color: #eb6100; text-decoration: none" href="https://www.assetstore.unity3d.com/en/#!/content/21088" target="_self">OpenCV for Unity&nbsp;</a>插件解决了，它是基于 OpenCV for Java 的，所以接口和 Python C++ 相比略有些变化，不过基本是相同的。在整合 OpenCV 和 Vuforia 的时候看到了 OpenCV for Unity 开发团队的&nbsp;<a style="margin: 0px; padding: 0px; color: #eb6100; text-decoration: none" href="https://github.com/EnoxSoftware/VoforiaWithOpenCVForUnitySample" target="_self">Voforia with OpenCV for Unity Sample</a>&nbsp;这个示例项目，再结合自带的&nbsp;<a style="margin: 0px; padding: 0px; color: #eb6100; text-decoration: none" href="https://github.com/EnoxSoftware/OpenCVForUnity" target="_self">Samples&nbsp;</a>文件基本就没问题了。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">遇到的第二个问题是 Unity3D 中如何处理项目文件的问题，在 iOS 项目里我的项目目录是这样的：</p><ul class=" list-paddingleft-2" style="margin: 0px 0px 20px 2em; padding: 0px; list-style: none; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa"><li style="margin: 0px; padding: 0px; list-style: disc"><p style="margin: 0px; padding: 0px">General</p></li></ul><ul class=" list-paddingleft-2" style="margin: 0px 0px 20px 2em; padding: 0px; list-style: none; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa"><li style="margin: 0px; padding: 0px; list-style: disc"><p style="margin: 0px; padding: 0px">Macro</p></li><li style="margin: 0px; padding: 0px; list-style: disc"><p style="margin: 0px; padding: 0px">View</p></li><li style="margin: 0px; padding: 0px; list-style: disc"><p style="margin: 0px; padding: 0px">Extension</p></li></ul><ul class=" list-paddingleft-2" style="margin: 0px 0px 20px 2em; padding: 0px; list-style: none; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa"><li style="margin: 0px; padding: 0px; list-style: disc"><p style="margin: 0px; padding: 0px">Section</p></li><li style="margin: 0px; padding: 0px; list-style: disc"><p style="margin: 0px; padding: 0px">Vendor</p></li></ul><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">在 Unity3D 里，由于项目里不止是代码文件，还包括 fbx 之类的模型文件、 mat 等材质文件、prefab 等预设文件、unity 等场景文件，如果都放在一起十分混乱，很难检索。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">参照 iOS 的项目目录，现在 Unity3D 里的项目里是这样安排的：</p><ul class=" list-paddingleft-2" style="margin: 0px 0px 20px 2em; padding: 0px; list-style: none; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa"><li style="margin: 0px; padding: 0px; list-style: disc"><p style="margin: 0px; padding: 0px">General：全局通用的文件</p></li></ul><ul class=" list-paddingleft-2" style="margin: 0px 0px 20px 2em; padding: 0px; list-style: none; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa"><li style="margin: 0px; padding: 0px; list-style: disc"><p style="margin: 0px; padding: 0px">Scripts：通用的代码文件</p></li></ul><ol class=" list-paddingleft-2" style="margin: 0px 0px 20px 2em; padding: 0px; list-style: none; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa"><li style="margin: 0px; padding: 0px; list-style: decimal"><p style="margin: 0px; padding: 0px">Class：自定义的通用类</p></li><li style="margin: 0px; padding: 0px; list-style: decimal"><p style="margin: 0px; padding: 0px">Extension：基础模块的扩展，比如 List 的方差运算等等</p></li><li style="margin: 0px; padding: 0px; list-style: decimal"><p style="margin: 0px; padding: 0px">Static：静态工具类</p></li></ol><ul class=" list-paddingleft-2" style="margin: 0px 0px 20px 2em; padding: 0px; list-style: none; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa"><li style="margin: 0px; padding: 0px; list-style: disc"><p style="margin: 0px; padding: 0px">Section：业务相关的文件，一个场景一个文件夹</p></li></ul><ul class=" list-paddingleft-2" style="margin: 0px 0px 20px 2em; padding: 0px; list-style: none; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa"><li style="margin: 0px; padding: 0px; list-style: disc"><p style="margin: 0px; padding: 0px">Scene1：具体场景的文件夹，包括所有该场景下的资源</p></li></ul><ol class=" list-paddingleft-2" style="margin: 0px 0px 20px 2em; padding: 0px; list-style: none; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa"><li style="margin: 0px; padding: 0px; list-style: decimal"><p style="margin: 0px; padding: 0px">Scripts：该场景所需的代码</p></li><li style="margin: 0px; padding: 0px; list-style: decimal"><p style="margin: 0px; padding: 0px">Prefabs：该场景内的预设对象</p></li><li style="margin: 0px; padding: 0px; list-style: decimal"><p style="margin: 0px; padding: 0px">Resources：该场景下的其他资源</p></li></ol><ul class=" list-paddingleft-2" style="margin: 0px 0px 20px 2em; padding: 0px; list-style: none; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa"><li style="margin: 0px; padding: 0px; list-style: disc"><p style="margin: 0px; padding: 0px">Materials：该场景下的材质</p></li></ul><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">基本上单个场景的目录结构和 General 的目录结构是一致的， General 像是所有场景的『基类』。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">遇到的第三个问题是 OpenCV 绘图如何处置的问题。我希望能够将 OpenCV 的一些 Debug 信息绘制在屏幕上，比如找到的 contours 、比如计算出的方差/均值、比如画面里的积木总数等等，可以很方便的了解图像识别的情况，找到出现问题的原因。本来是通过注释掉绘图代码的方式进行状态切换，后来发现实在是太麻烦了，于是在所有的 OpenCV 绘图方法外面套了一层，放在 CVUtil 里：</p><div style="margin: 0px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa"><div id="highlighter_882738" class="syntaxhighlighter&nbsp;&nbsp;js" style="padding: 0px; width: 703px; margin: 1em 0px !important; position: relative !important; overflow: auto !important; font-size: 1em !important; background-color: white !important"><table border="0" cellspacing="0" cellpadding="0" style="border-collapse: collapse; border-spacing: 0px; width: 738px; border: 0px !important; border-radius: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; margin: 0px !important; outline: 0px !important; overflow: visible !important; padding: 0px !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; box-sizing: content-box !important; font-family: Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important; font-size: 1em !important; min-height: auto !important; background: none !important"><tbody><tr style="border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; margin: 0px !important; outline: 0px !important; overflow: visible !important; padding: 0px !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; background: none !important"><td class="gutter" style="margin: 0px !important; padding: 0px !important; border: 0px !important; border-radius: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-family: Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important; font-size: 1em !important; min-height: auto !important; color: #afafaf !important; background: none !important"><div class="line number1 index0 alt2" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">1</div><div class="line number2 index1 alt1" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">2</div><div class="line number3 index2 alt2" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">3</div><div class="line number4 index3 alt1" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">4</div><div class="line number5 index4 alt2" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">5</div><div class="line number6 index5 alt1" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">6</div><div class="line number7 index6 alt2" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">7</div><div class="line number8 index7 alt1" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">8</div><div class="line number9 index8 alt2" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">9</div><div class="line number10 index9 alt1" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">10</div><div class="line number11 index10 alt2" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">11</div><div class="line number12 index11 alt1" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">12</div><div class="line number13 index12 alt2" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">13</div><div class="line number14 index13 alt1" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">14</div><div class="line number15 index14 alt2" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">15</div><div class="line number16 index15 alt1" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">16</div><div class="line number17 index16 alt2" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">17</div><div class="line number18 index17 alt1" style="margin: 0px !important; padding: 0px 0.5em 0px 1em !important; border-radius: 0px !important; border-width: 0px 3px 0px 0px !important; border-right-style: solid !important; border-right-color: #6ce26c !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; text-align: right !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">18</div></td><td class="code" style="width: 698px; margin: 0px !important; padding: 0px !important; border: 0px !important; border-radius: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; box-sizing: content-box !important; font-family: Consolas, 'Bitstream Vera Sans Mono', 'Courier New', Courier, monospace !important; font-size: 1em !important; min-height: auto !important; background: none !important"><div class="container" style="margin: 0px !important; padding: 0px !important; min-height: auto !important; height: auto !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: relative !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; background: none !important"><div class="line number1 index0 alt2" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">public&nbsp;class&nbsp;CVUtil&nbsp;&#123;</div><div class="line number2 index1 alt1" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">public&nbsp;class&nbsp;Draw&nbsp;&#123;</div><div class="line number3 index2 alt2" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">public&nbsp;static&nbsp;void&nbsp;Text(Mat&nbsp;mat,&nbsp;string&nbsp;str,&nbsp;double&nbsp;x,&nbsp;double&nbsp;y,</div><div class="line number4 index3 alt1" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">double&nbsp;fontScale&nbsp;=&nbsp;1,&nbsp;Scalar&nbsp;color&nbsp;=&nbsp;null,</div><div class="line number5 index4 alt2" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">LogLevel&nbsp;level&nbsp;=&nbsp;LogLevel.Debug)&nbsp;&#123;</div><div class="line number6 index5 alt1" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">if&nbsp;(level&nbsp;&gt;=&nbsp;Global.CurrentLogLevel)&nbsp;&#123;</div><div class="line number7 index6 alt2" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">Imgproc.putText&nbsp;(mat,&nbsp;str,&nbsp;new&nbsp;Point&nbsp;(x,y),&nbsp;Core.FONT_HERSHEY_PLAIN,&nbsp;fontScale,&nbsp;color);</div><div class="line number8 index7 alt1" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">&#125;</div><div class="line number9 index8 alt2" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">&#125;</div><div class="line number10 index9 alt1" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">public&nbsp;static&nbsp;void&nbsp;Rectangle(Mat&nbsp;mat,&nbsp;OpenCVForUnity.Rect&nbsp;rect,</div><div class="line number11 index10 alt2" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">Scalar&nbsp;color&nbsp;=&nbsp;null,&nbsp;int&nbsp;thickness&nbsp;=&nbsp;1,</div><div class="line number12 index11 alt1" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">LogLevel&nbsp;level&nbsp;=&nbsp;LogLevel.Debug)&nbsp;&#123;</div><div class="line number13 index12 alt2" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">if&nbsp;(level&nbsp;&gt;=&nbsp;Global.CurrentLogLevel)&nbsp;&#123;</div><div class="line number14 index13 alt1" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">Imgproc.rectangle&nbsp;(mat,&nbsp;rect.tl&nbsp;(),&nbsp;rect.br&nbsp;(),&nbsp;color,&nbsp;thickness);</div><div class="line number15 index14 alt2" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">&#125;</div><div class="line number16 index15 alt1" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">&#125;</div><div class="line number17 index16 alt2" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">&#125;</div><div class="line number18 index17 alt1" style="margin: 0px !important; padding: 0px 1em !important; border-radius: 0px !important; border: 0px !important; bottom: auto !important; float: none !important; height: auto !important; left: auto !important; line-height: 1.1em !important; outline: 0px !important; overflow: visible !important; position: static !important; right: auto !important; top: auto !important; vertical-align: baseline !important; width: auto !important; box-sizing: content-box !important; font-size: 1em !important; min-height: auto !important; white-space: pre !important; background-image: none !important; background-attachment: initial !important; background-size: initial !important; background-origin: initial !important; background-clip: initial !important; background-position: initial !important; background-repeat: initial !important">&#125;</div></div></td></tr></tbody></table></div></div><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">然后这样只要切换全局变量 Global.CurrentLogLevel 就能控制 Debug 内容的显示和隐藏了。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">整个 Unity3D 项目里，AR 相关的渲染完全不用操心，只需要把 Vuforia 里的 ImageTarget 这个 Prefab 脱拽到场景中就能实现基础的 AR 功能。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa"><strong>小结</strong></p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">就简单的写这么多啦，没什么干货，只是简单回顾一下自己的开发过程。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">AR 开发的技术门槛并不是很高，目前现成的 SDK 很多，可以自行选择。而如何通过 AR 做出有趣的产品，这才是核心所在。</p><p style="margin: 0px 0px 20px; padding: 0px; color: #252525; font-family: 'Helvetica Neue', Helvetica, STheiti, 微软雅黑, 黑体, Arial, Tahoma, sans-serif, serif; font-size: 14px; line-height: 28px; background-color: #fafafa">玩得开心。</p>
]]>
</description>
</item><item>
<link>http://i.renjihe.com/blog/read.php?7421</link>
<title><![CDATA[全球首份AR报告 2万字告诉你它为什么比VR还酷]]></title> 
<author>renjihe1988 &lt;admin@yourname.com&gt;</author>
<category><![CDATA[AR&amp;AI&amp;模式识别]]></category>
<pubDate>Wed, 27 Jul 2016 06:34:40 +0000</pubDate> 
<guid>http://i.renjihe.com/blog/read.php?7421</guid> 
<description>
<![CDATA[ 
	<span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun"><span style="word-wrap: break-word; color: #8b0000">以下为报告精华版：</span></span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun"><span style="word-wrap: break-word; color: #8b0000">　AR与VR有哪些区别？</span></span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　从技术角度来看，AR是将计算机生成的虚拟世界套在现实世界上，即把数字想象世界加在真实世界之上。最典型的AR设备就是谷歌眼镜。这种智能眼镜将触控板、摄像头以及LED显示器结合起来，通过显示器，用户可以联网，并在视野内使用地图、电子邮件等服务。其他知名的AR产品还有微软的HoloLens，创业公司则以Magic Leap为典型代表。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　VR是让用户置身于一个想象出来或者重新复制的世界，或是模拟真实的世界。VR领域主要的产品包括Oculus、索尼PlayStation VR、HTC Vive和三星Gear VR。（有关VR更多的情况，可关注VR次元微信公众号，回复&ldquo;高盛&rdquo;和&ldquo;德银&rdquo;，分别获得高盛VR中文版报告和德银VR中文版报告）</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　区分VR和AR的一个简单的方法是：VR需要用一个不透明的头戴设备完成虚拟世界里的沉浸体验，而AR需要清晰的头戴设备看清真实世界和重叠在上面的信息和图像。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　从目前来看，AR比较适合服务企业级用户，而VR同时适用于消费者和企业用户。有些情况下，两者还会出现重叠市场。例如，目前大多数游戏基于VR研发，但微软也用HoloLens重新创作了《我的世界》这样的游戏。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun"><span style="word-wrap: break-word; color: #8b0000">AR的市场潜力有多大？</span></span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311764" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115947mz7cdkow3rdezudw.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　最新预测指出，到2017年，AR市场将增长至52亿美元，年增长率竟逼近100%。随着大量资金注入AR项目及AR创业公司，尤其是随着谷歌、佳能、高通、微软等大公司的入场，我们已经看到第一批消费级AR产品的涌现。随着实际商业利益的出现， AR将成为消费、医疗、移动、汽车以及制造市场中的&ldquo;下一件大事&rdquo;。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311765" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/1159474hhcv3mvhcmxgzj4.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　市场调研公司Digi-Capital给出的一组数据很值得研究：到2020年，AR的市场规模将达到1200亿美元，远高于VR的300亿美元。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　VR对于游戏与3D电影来说是一项非常棒的技术，甚至可以说这项技术可谓是专门为此而设计的。但这项技术的体验主要是在客厅、办公室或者座位上展开的，因为如果你戴着一个完全封闭的头戴式显示器走在路上，随时都可能撞到路边的东西。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　虽然AR技术应用在游戏也非常有趣，但在需要真正沉浸式体验的时候，其所带来的乐趣或许不如VR技术那么多，这就像是移动游戏与主机游戏之间的差距。但是，AR技术在游戏玩家眼中的这个缺点，恰恰是让它可以同智能手机一样，在数以亿计用户的现实生活中发挥重要作用的优势。人们可以戴着它四处活动，做任何事情。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　AR的软件与服务拥有可与如今的移动市场相媲美的经济效应，它们都可以利用现有的其他产品的市场，并不断扩张它们。AR庞大的用户基础将会成为电视电影、广告以及Facebook的用户应用程序甚至《部落冲突》等游戏的主要收入来源。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　换句话说，AR技术有可能触及到更多的人，因为它是对人们日常生活的无缝补充，而不是像VR那样在现实世界之外营造出一个完全虚拟的世界。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun"><span style="word-wrap: break-word; color: #8b0000">AR面临哪些挑战？</span></span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　对于AR而言，解决注册任务是最核心的问题。注册对精度的要求极为严格：由于AR应以实时、六个自由度的形式将虚拟信息和现实信息相融合，即便是轻微的注册失准都会造成组合视图难以容忍的失真。因此，移动AR存在两大难点：注册必须极为精准，注册对计算能力和内存的利用必须极为高效。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　这个问题是AR面向大众部署所面临的终极挑战。我们断言，目前大部分已知的注册任务解决方案其实并不适用于智能手机&mdash;&mdash;尽管看上去能用。因此，所有的AR研究人员都应该为智能手机AR的大空间应用问题开发专门的解决方案。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　智能手机是AR大众市场最具前景的平台。智能手机生态系统为面向大众部署AR的纯软件解决方案提供了一切要素。然而不应忽视的是，尽管技术和逻辑取得了种种进步，但是AR应用在智能手机上的大规模部署仍然存在着下列重大障碍：</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　1、相机质量与成像处理。智能手机通常配备的相机传感器在弱光条件下表现糟糕：图像模糊，开始出现明显色差。相机传感器硬件通常禁止低层级访问。API只提供了相机传感器的高层级访问，无法控制曝光、光圈及焦距。小型CCD传感器导致相机采样噪点增加，进而严重影响后续CV算法的发挥。图像获取过程中的质量损失很难通过后期处理步骤补偿。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　2、电量消耗。电池电量近年来并没有显著提升。相机传感器在以高帧率持续运行时耗电量很大，其主要原因是目前手机的设计用途仍然是拍照，而不是摄影。另外，传感器和网络接口也是耗电大户。运行功能强大的AR应用会让电池迅速耗干。因此，AR应用必须只能设计成供短时间使用，而不是一种&ldquo;常开&rdquo;功能。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　3、网络依赖性。远程访问大量数据受到几个因素的影响。首先，网络延迟会导致令人不爽的延迟，拖累AR应用的瞬时表现。其次，访问远程数据仅在开了流量套餐时才有可能做到，而流量套餐可能过于昂贵或者无法开通。最后，某些地区的网络覆盖可能不满足条件。于是完全独立的AR应用成为了唯一的可行选择，这就意味着需要在设备上占用大量的存储空间。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　4、可视化与交互的可能性。智能手机的外形因素在购买决策中发挥着重要作用。实际上，可接受最大设备的尺寸严格制约了显示屏的大小。交互技术同样存在着类似的限制。多点触控界面或许是最为先进的交互机制，但它在某些特定任务&mdash;&mdash;如像素级的选取上表现糟糕。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　理论上讲，针对AR改进未来智能手机需从哪些方面入手已是众所周知。在实践中，AR应用的开发者却要看硬件厂商和服务供应商的脸色，后者做出硬件发展决策的依据是市场预测，而其中可能不含对AR的需求。不过，硬件总体是朝着正确的方向发展的，尤其在移动游戏或移动导航系统的驱动下&mdash;&mdash;而这两者与AR在技术需求方面存在许多共通之处。此外，研究人员意识到目前相机控制方面存在限制，更好的相机API也会因此诞生，比如Frankencamera项目。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　尽管平板电脑作为一种流行移动平台也在不断壮大，但它属于放大版的智能手机平台。由于尺寸放大，可视化与交互的限制有了些许放松，但这些设备的尺寸和重量同时也制约着它们在AR领域的应用，原因是拿起来更加累人（比如说，把设备举起来较长时间可能需要两只手，反过来制约了交互的可能性）。除此之外，目前的平板电脑存在着与智能手机相同的问题。对于不同的AR应用而言，智能手机和平板电脑可能前者更适合，也可能后者更适合。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun"><span style="word-wrap: break-word; color: #8b0000">以下为AR报告第一章：AR与VR</span></span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　VR和AR有着不同的应用领域、技术和市场机会，因此区分两者之间的不同至关重要。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　从技术角度来看，AR是将计算机生成的虚拟世界套在现实世界上，即把数字想象世界加在真实世界之上。最典型的AR设备就是谷歌眼镜。这种智能眼镜将触控板、摄像头以及LED显示器结合起来，通过显示器，用户可以联网，并在视野内使用地图、电子邮件等服务。其他知名的AR产品还有微软的HoloLens，创业公司则以Magic Leap为典型代表。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　AR具备三个主要特征：</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　1、融合虚拟和现实：与VR技术不同的是，增强现实技术不会把使用者与真实世界隔开，而是将计算机生成的虚拟物体和信息叠加到真实世界的场景中来，以实现对现实场景更直观深入的了解和解读，在有限的时间和有限的场景中实现与现实相关知识领域的理解。增强的信息可以是与真实物体相关的非几何信息，如视频、文字，也可以是几何信息，如虚拟的三维物体和场景。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　2、实时交互：通过增强现实系统中的交互接口设备，人们以自然方式与增强现实环境进行交互操作，这种交互要满足实时性。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　3、三维注册：&ldquo;注册&rdquo;（这里也可以解释为跟踪和定位）指的是将计算机产生的虚拟物体与真实环境进行一一对应，且用户在真实环境中运动时，也将继续维持正确的对准关系。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　VR是让用户置身于一个想象出来或者重新复制的世界，或是模拟真实的世界。VR领域主要的产品包括Oculus、索尼PlayStation VR、HTC Vive和三星Gear VR。（有关VR更多的情况，可关注VR次元微信公众号，回复&ldquo;高盛&rdquo;和&ldquo;德银&rdquo;，分别获得高盛VR中文版报告和德银VR中文版报告）</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　区分VR和AR的一个简单的方法是：VR需要用一个不透明的头戴设备完成虚拟世界里的沉浸体验，而AR需要清晰的头戴设备看清真实世界和重叠在上面的信息和图像。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　从目前来看，AR比较适合服务企业级用户，而VR同时适用于消费者和企业用户。有些情况下，两者还会出现重叠市场。例如，目前大多数游戏基于VR研发，但微软也用HoloLens重新创作了《我的世界》这样的游戏。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　AR发展简史</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　AR技术的起源可追溯到&ldquo;VR之父&rdquo;Morton Heilig在上个世纪五、六十年代所发明的Sensorama Stimulator。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　Heilig是一名哲学家、电影制作人和发明家。他利用他在电影拍摄上经验设计出了Sensorama Stimulator，并在1962年获得了专利。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　Sensorama Stimulator使用图像、声音、风扇、香味和震动，让用户感受在纽约布鲁克林街道上骑着摩托车风驰电掣的场景。尽管这台机器大且笨重，但在当时却非常超前。令人遗憾的是，Heilig没有能够获得所需的资金支持让这个发明商业化。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311766" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115948wjx6foiiq8ojuoje.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="500" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　AR历史上的下一个重大里程碑是第一台头戴式AR设备的发明。1968年，哈佛副教授Ivan Sutherland跟他的学生Bob Sproull合作发明了Sutherland称之为&ldquo;终极显示器&rdquo;的AR设备。使用这个设备的用户可以通过一个双目镜看到一个简单三维房间模型，用户还可以使用视觉和头部运动跟踪改变视角。尽管用户交互界面是头戴的，然而系统主体部分却又大又重，不能戴在用户头上，只能悬挂在用户头顶的天花板上。这套系统也因此被命名为&ldquo;达摩克利斯之剑&rdquo;。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311767" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115948nnqq2poentonjh2t.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　尽管这些早期的发明属于AR的范畴，但实际上，直到1990年，波音公司研究员Tom Caudell才创造了&ldquo;AR&rdquo;这个术语。Caudell和他的同事设计了一个辅助飞机布线系统，用于代替笨重的示例图版。这个头戴设备将布线图或者装配指南投射到特殊的可再用方板上。这些AR投影可以通过计算机快速轻松地更改，机械师再也不需要手工重新改造或者制作示例图版。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　大约在1998年，AR第一次出现在大众平台上。当时有电视台在橄榄球赛电视转播上使用AR技术将得分线叠加到屏幕中的球场上。此后，AR技术开始被用于天气预报&mdash;&mdash;天气预报制作者将计算机图像叠加到现实图像和地图上面。从那时起，AR真正地开始了其爆炸式的发展。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　2000年，Bruce H. Thomas 在澳大利亚南澳大学可穿戴计算机实验室开发了第一款手机室外AR游戏&mdash;&mdash;ARQuake。2008年左右，AR开始被用于地图等手机应用上。2013年，谷歌发布了谷歌眼镜，2015年，微软发布HoloLens，这是一款能将计算机生成图像（全息图）叠加到用户周围世界中的头戴式AR设备，也正是随着这两款产品的出现，更多的人开始了解AR。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">AR硬件概览</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　AR硬件发展的驱动力源于计算机处理器、显示技术、传感器、移动网络速率、电池续航等多个领域的技术进步。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　目前能够确定的AR硬件类型有以下几种：</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　手持设备（Handheld Devices）</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　固定式AR系统（Stationary AR Systems）</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　空间增强现实（SAR）系统（Spatial Augmented Reality Systems）</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　头戴式显示器（Head-mounted Displays ，即HMD）</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　智能眼镜（Smart Glasses）</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　智能透镜（Smart Lenses）</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">手持设备</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311768" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/1159488wkhlq6ej450ijkk.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="353" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　智能手机正是手持设备的代表。我们正经历着智能手机、平板电脑等手持设备的大爆炸时代，这将会促进AR的普及。这些设备正在变得越来越好&mdash;&mdash;显示器分辨率越来越高，处理器越来越强，相机成像质量越来越好，传感器越来越多，提供着加速计、GPS、罗盘等等功能&hellip;&hellip;这些成为了天然的AR平台。尽管手持设备是消费者接触AR应用最为方便的形式，但由于大部分手持设备不具备可穿戴功能，因此用户无法获得双手解放的AR体验。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">固定式AR系统</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311769" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115948vgzqgb7qbrzjgy7u.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="345" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center">俄罗斯一家Topshop内的固定式AR衣橱</p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　固定式AR系统适用于固定场所中需要更大显示屏或更高分辨率的场景。与移动AR设备不同的是，这些极少移动的系统可以搭载更加先进的相机系统，因此能够更加精确地识别人物和场景。此外，显示单元往往能呈现出更加真实的画面，而且受阳光或照明等环境因素影响较小。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">空间增强现实（SAR）系统</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311770" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/11594803k593j5k9f2q029.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="351" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center">大众公司的SAR系统</p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　与其它所有系统不同的是，空间增强现实（SAR）系统的虚拟内容直接投影在现实世界中。SAR系统往往固定在自然中。任何物理表面，如墙、桌、泡沫、木块甚至是人体都可以成为可交互的显示屏。随着投影设备尺寸、成本、功耗的降低以及3D投影的不断进步，各种全新的交互及显示形式正在不断涌现。SAR系统最大的优点在于，现实世界的反射在这里更加精确，即虚拟信息能够以实际的比例和大小呈现在眼前。此外在观看人数较多时，内容也能看清，这个案例可以用来实现同步办公。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　头戴式显示器（HMD）</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311771" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115949inli2z7h7e75zi62.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="349" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center">佳能的混合现实头戴设备</p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　HMD代表着另一种快速发展的AR硬件类型。HMD由一个头戴装置（如头盔），以及与之搭配的一块或多块（微型）显示屏组成。HMD将现实世界和虚拟物体的画面重叠显示在用户视野中。换而言之，用户不会直接看到现实，看到的是现实的增强视频画面。如果显示屏只覆盖用户的一只眼睛，这样的HMD称为单眼HMD，另一种是两只眼睛都看显示屏的双眼HMD。先进的HMD通常能够搭载具有很高自由度的传感器，用户可以在前后、上下、左右、俯仰、偏转和滚动六个方向自由移动头部。该系统因此能够实现虚拟信息与现实世界的贴合，并根据用户头部移动作做相应的画面调整。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　智能眼镜</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311772" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115949aaivns8zh8aux5ia.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="356" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center">Vuzix M100智能眼镜</p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　消费电子行业的许多公司认为，智能眼镜将会成为智能手机后下一大全球热卖消费产品。这些AR设备实际上是带有屏幕、相机和话筒的眼镜。根据这一概念，用户的现实世界视角被AR设备截取，增强后的画面重新显示在用户视野中。AR画面透过眼镜镜片，或者通过眼镜镜片反射，从而进入眼球。智能眼镜技术最为突出的例子是谷歌眼镜和Vuzix M100。不过，目前开发中的最令人激动的智能眼镜要数Atheer One&mdash;&mdash;该智能眼镜配有3D景深传感器，用户可以实际控制眼前显示的虚拟内容。</span><br /><br /><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　智能透镜</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311773" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115949vo2jkfwzslm2o7wh.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="349" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center">华盛顿大学开发的透镜中含有金属电路结构</p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　智能眼镜绝不是故事的结局。越来越多的研究投入到能显示AR画面的智能透镜上；微软、谷歌等公司也正忙于宣布自己的智能透镜项目。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　智能透镜的理念是在传统透镜中集成控制电路、通信电路、微型天线、LED及其它光电组件，从而形成一套功能系统。未来或许可以用成千上万颗LED直接在眼前形成画面，从而让透镜变成显示屏。然而，还必须克服一系列难题，比如说如何给透镜供电，如何保证人眼不受伤害等等。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">在这一章的最后，我们简单看下AR技术会应用到哪些领域：</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　考古：在古代遗迹上显示遗迹原本的样子。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　艺术：跟踪眼球移动并将这些移动显示在屏幕上，帮助残疾人进行艺术创作。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　商业：显示产品的多种定制选项或者补充信息。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　教育：将文本、图像、视频和音频叠加到学生周围的实时环境中。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　时尚：显示不同的妆容和发型用在一个人身上的效果。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　游戏：运用真实世界环境让用户在游戏中进行互动，获得不同的体验。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　医药：通过虚拟X光将病人的内脏器官投射到他们的皮肤上。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　军事：使用AR眼镜向士兵展示战场中出现的人和物体，并附上相关信息，以帮助士兵避开潜在的危险。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　导航：将道路和街道的名字跟其他相关信息一起标记到现实地图中，或者在挡风玻璃上显示目的地方向、天气、地形、路况、交通信息，提示潜在危险。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　体育：显示橄榄球场的得分线、高尔夫球的飞行路线和冰球移动的轨迹。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　电视：在天气预报中显示天气视觉效果和图像。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun"><span style="word-wrap: break-word; color: #8b0000">　以下为AR报告第二章：AR的工作原理</span></span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　AR介于VR和真实世界之间，VR创造逼真的虚拟世界，AR则将图形、声音、触感和气味添加到真实的世界中。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　在介绍AR的工作原理之前，我们先通过一个例子，让大家有一个简单的认识。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　在2009年2月的TED大会上，帕蒂?梅斯（Pattie Maes）和普拉纳夫?米斯特莱（Pranav Mistry）展示了他们研发的AR系统。该系统属于麻省理工学院媒体实验室流体界面小组的研究成果之，他们称之为SixthSense（第六感）。它依靠众多AR系统中常见的一些基本元件来工作：摄像头、小型投影仪、智能手机和镜子。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311774" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115949zhb4d994xoy49b9z.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　这些元件通过一根类似绳索的仪器串连起来，然后戴在佩戴者的脖子上。用户还会在手指上戴上四个不同颜色的特殊指套，这些指套可以用来操纵投影仪投射的图像。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　SixthSense设备利用简单的、现成的元件来组成AR系统，它的投影仪可以将任何平面变成一个互动的显示屏。SixthSense设备利用摄像头和镜子来捕捉周围的环境，然后将这种图片传给手机（手机处理这种图片，获得GPS坐标以及从互联网上搜索相关信息），然后将这些信息从投影仪投射到用户面前的任何平面上，不管这种平面是一个手腕，一面墙，还是一个人。由于用户将摄像头佩戴在胸前，因此SixthSense设备能够增强他所看到的一切。例如，如果他在一个杂货店里挑选了一罐汤，SixthSense设备将能够搜索这罐汤的相关信息，例如成分、价格和营养价值甚或用户评论，然后将它们投射到平面上。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　利用手指上的指套，用户可以在投射的信息上执行各种操作，这些操作将会被摄像头捕捉到，然后通过手机来处理。如果他希望了解这罐汤的更多信息，例如与之竞争的同类产品，那么他可以用手指与投射画面进行互动，从而获取更多的信息。SixthSense设备还能够识别一些复杂的手势，例如你在手腕上画一个圆圈，SixthSense设备就能够投射一款手表来显示当前的时间。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　AR的系统结构</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311775" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115949915bb2c5193vvjxv.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center">一个典型的AR系统结构</p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　一个典型的AR系统结构由虚拟场景生成单元、透射式头盔显示器、头部跟踪设备和交互设备构成。其中虚拟场景生成单元负责虚拟场景的建模、管理、绘制和其它外设的管理；透射式头盔显示器负责显示虚拟和现实融合后的信号；头部跟踪设备跟踪用户视线变化；交互设备用于实现感官信号及环境控制操作信号的输入输出。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　首先透射式头盔显示器采集真实场景的视频或者图像，传入后台的处理单元对其进行分析和重构，并结合头部跟踪设备的数据来分析虚拟场景和真实场景的相对位置，实现坐标系的对齐并进行虚拟场景的融合计算；交互设备采集外部控制信号，实现对虚实结合场景的交互操作。系统融合后的信息会实时地显示在头盔显示器中，展现在人的视野中。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　AR的关键技术</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　目前AR技术的技术难点在于：精确场景的理解、重构和高清晰度、大视场的显示技术。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">1、对现实场景的理解和重构</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　在增强现实系统中，首先要解决&ldquo;是什么&rdquo;的问题，也就是要理解、知道场景中存在什么样的对象和目标。第二要解决&ldquo;在哪里&rdquo;的问题，也就是要对场景结构进行分析，实现跟踪定位和场景重构。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　物体的检测和识别技术</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311776" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115949hwhoxpf2phuj55v9.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="335" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center">物体检测和识别</p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　物体检测和识别的目的是发现并找到场景中的目标，这是场景理解中的关键一环。广义的物体检测和识别技术是基于图像的基本信息（各类型特征）和先验知识模型（物体信息表示），通过相关的算法实现对场景内容分析的过程。在增强现实领域，常见的检测和识别任务有，人脸检测、行人检测、车辆检测、手势识别、生物识别、情感识别、自然场景识别等。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　目前，通用的物体检测和识别技术，根据不同的思路可以分为两种：一种是从分类和检测的角度出发，通过机器学习算法训练得到某一类对象的一般性特征，从而生成数据模型。这种方法检测或者识别出的目标不是某一个具体的个体，而是一类对象，如汽车、人脸、植物等。这种识别由于是语义上的检测和识别，所以并不存在精确的几何关系，也更适用于强调增强辅助信息，不强调位置的应用场景中。如检测人脸后显示年龄、性别等。另外一种识别是从图像匹配的角度出发，数据库中保存了图像的特征以及对应的标注信息，在实际使用过程中，通过图像匹配的方法找到最相关的图像，从而定位环境中的目标，进一步得到识别图像和目标图像的精确位置，这种识别适用于需要对环境进行精确跟踪的应用场景。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　就现阶段而言，识别检测技术的难点之一是技术的碎片化。这一方面是由于每一类对象都会有其独有的特征，而不同特征的提取和处理都需要实现一一对应，这对识别检测是一个巨大的挑战。另一方面，图像本身还受到噪声、尺度、旋转、光照、姿态等因素的影响。近几年来，随着深度学习技术的不断成熟，检测和识别方法也越来越统一，而性能也在不断提高中。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　跟踪定位技术</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　跟踪技术的方法可以分为基于硬件和基于视觉两大类。基于硬件设备的三维跟踪定位方法在实现跟踪定位的过程中使用了一些特殊的测量仪器或设备。常用的设备包括机械式跟踪器、电磁式跟踪器、超声波跟踪器、惯性跟踪器以及光学跟踪等。光学跟踪和惯性跟踪是比较常用的两种硬件跟踪方式，HTC Vive就是采用了光学跟踪和惯性跟踪两种硬件来定位头部的位置。使用硬件设备构成的跟踪系统大多是开环系统，跟踪精确取决于硬件设备自身的性能，其算法的扩展性要差一些，且成本相对较高。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311777" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/11595094994z98leepeeze.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="377" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center">HTC Vive 采用光学和惯性跟踪设备</p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　视觉跟踪方法具备更强的扩展性，其系统多为闭环系统，更依赖于优化算法来解决跟踪精度问题。相比于上述基于硬件设备的跟踪方法，计算机视觉跟踪方法提供了一种非接触式的、精确的、低成本的解决方法，但是基于视觉的方法受限于图像本身，噪声、尺度、旋转、光照、姿态变化等因素都会对跟踪精度造成较大的影响，因此更好地处理这些影响因素，研发鲁棒性强的算法就成为下一步AR技术的研究重点。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　根据数据的生成方式，视觉跟踪技术的算法可以分为两种，一种是基于模板匹配的方式，预先对需要跟踪的target进行训练，在跟踪阶段通过不断的跟预存训练数据进行比对解算当前的位姿。这类方法的好处是速度较快、数据量小、系统简单，适用于一些特定的场景，但不适用于大范围的场景。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　另外一种是SLAM方法，也就是即时定位和地图构建技术。这类技术不需要预存场景信息，而是在运行阶段完成对于场景的构建以及跟踪。其优点是不需要预存场景，可以跟踪较大范围，适用面广，在跟踪的同时也可以完成对于场景结构的重建。但目前这类技术计算速度慢、数据量大、算法复杂度高，对于系统的要求也较高。Hololens和Magic Leap的宣传视频中都展现了这方面技术，而亮风台对相应的技术也在研发当中。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311778" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115950czh7aglxuv0u9nag.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="362" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center">SLAM跟踪技术</p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　为了弥补不同跟踪技术的缺点，许多研究者采用硬件和视觉混合跟踪的方法来取长补短，以满足增强现实系统高精度跟踪定位的要求。</span><br /><br /><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　2、增强现实的显示技术</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　透射式头盔显示器</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311779" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/1159507hgkxllxmxbq5smb.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="436" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center">透射式头盔显示器 Hololens</p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　目前大多数的AR系统采用透视式头盔显示器实现虚拟环境与真实环境的融合。根据真实环境的表现形式划分，主要有视频透视式头盔显示器和光学透视式头盔显示器两种形式。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　视频透视式头盔显示器通过安装在头盔上的微型摄像头获取外部真实环境的图像，也就是通过摄像头来采集真实场景的图像进行传递。计算机通过场景理解和分析将所要添加的信息和图像信号叠加在摄像机的视频信号上，将计算机生成的虚拟场景与真实场景进行融合，最后通过类似于浸没式头盔显示器的显示系统呈现给用户。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　虽然视频透射式头盔在显示上不受强光的干扰，具有比较大的视场，但由于真实环境的数据来自于摄像头，因此会造成显示分辨率较低的不利因素。另一方面，一旦摄像机与用户视点不能保持完全重合，用户看到的视频景象与真实景象将会存在偏差，因此会造成在某些领域（特别是工业、军事等领域）出现一些安全隐患。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　光学原理的透视式头盔显示器的基本原理则是通过安装在眼前的一对半反半透镜融合呈现出真实场景和虚拟场景。与视频透射式不同的是，光学透视式的&ldquo;实&rdquo;来自于真实的光源，经过透视光学系统直接进入眼睛，计算机生成的&ldquo;虚&rdquo;则经过光学系统放大后反射进入眼睛，最后两部分信息汇聚到视网膜上从而形成虚实融合的成像效果。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　光学透视式头盔相对来说结构简单，分辨率更高，因其能够直接看到外部，真实感和安全性也更强。其缺点是，在室外强光条件下显示效果会受影响。目前Hololens以及亮风台的HiAR Glasses都采用了光学透射式的成像方案。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　不难看出，两种方案各有优缺点，如何选择最优方案，目前来看，还应基于实际应用场景来进行判断。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　由于光学透射式头盔跟实际场景结合更紧密，真实感更强，大多数厂家会选择这种方案。对于透射式头盔显示器来说，单纯的强调厚薄或者视场大小并没有任何实际意义。这是由于厚度和视场是矛盾的，要做得较薄，方便用户使用佩戴，视场就必然变小；想要拥有大视场，则其厚度就必然增大，设备就目前来说也会显得比较笨重，不易佩戴。因此在目前技术依旧存在障碍的情况下，大家都会采取一些折中的方案。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　数字光场显示</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311780" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/1159503a845nzn2xp5mcn5.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="505" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center">Magic leap 光场显示</p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　随着Magic Leap的宣传视频，数字光场这个概念也变得广为人知。这种不采用屏幕来做载体的显示方式，通过记录并复现光场来完成虚拟物体的显示。通过呈现不同深度的图像，使用户在观察近景或远景时，可以实现主动的对焦，这也是光场显示的一大优点。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　同样，光场显示也有不同的显示方案，一种方案是采用多层的显示器，如光场立体镜。如Magic Leap采用的是光导纤维投影仪。这套方案的优势是可以做到很大的视场角，显示更加符合人的真实感受。但这一方案同时也具有比较大的挑战性，光场的显示需要比较大的计算量，并且需要有相应的手段记录或者生成想要叠加的虚拟对象相应位置的光源信息，同时还要精细地控制投影的内容和位置，目前这些技术还都处于研究阶段。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　尽管存在比较多的挑战，光场显示技术仍旧是非常值得期待的一种成像方式。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun"><span style="word-wrap: break-word; color: #8b0000">　以下为AR报告第三章：布局</span></span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　从目前来看，绝大多数巨头和创业公司更愿意选择在VR领域开疆拓土，但这并不意味着AR无人问津。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　苹果</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　种种迹象显示，苹果可能和微软一样瞄准了AR领域，并非时下最热的VR。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311781" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115950xtzm32mno2om3vt2.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="450" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　苹果已经在AR领域进行过一些并购交易。2015年5月，苹果收购了一家名为Metaio的德国AR公司。该公司主要开发基于智能手机的AR应用软件，比如其曾经开发一款让家具视觉化呈现的工具。该公司被收购之后，实体被注销，人员融入了苹果的开发团队。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311782" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115950we7mod7epgmmrnwn.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　2014年年底，苹果收购了一家从事脸部视觉识别的公司&mdash;&mdash;FaceShift，该公司的技术能够利用摄像头对用户脸部图像进行实时捕捉，甚至可以生成虚拟的头像。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　据悉，电影《星球大战：原力觉醒》的特效团队曾经使用了上述公司的技术，让外星人的脸部形象更加栩栩如生。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311783" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115951o9q4o274499viz8o.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　此外，苹果还曾经收购了以色列的硬件公司PrimeSense，该公司主要为微软的Xbox游戏机制造Kinect动感捕捉摄像头。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　该公司具备了先进的手势动作识别技术。在AR领域，用户一般不会使用手持控制器，因此识别手部动作十分重要，这一技术也能够用于AR头盔中。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　除了各种并购之外，苹果也储备了一些和AR有关的技术专利。这些专利并不意味着苹果一定会开发某种技术或者硬件，但是可能披露了苹果未来产品开发的某些思路。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　2015年2月，苹果获得一个技术专利，主要用于让智能手机连接AR和VR头盔。专利描述文字和谷歌、微软、三星电子和Facebook近些年推出过的产品十分相似。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　不过迄今为止，苹果从未对外宣布过开发AR硬件、软件等产品的计划。苹果向来并不喜欢做新技术的第一批尝鲜者，而是善于在市面已有的产品门类中拿出用户体验十分优秀的产品，依靠苹果的品牌力大规模占领市场。因此在AR领域，苹果也会选择一个相对成熟的时机再进入市场。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">微软</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　微软应该算是布局AR比较超前的巨头公司，其在2015年就推出了AR头盔HoloLens，开发者版已经开启预订，售价为3000美元。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　我们之所以能够看到物体，是因为光线被这些物体反弹，最后射入我们的眼中。而我们的大脑需要对这些光进行复杂运算，最后重现你眼睛所看到物体的图像。HoloLens实际上就是欺骗大脑，将光线以全息图的方式发射到你眼睛中，就好像物体真的存在于现实世界中一样。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　就像下面这幅图，HoloLens可以将屏幕投射到墙上。当用户四处走动时，屏幕依然会留在原地，就好像那是一面真实存在的镜子。HoloLens可在正确角度向你的眼中发射光线，让你觉得屏幕真的出现在墙上。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311784" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/1159517ovl829ovaa4a2b2.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="582" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　HoloLens本身就是一台独立电脑，拥有自己的CPU和GPU，以及微软所谓的全息处理单元，负责支持创造全息图必须的全部必要计算。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　在消费者方面，HoloLens拥有巨大潜力，你可能再无需购买60英寸电视，HoloLens允许用户将电视屏幕发射到墙上，屏幕大小可随意调节。如果未来版的HoloLens足够紧凑，你可以想象到有人边开车边接受导航，但司机的实现不再局限于屏幕上，而是可看到前方道路的全息图。当然，游戏可能是HoloLens的重要卖点。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　在企业方面，HoloLens最明显的应用就是实现3D模型或设计的可视化。HoloLens也可被用于视频会议等场合。此外，它的另一个用途可能是支持在线零售店，允许HoloLens用户看到其产品全息图。在你购买家具前，你就可以看到家具被摆放在室内的虚拟图。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　由于HoloLens运行Windows 10操作系统，通用应用将可在其上顺利运行。这些应用将被投射到用户面前，可被便捷操作。对于微软来说，吸引开发者非常重要，因为这款设备最吸引人的应用可能还未出现。尽管HoloLens的硬件设施令人印象深刻，但其依然需要好的应用为消费者和企业提供最好的服务。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　微软手中可能正握着一款革命性产品。在错失了移动大潮之后，微软将复兴的希望押在HoloLens身上，尽管在HoloLens成为大众设备前，它可能需要数次迭代，但对于微软来说，这将是改变游戏规则的良机。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">谷歌</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　谷歌当前在VR领域比较活跃，如推出硬件产品 Cardboard头盔，YouTube上线360度全景视频功能，还提供Tilt Brush、Jump和Assembler等VR小应用，方便帮助开发者创新新的VR体验，但这并不意味着谷歌放弃了AR市场。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　谷歌和联想合作，推出Project Tango项目。该项目旨在赋予智能手机3D绘图和创造AR体验的能力。Tango智能手机将于今年年终发货，相当于是一个完整功能的AR设备。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　除了自身开发AR项目，谷歌还投资了AR创业公司Magic Leap。Magic Leap专注于AR技术的研发，其最终产品很可能是一款头盔，可将电脑生成的图像投射到人眼上，最终在现实图像上叠加一个虚拟图像。有关Magic Leap的情况，将在下文进行详细说明。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">Magic Leap</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　Magic Leap算是知名度很高的AR创业公司。今年2月，Magic Leap在新一轮融资中获得7.935亿美元的投资，阿里、谷歌都参与了本轮融资。据估测， Magic Leap的估值至少达到45亿美元，这比两年前Facebook收购Oculus的价格高出了两倍。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　Magic Leap研发的技术依然处于半透明状态，没有任何产品出现，我们目前只知道它主要研发方向就是将三维图像投射到人的视野中。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　Magic Leap CEO鲁尼? 阿伯维兹曾公开表达过自己公司的定位：&ldquo;你可以将我们看作是科技生物学（Techno-biology），我们认为它是计算机的未来。&rdquo;</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　具体来说，Magic Leap制作图像的方法与人眼的工作方式相同。Magic Leap利用弯曲的光场制作图像，而不像其他平台那样利用立体图像欺骗眼球。利用其他3D图像投影方式，如果用户闭上一只眼睛，3D图像就会消失。在现实生活中，用户即使闭上一只眼睛，依然能够看到3D图像。Magic Leap便采用这种更为实用的图像制作方式。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun"><span style="word-wrap: break-word; color: #8b0000">以下为AR报告第四章：AR市场潜力</span></span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　尽管过去一年里媒体开始大肆报道AR技术，我们目前了解到的大部分AR解决方案仍处于开发之中。只有少数硬件解决方案得到了大规模生产并能够买到。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　2011年，全球AR营收仅为1.81亿美元，而且当时AR往往被人们视作一种营销噱头：一种还在摸索实用应用的技术。很少有人认识到AR的潜力，开发相关应用大多也是用来快速打响名声，或者这些应用的价值仅限于添加视频效果这样的博眼球之举而已。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311785" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115951a0ttjctfj681y58n.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　然而最新预测指出，到2017年，AR市场将增长至52亿美元，年增长率竟逼近100%。随着大量资金注入AR项目及AR创业公司，尤其是随着谷歌、佳能、高通、微软等大公司的入场，我们已经看到第一批消费级AR产品的涌现。随着实际商业利益的出现， AR将成为消费、医疗、移动、汽车以及制造市场中的&ldquo;下一件大事&rdquo;。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　AR比VR更具增长潜力</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311786" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115951q7ydi3j2gqkri0qb.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　市场调研公司Digi-Capital给出的一组数据很值得研究：到2020年，AR的市场规模将达到1200亿美元，远高于VR的300亿美元。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　VR对于游戏与3D电影来说是一项非常棒的技术，甚至可以说这项技术可谓是专门为此而设计的。但这项技术的体验主要是在客厅、办公室或者座位上展开的，因为如果你戴着一个完全封闭的头戴式显示器走在路上，随时都可能撞到路边的东西。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　虽然AR技术应用在游戏也非常有趣，但在需要真正沉浸式体验的时候，其所带来的乐趣或许不如VR技术那么多，这就像是移动游戏与主机游戏之间的差距。但是，AR技术在游戏玩家眼中的这个缺点，恰恰是让它可以同智能手机一样，在数以亿计用户的现实生活中发挥重要作用的优势。人们可以戴着它四处活动，做任何事情。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　AR的软件与服务拥有可与如今的移动市场相媲美的经济效应，它们都可以利用现有的其他产品的市场，并不断扩张它们。AR庞大的用户基础将会成为电视电影、广告以及Facebook的用户应用程序甚至《部落冲突》等游戏的主要收入来源。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　换句话说，AR技术有可能触及到更多的人，因为它是对人们日常生活的无缝补充，而不是像VR那样在现实世界之外营造出一个完全虚拟的世界。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　《增强现实：指向增强现实的一种新技术》一书的作者格里格?基佩尔（Greg Kipper）在书中写到：&ldquo;增强现实将具备更多的实际应用价值，因为在现实中，与真实世界中的事物互动的人更多一些。&rdquo;</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　在增强现实技术的帮助下，人们通过专用头盔看见的三维全息图像可以为真实世界提供一种有益的补充。当你走过一个杂货店的走道，你也许会在眼前的虚拟屏幕上看到制作意大利饭所需的食材和配料清单。又或者，当你在阅读一本有关天文学的书籍时，你周围可能会出现一幅太阳系的图像。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　但是戴上虚拟现实头盔之后，你与周遭世界的联系就被人为隔断了。你被投影到一个不同的世界中，就像恐龙冲过一片丛林，或者像站在一幢100层的摩天大楼的楼顶上俯瞰着脚下的大街一样。这跟主题乐园的游历过程有些相似，就连虚拟现实头盔戴久了会让你感到恶心或者头晕也跟你在主题乐园中呆久了的感觉很相似。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　Meta是硅谷的一家小公司，员工人数大约为100人。按计划它将在今年夏天交付第二代AR头盔，它的头盔是作为开发者工具套装的一部分出售的，整个套装售价949美元，主要用来帮助开发商为新头盔设计出更多的三维、互动应用。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　Meta CEO梅隆?格里贝茨预计，有朝一日，人们再也不用一边在笨拙的键盘上敲敲打打，一边紧盯着显示屏的屏幕，人们可以在漂浮在眼前的全息图像之间随意切换和浏览，只需用手碰一碰就可以完成各种操作。当然还有虚拟键盘，人们可以利用它输入数据。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　人们可以进入他们的全息影像屏幕，提取出人的解剖图，然后剔除骨骼进行研究。人们也可以通过透视去检查自己打算购买的鞋子的内部做工。到那个时候，打电话将会变成一种很奇怪的行为，因为所有人都可以在全息影像中进行对话。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　格里贝茨说：&ldquo;VR很酷，但它只是通向增强现实的一块垫脚石。我们将开发出比Mac电脑好用一百倍且强大一百倍的产品。&rdquo;</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun"><span style="word-wrap: break-word; color: #8b0000">以下为AR报告第五章：AR面临的挑战</span></span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　对于AR而言，解决注册任务是最核心的问题。注册对精度的要求极为严格：由于AR应以实时、六个自由度的形式将虚拟信息和现实信息相融合，即便是轻微的注册失准都会造成组合视图难以容忍的失真。因此，移动AR存在两大难点：注册必须极为精准，注册对计算能力和内存的利用必须极为高效。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　这个问题是AR面向大众部署所面临的终极挑战。我们断言，目前大部分已知的注册任务解决方案其实并不适用于智能手机&mdash;&mdash;尽管看上去能用。因此，所有的AR研究人员都应该为智能手机AR的大空间应用问题开发专门的解决方案。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　智能手机是AR大众市场最具前景的平台。智能手机生态系统为面向大众部署AR的纯软件解决方案提供了一切要素。然而不应忽视的是，尽管技术和逻辑取得了种种进步，但是AR应用在智能手机上的大规模部署仍然存在着下列重大障碍：</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　1、相机质量与成像处理。智能手机通常配备的相机传感器在弱光条件下表现糟糕：图像模糊，开始出现明显色差。相机传感器硬件通常禁止低层级访问。API只提供了相机传感器的高层级访问，无法控制曝光、光圈及焦距。小型CCD传感器导致相机采样噪点增加，进而严重影响后续CV算法的发挥。图像获取过程中的质量损失很难通过后期处理步骤补偿。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　2、电量消耗。电池电量近年来并没有显著提升。相机传感器在以高帧率持续运行时耗电量很大，其主要原因是目前手机的设计用途仍然是拍照，而不是摄影。另外，传感器和网络接口也是耗电大户。运行功能强大的AR应用会让电池迅速耗干。因此，AR应用必须只能设计成供短时间使用，而不是一种&ldquo;常开&rdquo;功能。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　3、网络依赖性。远程访问大量数据受到几个因素的影响。首先，网络延迟会导致令人不爽的延迟，拖累AR应用的瞬时表现。其次，访问远程数据仅在开了流量套餐时才有可能做到，而流量套餐可能过于昂贵或者无法开通。最后，某些地区的网络覆盖可能不满足条件。于是完全独立的AR应用成为了唯一的可行选择，这就意味着需要在设备上占用大量的存储空间。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　4、可视化与交互的可能性。智能手机的外形因素在购买决策中发挥着重要作用。实际上，可接受最大设备的尺寸严格制约了显示屏的大小。交互技术同样存在着类似的限制。多点触控界面或许是最为先进的交互机制，但它在某些特定任务&mdash;&mdash;如像素级的选取上表现糟糕。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　理论上讲，针对AR改进未来智能手机需从哪些方面入手已是众所周知。在实践中，AR应用的开发者却要看硬件厂商和服务供应商的脸色，后者做出硬件发展决策的依据是市场预测，而其中可能不含对AR的需求。不过，硬件总体是朝着正确的方向发展的，尤其在移动游戏或移动导航系统的驱动下&mdash;&mdash;而这两者与AR在技术需求方面存在许多共通之处。此外，研究人员意识到目前相机控制方面存在限制，更好的相机API也会因此诞生，比如Frankencamera项目。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　尽管平板电脑作为一种流行移动平台也在不断壮大，但它属于放大版的智能手机平台。由于尺寸放大，可视化与交互的限制有了些许放松，但这些设备的尺寸和重量同时也制约着它们在AR领域的应用，原因是拿起来更加累人（比如说，把设备举起来较长时间可能需要两只手，反过来制约了交互的可能性）。除此之外，目前的平板电脑存在着与智能手机相同的问题。对于不同的AR应用而言，智能手机和平板电脑可能前者更适合，也可能后者更适合。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　计算机视觉面临的挑战</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　智能手机的一大优势在于，定位不必单单依赖于相机传感器，也可以利用其它任意可用的传感器，如GPS，指南针，加速度计和陀螺仪。尽管其它传感器的使用在核心CV社区中往往被视为&ldquo;作弊&rdquo;，但这些传感器能够对开发实验室外快速、健壮的定位功能做出重大贡献。即便在结合了多种传感器的帮助下，基于CV的定位仍然非常困难，一系列原因列举如下：</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　纹理结构。大多数方法依赖于兴趣点外形上的自然特征，要求环境中各区域纹理足够清晰。兴趣点的主要问题在于，纹理的呈现形式至关重要。尤其在室内场景中，常常会有白墙出现，使得基于自然特征的定位方法很难发挥作用。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　光照和天气条件。尽管自然特征描述器通常被设计为不受光照影响，但这一假设只有在描述实际物理特征的观测研究中成立。不幸的是，室外环境中大量以自然画面呈现的特征与实际物理特征并不相关。场景中物体投射的阴影会造成斑点、边角、线条的出现，还会随着光照或天气条件变化而动态移动。因此，存在着大量的会对定位质量产生严重影响的异常因素和不匹配因素，这与匹配算法的选择并无关系。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　数据库规模大、易变化。对于室外环境而言，在定位之前必须采集大量数据并处理生成初始模型。利用昂贵设备的实时方法能够处理这一问题：然而，无法访问的区域仍然会造成最终模型中的孔洞（即未能构建地图的区域）。此外，得到的模型仅代表某个时间点的静态快照。环境中的任何变动，如商店橱窗的翻新，咖啡店遮阳伞的开闭，停车场汽车的去留，都会让数据采集生成的模型瞬间过时。另一个重要方面是通信通道（可能是移动网络）中最终模型的分发方式。由于这些模型通常体积颇大，整体还是拆分传输都会带来技术难题。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　失准及丢失的传感信息。在室外定位中，GPS和指南针提供了关于设备大致位置和方向的极具价值的绝对信息。不幸的是，传感器并不健壮：在不同的地点，传感信息的准确度可能会有天壤之别。尤其是在狭窄的城市峡谷里，GPS信息可能会偏差100米，甚至会不可用。类似的是，磁干扰会严重影响电子指南针的读数，而磁干扰在人造环境中是不可避免的。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　精准定位是AR亟待解决的最为重要的任务。但正如上面所述，仍然存在着一些重大挑战，仍需针对这些挑战寻找真正切实有效的解决方案。近来平板电脑AR的SLAM实施证明，如果上述条件（即纹理结构清晰）达到，就能充分实现小规模环境的定位注3。然而，大规模环境的定位仅存在于概念证明研究中。相关问题似乎难以攻克，因此只能等待技术的缓慢进步了。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">其他挑战</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　除了实现算法研究成果的精度和可扩展性这样的学术目标外，还存在着一系列严重影响AR体验实用性的实际问题。这些因素仅与AR的实际应用相关，因此在科学文献中讨论较少。这或许会造成&ldquo;这些问题不难解决或者与AR的成功不相关&rdquo;的错误认识。下面列举了一些与智能手机有关、同时也与AR一般用途有关的问题：</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　实际的硬件发展与&ldquo;AR心愿清单&rdquo;的矛盾：目前智能手机中相机及其它传感器的质量不足以满足AR的高要求。硬件进步&mdash;&mdash;如立体相机，CPU/GPU的统一随机寻址，WiFi三角定位&mdash;&mdash;能够让AR应用的开发者极大受益。不幸的是，在AR尚未气候成熟时，期待手机会针对AR优化纯属幻想。硬件配置的任何变动会增加数百万美元的开发成本，倘若之后无法满足市场预期，搭上的钱还会更多。目前，消费者购买手机主要是为了语音通讯，游戏和网页浏览。这些市场将会驱动近期到中期的手机功能革新。我们必须说服设备厂家AR是手机应用的新兴市场，这样才能为AR争取到更先进的硬件。幸运的是，如今AR的关注度已成规模，因此不久的将来，手机针对AR的优化或将成为现实。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　动态场景与AR真实感的矛盾。目前的AR应用假设场景中的一切事物都是静态的。然而，现实恰好与之相反。尤其在室外场景中，几乎所有物体都在变化：行人，光照和天气条件，甚至是建筑物每隔几年也会刷上新的颜色。定位会因此受到严重影响。在动态场景中，大多数算法的基本假设从一开始就是错误的。比如说你正在对一个建筑立面进行增强，行人路过挡住了部分视野。由于算法缺少阻挡推理，就算增强内容的视觉效果再好，未来硬件平台的性能再强大，也会出现碍眼的错误。动态物体与虚拟内容之间交互的缺失绝对会损害AR应用的真实感。因此，目前CV研究成果中物体动态检测与跟踪技术的加入是未来实现高质量AR的关键。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　内容创作与注册的矛盾：AR之所以让人兴奋，很大程度上源于终端用户参与内容创作的发展前景。个人内容创作是促使用户积极参与而非被动观察的关键所在。然而，目前仍然没有实现这一概念的基本机制。尽管手机的交互方法得到了极大改进，但在没有精准全局环境模型的条件下，如何使用2D界面方便、精准地注册6自由度内容，这个问题仍未得到解答。就拿增强建筑物里面的一扇窗户举例，目前的方法甚至都无法搞定简单的标记任务。尚没有在开放空间内输入任意3D位置的机制，更别说明确指出方向了。目前决定标签的做法通常利用的是用户（不精准的）GPS位置，而不是兴趣物体本身。对于终端用户创作真实、理想的内容而言，在用户附近对任意位置进行精准注册一定要简单而健壮&mdash;&mdash;然而，这又是一个超出CV基本范畴的研究难题。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun"><span style="word-wrap: break-word; color: #8b0000">以下为AR报告第六章：顺应AR潮流</span></span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　近些年，AR引起了市场营销人员的注意，因为它可能改变消费者的购物体验，例如寻找新产品以及决定购买哪个产品。AR技术可以通过HoloLens 或谷歌眼镜或通过智能手机上的摄像头来将虚拟的元素（例如信息和图片）叠加在真实的物理环境之上。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　但是，要发挥AR的潜力，公司应该克制草率开发AR应用程序的冲动，而把注意力放到深入理解消费者与AR技术互动的方式上来。设计和执行有价值的AR应用程序必须遵守以下几点：</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　深入理解消费者如何使用AR技术；</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　加强电脑专家、设计师和市场营销人员之间的合作；</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　在消费者现有购物体验中整合AR应用程序。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">AR技术的独特性</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　首先，任何公司必须理解AR技术与其他数字技术的区别。虽然它们在某些方面很相似（例如，它们的应用程序都可以在智能手机上使用，内容由文字或图片组成以及应用程序通常具有很强的互动性），但是AR技术也有自己内在的独特性：它能够将虚拟内容叠加在真实的物理环境中，并让这两者实现实时互动。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　曾有一项实验来调查AR如何影响消费者的反应。这个实验总共有60个受试者参加，在这个实验中，受试者需要寻找他们喜爱的太阳镜或家具，他们要么通过（宜家家居或雷朋眼镜）AR应用程序来查找，要么通过那些可以搜索产品但无AR功能的应用程序来查找。实验结果发现，当受试者发现现实环境被实时增强时（例如，看到太阳镜模拟戴在他们脸上的样子，或看到一把椅子摆在虚拟办公室中的情景），他们就会产生一种身临其境的感觉。这种感觉比只看到网络上的太阳镜照片或家居照片要强烈得多。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　这种增强现实体验会让消费者对AR应用程序产生好感，并愿意再次使用这种应用程序以及与别人谈论这种应用程序。但是，这种好感似乎并不能延伸到产品或品牌上。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">应用AR的目的是让消费者对产品产生好感</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　但是，另一项研究表明这种情况是可以改变的，只要巧妙地将AR应用程序整合到消费者的实际购物体验中，实验使用的应用程序可以让消费者涂抹虚拟口红或画虚拟眼影。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　在店里使用这种AR技术可以帮助消费者决定购买什么产品。大多数消费者觉得它很好玩，可以让他们尝试实际化妆难以达到的妆容效果。更为重要的是，当AR应用程序整合进类似的虚拟零售店环境的时候，消费者不仅对这种AR技术产生了好感，而且对于产品也产生了好感。现在，他们更可能购买这些产品，并将AR应用程序看做是购物的便利工具，而不仅仅是用来娱乐的工具。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　另一项研究表明，当受试者频繁在其手机上使用AR化妆应用程序的时候，他们也会对AR技术和产品同时产生好感。他们认为，AR应用程序不仅好玩，而且很方便用来购买化妆品。这种好感往往会促使他们购买他们试用过的化妆品。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　总的说来，如果AR体验是一次性的，那么它可能只会把消费者的注意力引向这种技术本身。但是，如果它能够很好地整合到消费者的购物环境或购物过程中，那么它就能够积极地影响消费者的购买行为。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　值得指出的是，由于在实验中售货员邀请了消费者来使用AR设备，并教了他们如何使用它，因此现在我们尚不清楚如果没有售货员的帮助消费者是否就会得到不一样的体验。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　应用AR的关键在于给消费者创造价值</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　市场营销人员应该记住，AR并没有创造全新的虚拟现实；它只是在现实情境中添加了一些虚拟的元素。当这些虚拟的元素与实际环境完全契合和互动的时候，AR的神奇效果就出现了。与虚拟现实（例如Oculus Rift）让你完全沉浸在不一样的世界中不同，AR只会在特定情境的现实环境中添加必要的虚拟元素（最新的例子就是HoloLens的全息传送功能）。这就是人们喜爱阅后即焚照片应用Snapchat新推的AR功能的原因之一。它的AR功能可让用户利用不同视觉效果将普通的视频转变成可以分享的信息。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　AR体验的关键在于这种技术是否能够给消费者创造价值。简单地将虚拟的信息叠加在手机屏幕上并不能给它加分，而且这使得它看起来就像一个花哨无用的噱头。扫描某品牌的商标，然后你的智能手机屏幕上就会弹出相关的广告信息。这样体验在一开始可能会让消费者觉得好玩，但很快会让他们感到厌烦。同样的，当你把手机摄像头对准街道上的不同店面或商店里的不同产品时，AR应用程序就会把相关信息和促销活动呈现在你的手机屏幕上。这听起来似乎很有用，但是市场营销人员需要问问自己：消费者真的会高举着平板电脑或智能手机逛街吗？他们真的想通过扫描的方式来购买任何产品吗？</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　现在，这个问题的答案是否定的。人们只有觉得在早已饱和的数字空间里叠加虚拟信息是值得的，他们才会愿意这样做。因此，多想想他们愿意这样做的情境吧：例如，参加某个文化活动，参观某个城市景点或历史遗址；或深入了解他们真正喜欢的某个奢侈品或品牌。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　AR技术商业化的真正使命是整合AR技术提高消费者体验，让他们的购物过程更轻松、更有趣以及更便利。我们并不想生活在一个完全用虚拟环境取代了真实环境的世界中。谷歌眼镜Google Glass失败的真正原因就在于我们不想走在大街上看到一切现实环境都被增强了。（微软的全息眼镜HoloLens则是另一码事，因为它设计的目的是为了用到特殊的场合，例如会议室或工作间）。因此，我们不是要想方设法地给尽可能多的地方提供虚拟内容，而是要弄明白哪些情境下的虚拟叠加信息可以给消费者创造价值。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun"><span style="word-wrap: break-word; color: #8b0000">　以下为AR报告第七章：AR应用案例</span></span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　在这一章中，我们将探索AR这一新兴技术目前在不同领域的运用情况，并预测有可能成为未来主流的最佳实践。我们选取了一定数量的AR创新案例，归纳成四种功能类别；每一种都会在个人或公司使用AR应用时为其带来显著益处。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">情境敏感式信息&mdash;&mdash;在恰当的事件地点出现的信息</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311787" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115952ii2foxy5zalo2lfr.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　第一类是情境敏感式信息，涵盖能够根据特定情境轻松获取互联网已有静态数据的各种应用。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　Wikitude和Metaio公司的Junaio（魔眼）是AR浏览器两个最有名的例子，它们提供的情境敏感式信息软件能够识别场所或物体，并将数字信息与现实世界的场景连接起来。智能手机都可以运行这一软件，用户可以通过手机摄像头的视角看到周围的数字信息。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　这些数字信息可以是附近感兴趣的地方，比如博物馆、商店、餐馆或者前往下一个公交站的步行路线。该软件通过GPS、WiFi和3D建模实现图像识别和用户定位功能。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311788" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115952oydzgt31plt74ygb.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　语言翻译是AR应用中最具发展前景的领域之一。现有的一款应用Word Lens兼容于几乎所有智能手机，能够将文本同步翻译成另一种语言。打开应用后，用户只要将设备对准外国文字即可。设备就会将此信息翻译成用户母语并显示出来。而且翻译后的文本是同样的字体，印在同一面墙上&mdash;&mdash;就跟原始文本一样。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311789" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/1159521e1bw1vawygezfbd.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　面部检测和AR的结合则是在现实生活特定情境中轻松获取互联网信息的另一个例子。Infinity是一款AR应用，它可以分析一张面孔，将其与社交网络（如Facebook）上的头像进行比对匹配，匹配目标在社交网络中发布的信息就会显示在用户视野中。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　这项功能在消费应用领域非常实用的技术也会受到执法部门的欢迎（如扫描人群，寻找通缉犯）。但不难理解，这款应用已经引发了许多人对隐私的担忧。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311790" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/1159527gtju0yy7zjy7r7q.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　大众公司开发的MARTA系统是汽车领域中在恰当地点提供恰当信息的极具可行性的最佳实践解决方案。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　该系统在汽车运转失常时派上用场，帮助用户进行汽车维修及维护。它能通过物体识别技术识别出汽车零部件，实时详细地将所有必需的维修、维护步骤描述并图示出来，并配有需要用到哪些设备的信息。这款应用可以在多种移动设备上运行。目前，该系统为大众服务独家使用，不过可以想象，未来消费者都会用上类似的系统，不太了解汽车机械的人都能修好自己的汽车。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">增强感知&mdash;&mdash;成为人类2.0</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　即便是今天，AR应用所能提供的也远不止是随时检索互联网信息这么简单。下面讲述的几个AR用例通过主要由设备传感器收集的数据生成新的信息，实现增强现实。这一系列设备能够增强我们的感知，延伸人类能力，超越目前我们所能取得的成就。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311791" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/1159522pvwq9xo9m7soxsm.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　已经问世的Recon Jet是一套用于休闲活动的AR系统。该设备便于运动的平视显示器（HUD）可以与蓝牙、WiFi等第三方传感器连接，提供导航和天气信息，访问社交网络，显示实时的状态信息。例如，跑步者可以看到自己的速度，到终点线的距离，目前的海拔提升高度以及心率。目前已有上述功能的Recon Jet计划未来针对在危险环境中工作或从事体力劳动人群开发可穿戴AR设备，监测他们的生命体征和周围环境。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311792" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115952wljg29gz1bqz1jzl.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　再举一个平视显示器的例子，某些型号的宝马汽车能够在挡风玻璃上投影行驶速度等传感信息。这种增强感知功能自从2004年以来被汽车公司所采用，宝马正在不断增加新功能，持续改进其HUD系统。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　宝马目前的ConnectedDrive HUD系统的增强方式是在外部环境真实物体上叠加虚拟标记。这样导航信息或者驾驶助手系统的信息可以显示在司机前方道路视野的精确位置上。导航指示可以层叠在道路上，其它汽车或安全相关的物体可以根据情况高亮显示或标记出来。宝马夜视系统提供的可视化信息正是HUD应用的绝佳例证。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311793" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115953wze8mn8besj28ke9.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　屡获殊荣的iOnRoad应用是一个类似于宝马HUD的增强驾驶助手系统，只不过面向平民大众市场，也没那么先进。该应用仅使用智能手机相机和一些视觉算法，提供了诸如碰撞预警、出口监测、道路出界预警以及事故后能派上用场的黑匣子录像功能。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311794" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/1159530eeg4m0gdq8dt8qj.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　Liver Explorer是AR应用在另一个截然不同的领域中的例证。外科医生可以通过Fraunhofer MEVIS公司开发的Liver Explorer应用增强感知。该应用能够为执业医生提供实时的AR向导和辅助。设备通过摄像头捕捉肝脏影像，利用AR技术将手术计划的数据叠加到器官上。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　另外，该软件还能实时响应（如根据系统持续追踪的血管运动状态及时更新手术计划）。这些功能超越了MARTA系统对于情境敏感式信息的定义。如果该应用能得到积极评价的话，未来很可能会改造推广到更多的手术领域中。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311795" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115953vfu9r7ru9e6z99p9.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　在危险情况下，随时掌握关键信息尤为重要。正因为如此，军方成为了AR应用最大的投资者之一。Q-Warrior Helmet是一款军事应用。该AR项目希望能为士兵们提供&ldquo;保持警惕，视野开阔，手搭扳机&rdquo;的场景意识，以及敌我识别、夜视影像和远程协调小分队的增强功能。该头盔会将每个佩戴者的具体位置信息提供给其他人，军事组织可以通过它在战斗或侦查行动中集结、行军、分享信息与位置。不难想象，未来类似的系统会出现在其他工作环境危险的职业中（如消防员、执法人员）。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">混合现实模拟&mdash;&mdash;在现实中探索虚拟</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　上述案例以提供静态数字信息的方式为我们展示了增强现实的应用，然而接下来这一类的AR实践相比之下更进了一步。通过这些所谓的混合现实模拟，用户可以在现实环境中动态地更换或调整虚拟物体。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311796" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115953sa1vvo1jo2m71rya.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　最新的宜家应用Ikea Catalog就是其中最为突出的一个例子。借助于这个由Metaio公司开发的AR应用，消费者可以使用移动设备把所选的数字版宜家家具&ldquo;放置&rdquo;在自己家客厅里，从而更方便地测试家具的尺寸、风格、颜色摆在某个位置是否合适。该应用还允许用户调整每一个部件的尺寸和颜色。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311797" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115953xopo16un5rnzy6rn.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　优衣库的试衣魔镜（Magic Mirror）提供了一种更加个人化的AR试衣体验。2012年旧金山的一家优衣库门店安装了这台大型增强试衣镜，它能够识别顾客的身材和所选衣物，因此免去了再试其它颜色的必要。顾客只需换上某件衣物站到镜子前；根据触摸屏的提示选择其它颜色，镜子中就会投射出顾客身着另一种颜色的影像。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311798" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115954ga3onrla734urcel.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　佳能推出的MRERL系统能够实现3D电脑渲染模型在现实环境中与现实世界物体无缝融合的设计过程。举例来说，汽车领域可以借助于这套系统设计出新汽车的模型。MREAL系统支持多用户协同工作，同步进行完整规模的产品设计。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　这套系统可以用来分析新规划设计中现实部件如何组合的问题。其实现方式是，渲染出包括现有部件和新设计概念的3D模型，再将两者组合起来。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　例如，可以将现有的汽车座椅整合到新车虚拟设计的投影中。MREAL系统提供的是混合现实，因此用户可以真的坐到（真实的）座椅上，看到汽车外面的真实环境以及汽车内部的数字虚拟模型&mdash;&mdash;包括全新设计的仪表盘和方向盘。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311799" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115954qyl6gbqa6i26qud8.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　另一个已投入使用的工业级AR应用来自空中客车公司（Airbus）。为了能够完全依靠数字工具完成新飞机的生产流程，空中客车公司于2009年联合打造了MiRA（混合现实应用）。该应用利用AR扫描部件、检测错误，从而提高了生产线的效率。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　以A380客机为例，由平板PC、特制传感套件和软件组成的MiRA应用现在已将组装机身中成千上万个支架的时间由300小时降低至惊人的60小时。更为震撼的是，之后发现，损坏、安装错位或者遗失支架的数量却降低了40%。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311800" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115954q2t6a84ae26ax468.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　我们可以展望一下若干年后AR应用的样子。日本的一位黑客利用现有的3D模型和廉价的动作传感器实现了与日本超人气虚拟歌手初音未来的AR&ldquo;约会&rdquo;。在演示视频中，初音陪着他漫步公园，初音能够识别现实世界的物体并做出反应（比如坐在真实的长椅上）。该软件甚至还能与这位虚拟歌手互动（比如摸摸她的头或领带）。尽管这个应用有着明显的煽动性，但它绝非只是噱头。由此我们可以想到，不久之后人们或许会有虚拟伴侣的陪伴，在需要时提供帮助（比如，辅助搞定医疗或工程问题，或者以人形界面的形式处理个人日历、备忘录、通讯录等日常数字事务）。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　虚拟界面&mdash;&mdash;在虚拟中控制现实</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　接入互联网&ldquo;智能&rdquo;玩意儿越来越多，获取数字信息的方式越来越多，于是打算利用AR设备及数据来工作的人也越来越多。因此，我们讨论的第四类&mdash;&mdash;虚拟界面，关注的是提供以数字形式控制现实世界物体的新方式的AR技术。本质上说，这类技术让调整、控制真实物体的混合现实成为可能。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311801" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115954b6je0letubuxbxtt.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　手势是一种随时与数字世界进行交互的高级方式。上文所说的麻省理工学院开发的SixthSense正是这么一种手势界面系统。尽管该系统目前采用的是空间AR技术，它也可以应用于其它各种技术中。借助于该系统，用户可以使用自然手势与信息进行交互。为了捕捉用户的输出意图，该系统的相机采用计算机视觉技术对用户手势进行识别和追踪。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311802" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115954wmrstf8dqovvvmzt.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　基于AR的界面不局限于计算机设备。还能用来控制汽车，娱乐设备，以及加热系统这样的家居配套设施。仍在开发之中的家庭自动化系统Revolv正是这样的例子。结合Google Glass后，用户可以通过该系统控制家中的所有数字设备（如照明系统和门锁系统）。于是就形成了可以用语音或指尖控制的增强&ldquo;智能&rdquo;家居环境。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311803" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115955v0i3uuczuzvimhvk.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="600" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　中国电商1号店的例子告诉我们，虚拟界面也不局限于家中。该公司曾宣布，将成立全球第一个AR连锁超市。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　每一家超市将会有一块约1.2平方米的货架，设置在&ldquo;空白&rdquo;的公共区域（比如火车车站或地铁车站，公园或大学校园）。裸眼看去只是空荡荡的货架和墙壁，通过AR设备看到的则是完整的一个超市，货架上堆满了数字形式的真实商品。用户只需通过移动设备扫描商品，添加到网络购物车中，即可完成购买。AR购物完成后，用户会在家中收到配送的商品。这个概念类似于韩国地铁站里基于二维码的乐天超市，但得到了AR技术的增强。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　应用详解：物流中的AR</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　上面我们将各种各样的最佳实践分为四类，接下来我们将以物流产业为例，具体说明一下AR技术奖发挥怎样的影响。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　虽然AR在物流业中的采用仍处于相对早期阶段，但AR也能提供巨大的益处，例如AR可以让物流供应商随时随地快速获预期信息。这对于配送及优化配载等任务的精确规划和细致运作来说至关重要，同时也能为提供更高质量的客户服务打下坚实基础。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　报告将其它行业里我们所认为的最佳实践移植到物流中，由此为AR在物流业中的应用设想了一些用例。在这里拿出来阐述的用意更多的是借此展开讨论、眺望未来，而不是对未来AR在物流业中的发展做出精确预测。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　这些用例分为以下四类：</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　仓库运作</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　运输优化</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　最后一公里配送</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　强化增值服务</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">仓库运作</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　仓库运作是AR在物流中最具应用前景的领域。这些运作大约占到物流总成本的20%，而拣货任务占到仓库运作总成本的55%到65%。AR可以由改进拣货流程入手，大幅降低运作成本。AR还有助于培训仓库新员工及临时员工，并为仓库规划提供参考。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　视觉拣货（Pick-by-vison）：优化拣货流程</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　在物流中，最切实际的AR解决方案要数能够优化拣货流程的系统。发达国家里，绝大部分仓库仍采用纸质拣货（pick-by-paper）的做法。但任何基于纸质的做法都是低效、易错的。另外，拣货工作往往由临时工完成，这些人通常需要耗费成本进行培训，以确保他们能够高效拣货，不犯错误。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　Knapp、SAP和Ubimax共同研发的视觉拣货系统目前处于最后的现场测试阶段，该系统包括头戴式显示器（HMD）之类的移动AR装置，相机，可穿戴PC，以及续航至少为一班次时长的电池模块。其视觉拣货软件功能包括实时物体识别，条形码读取，室内导航，以及与仓库管理系统（Warehouse Management System，简称WMS）的无缝信息整合。视觉拣货带来的最大好处是，仓库工在人工拣货时无需腾出手来即可获得直观的数字信息支持。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　借助于这样的一套系统，每位仓库工都能在视野中看到数字拣货清单，还能受益于室内导航功能，看到最佳路径，通过有效路径规划减少移动耗时。该系统的图像识别软件能自动读取条形码以确认仓库工是否到达正确位置，并指引他在货架上快速定位待拣物品。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　接着，仓库工可以扫描该物品，将此流程同步登记到仓库管理系统中，实现实时的库存更新。另外，诸如此类的系统能够降低新员工的培训耗时，还能为文化水平有限的仓库工解决可能遇到的语言障碍问题。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　这些AR系统的现场测试已经证明，它们为仓库运作的效率提升做出了巨大贡献。举例而言，持续的拣货验证功能可以减少40%的错误。尽管如今的拣货错误率非常低，即使用的还是纸质拣货方法&mdash;&mdash;专家估计错误率约为0.35%&mdash;&mdash;但每一个错误都必须避免，因为每一个错误都会带来高昂的连锁代价。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　拣货人员佩戴专为拣货流程开发的可穿戴AR设备。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311804" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115955eb8ft8uo0cbpeb20.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="418" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　该解决方案提供数字导航，有助于更加高效地找到正确路径和正确物品，同时降低培训时间。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　主要目的：减少拣货错误，降低查找时间。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">仓库规划</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　AR很可能还会对仓库规划流程产生积极作用。如今的仓库不再只是存放和集散的节点；它们逐渐地肩负起越来越多的增值服务，从产品的组装到贴标签、重新打包，乃至产品维修。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　这意味着仓库必须重新设计以适应上述这些新服务的需求。可以用AR从全局角度直观地看到任何重新规划的效果，实现在现有的真实仓库环境中放置将来准备改动的可交互数字模型。管理者可以检查所规划的改动尺寸是否合适，并为新的工作流程建立模型。受益于此，未来的仓库实地可以用作仓库运作规划的试验场所。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　实现仓库运作流程的混合现实模拟。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311805" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115955q4q1j34qjz4353wq.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="422" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　改动可以叠加在真实环境中，从而做到&ldquo;现场测试&rdquo;，并因地适宜，调整所规划的尺寸。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　主要目的：支持仓库的重新设计与规划，并降低成本。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　运输优化</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　过去十年中，物流供应商对高新信息技术的运用极大地提高了货物运输的时效性、可靠性和安全性。在完整性检查、国际贸易、司机导航和货物配载等领域，AR有着进一步优化货物运输的潜力。</span><br /><br /><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　完整性检查</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　AR可以实现更加高效的分拣。佩戴AR设备的拣货员快速扫视一下配载，就能知道是否完整。目前，这项工作需要人工统计，或是用手持设备花大量时间逐个扫描条形码。未来，可穿戴AR设备利用扫描仪和3D景深传感器的组合，就能确定货盘或包裹的数量（通过扫描每个包裹上的特殊标识），或者确定包裹的体积（通过测量设备）。测量值与预定义值相比较，结果呈现在拣货员眼前&mdash;&mdash;最好两者一致。此类AR系统还可以扫描物品，检测是否有损坏或错误。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311806" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115955ydz1906udu16un60.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="425" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　AR设备能够登记一批货物是否完整、可供分拣。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　通过标识或先进的物体识别技术，捕捉货盘和包裹的数量、体积。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　识别到无损包裹数量正确后，AR自动确认、交付分拣。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　主要目的：节省时间，完整性检查，损坏检测。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">国际贸易</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　随着全球越来越多的地区经济开始腾飞，往来于新兴市场的运输量正在显著增长。这是物流供应商的巨大商机，但同时也增加了物流的复杂程度，原因在于世界各地的贸易条例及要求之间存在着巨大差异。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　AR也许能在这方面为全球贸易服务供应商们提供价值。在发货前，AR系统可以帮助检查货物是否符合相关的进出口条例，或者帮助检查贸易文件填写是否正确、完整。AR设备可以扫描文件或货物搜寻关键词，自动给出修改建议或自动纠正商品编码分类。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　在发货后，AR技术可以实时翻译贸易术语等贸易文件文本，从而大幅减少耽误在港口和储存上的时间。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311807" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115955wm4omde11ew24opo.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="418" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　为全球的贸易服务供应商提供AR支持。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　AR设备可以检查（打印版）贸易文件并识别商品编码分类。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　实时翻译包裹标签或外国贸易术语。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　主要目的：加快贸易文件和国际货物的处理速度。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">动态交通支持</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　很多严重依赖于实物商品畅通流转的经济流程往往受制于交通拥堵。据估计，交通拥堵每年让欧洲损失了约1%的国内生产总值（GDP），而且随着拥堵的愈发严重，人们愈发需要能提高正点率的解决方案。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　未来我们将看到，提供实时交通数据从而优化路线（或在货物运输过程中重新规划路线）的动态交通支持会越来越普遍地应用于物流业中。AR驾驶助手应用（无论是显示在眼镜上还是挡风玻璃上）能够实时地在司机视野中呈现信息。实际上，AR系统将会成为目前导航系统的继承者，其关键优势在于司机的视线不用离开道路。AR系统还能为司机显示车辆和货物的关键信息（如货物温度）。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311808" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115955lcn9cd2ld72h7j69.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="419" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　在运输车辆中使用AR设备（眼镜或挡风玻璃投影）代替传统导航系统。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　分析实时交通数据，在司机视野中显示相关信息（如拥堵情况以及代替路线）。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　叠加显示周围、车辆及货箱的关键信息（如冷箱的温度）。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　主要目的：行驶过程中优化路线，改善驾驶安全，把让司机分心的因素降至最低。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">货运配载</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　如今，空运、水运及陆运这些货运方式高度依赖于数字数据和规划软件，以达到优化配载规划和提高车辆利用率的目的。每件货物的内容，重量，大小，目的地及后续处理都属于系统的考虑因素。即便系统或许还存在进一步改进的空间，货运配载的瓶颈往往是配载流程本身。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　AR设备可助其一臂之力，它能够取代打印版的货物清单和配载说明。比如说在中转站里，配载员可以在AR设备上实时得知接下来该取哪个包裹，这个包裹应该放在车上的哪个位置。AR设备能够以箭头或在货车内部高亮显示适当目标区域的方式，为配载员提供配载指引。这一信息要么由规划软件事先生成，要么依赖于特定物体识别技术的实时计算。后一种方法可以用风靡全球的电脑游戏《俄罗斯方块》来解释，在这个游戏中，玩家必须根据下一个随机物体的形状，将它放置在恰当位置，从而尽可能填充空间、避免间隙。与目前纸质清单不同的是，基于AR的货物清单还能支持各种实时操作&mdash;&mdash;这在配载过程中时有发生。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311809" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115956v8bg8cct783sq7rq.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="420" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　使用AR设备优化货运配载。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　配载员直接从AR设备显示屏商直接接收规划及指示（接下来拿哪件包裹、将它放在哪里）。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　让打印版的配载清单变得无关紧要。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　主要目的：加快货运配载流程。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">最后一公里配送</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　最后一公里是AR技术的另一个重要应用领域。人们对电子商务不断增长的依赖使得最后一公里配送服务呈爆炸式增长，这是供应链的最后一个环节，往往也是成本最高的一个环节。因此，在优化最后一公里配送以降低成本、提高利润这一领域中，AR设备的应用前景一片光明。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">包裹配载及送达</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　据估计，司机离开配送中心后有40%到60%的时间不在开车。这段时间，他们都在货箱里寻找接下来要配送的包裹。目前的物流行业中，司机想要找到包裹，只能靠自己对配载过程的深刻记忆。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　未来在配送中心，每个司机通过AR设备看一下包裹，就会接收到该包裹的关键信息。该信息可包括运输商品的种类，每个包裹的重量、配送地址，是否易碎，是否需要正确摆放以避免损坏。接着，AR设备会实时计算每个包裹的空间需求，扫描车辆货箱寻找合适的空位，然后提示司机应该将包裹摆放在哪个位置，并记入规划路线中。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　在高效智能的包裹配载以及AR设备为司机高亮显示正确包裹的帮助下，查找流程将会方便快捷得多，极大地节省了每一次配送的时间。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　另外，AR还有助于减少包装损坏事件。目前包裹损坏的一个关键原因是，司机需要腾出手来关车门，只能将包裹放在地上或夹在胳膊里。有了AR设备，无需用手就能关上车门&mdash;&mdash;司机可以通过语音或者眼球/头部的动作发送命令。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311810" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115956t7ky7nbx1thn9bb1.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="420" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　员工借助于可穿戴AR设备完成包裹处理、配载及配送的流程。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　透过AR设备看，所有包裹上都叠加了关键信息（如内容，重量，目的地）及处理指示，而且包裹经过智能配载，装在车厢里。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　主要目的：改进处理流程，避免不当处理，确保配载优化。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">最后一米导航</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　司机关上车门，手里拿着正确包裹，往往接下来会面临如何找到对应建筑的难题。第一次配送到某个地址时尤其如此，因为会存在许多的复杂因素，比如门牌号或街道名牌被遮挡或遗失，入口隐藏在后院里，或者像很多发展中国家那样，街道和建筑没有根据规则命名。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　在这样的情况下，AR可以起到极大的帮助；司机将AR设备指向某个建筑或建筑群，它会显示出谷歌街景之类的信息，或源自其它数据库的相关详情。如果在公共数据库中找不到可用信息，还可以使用AR设备根据入口位置或其它当地特征来放置标记，从而逐渐建立起一个独立的数据库。下一次再配送到这个地址时，AR设备会访问之前收集的数据；同时渲染相应的虚拟信息图层。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　有些时候，最后一米配送需要用到室内导航。尽管GPS导航在户外非常好用，但建筑物往往会对GPS信号造成严重干扰。学习型AR设备在建筑物内部多个点位放置LLA（经度、纬度、海拔）标记是一种可行的解决方案。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311811" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/115956za558ayowup1lpa5.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="412" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　AR设备识别建筑物及入口，并提供室内导航，从而实现更快送达。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　学习型AR系统能够添加用户生成内容（UGC），尤其是在公共数据库不可用时。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　主要目的：高效的室内导航，减少寻找地址和送达包裹的时间，尤其是在首次配送至某地址时。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">经AR验证安全的包裹交付</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　让员工佩戴AR设备还能够改善安全性，提高客户接触的质量。在面部识别技术的帮助下，签收包裹的人无需出示任何身份证件即可被精确识别。AR设备会拍照并自动与社保数据库进行比对。考虑到数据隐私问题，需要在得到签收人许可的前提下才能使用这种AR面部确认技术。普通的日常配送或许用不上这种服务，但在包裹价值不菲的时候，用户就会感受到更高安全级别的好处，因为它与易于伪造的身份证或收件人签名相比要可靠得多。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311812" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/1159562lawvjuvmaopp9uc.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="420" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　AR利用面部识别技术对包裹签收人进行精确识别。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　取代身份证或签名，完成可视化的批准/拒绝签收。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　主要目的：提高挂号信的安全性，加快配送流程。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　服务需要事前得到批准并完成注册。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">强化增值服务</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　除了帮助物流供应商改进流程以外，AR还能使其开展新的客户服务（如组装、维修），并为其提供新型的客户支持工具。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">组装与维修</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　越来越多的物流供应商开始为客户提供组装、维修这样的增值服务。举例而言，物流方不仅从奥迪的零件供应商收取材料，还将这些零件组装成汽车门内板，然后配送至位于德国的奥迪生产车间。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　目前，这样的任务需要技术工人来完成，而且每一种任务都需要进行单独培训。不过，将来的AR可以培训并帮助仓库员工组装各种产品，并确保组装服务的高标准，进而为客户降低成本。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　AR系统能够监视每个工作步骤（借助于增强图像识别技术）并检测组装流程中的错误，从而保证质量控制。对于维修人员而言，AR系统可以提供一种直观的视觉方式，帮助他们识别并修复问题&mdash;&mdash;考虑到终端消费技术和终端消费电子产品数量的不断增长，这一点显得尤为重要。此类交互式维修指南的投入使用可以显著降低培训成本以及技术员工的平均修复时间。</span><br /><br /><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px" align="center"><img id="aimg_311813" style="word-wrap: break-word; cursor: pointer; max-width: 620px" class="zoom" src="http://www.gameres.com/data/attachment/forum/201604/26/1159563vtmv1zyu1ktma3a.jpg" border="0" alt="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." title="全球首份AR报告 2万字告诉你它为什么比VR还酷 ..." width="424" /></p><p style="word-wrap: break-word; margin: 0px; padding: 0px; font-family: Tahoma, 'Microsoft Yahei', Simsun; font-size: 16px; line-height: 28.8px"></p><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　组装与维修团队配备有支持特定任务的无需用手的AR设备（眼镜）及软件。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　其软件为组装或维修工作提供了可视化的逐步工作指导，同时解放每位工人的双手，以便他们按照指导执行步骤。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　主要目的：质量控制，显著降低培训成本。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　</span><span style="word-wrap: break-word; font-weight: 700; font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　客户服务</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　不久的将来，加入AR功能的包裹服务应用可以让客户使用支持AR的设备扫描待寄物品，测量体积，估算重量，从而确定选用物流供应商尺寸最合适、价格最低廉的包裹盒。另外，该应用还能显示不同的寄件方式和保价选项。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　尽管类似这样的复杂应用尚未出现，不过目前有一个可用的简易版。DHL Paketassistent注释11应用让用户打印一张纸，上面有一个类似于二维码的图标。相机扫描该图标后，DHL可选包裹盒的全息模型就会投影在用户面前，以便用户比对物品、选择合适尺寸的包裹盒。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　针对终端消费设备（如智能手机、平板电脑）的AR应用可以带来便利的寄件体验。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　主要目的：扫描待寄物品，将包裹盒的虚拟呈现与扫描图像相层叠，帮助客户选择合适的寄件方式并下单；提升包裹处理环节。</span><br /><br /><span style="font-size: 16px; line-height: 28.8px; font-family: Tahoma, 'Microsoft Yahei', Simsun">　　总而言之，AR在物流业中有着远大的前程。从仓库里的视觉拣货，到帮助客户进行售后服务，显然AR能够在物流价值链的几乎所有环节中发挥作用。尽管上述用例目前只有少数得到了开发，但物流业中的AR应用正在出现鼓舞人心的&ldquo;星星之火&rdquo;迹象。这一趋势将会持续增长，我们希望更多的物流供应商能够加入进来，共同推动AR革命。</span>
]]>
</description>
</item>
</channel>
</rss>