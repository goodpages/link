<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">
<channel>
<title><![CDATA[流浪的龙－个人知识管理]]></title> 
<link>http://i.renjihe.com/blog/index.php</link> 
<description><![CDATA[]]></description> 
<language>zh-cn</language> 
<copyright><![CDATA[流浪的龙－个人知识管理]]></copyright>
<item>
<link>http://i.renjihe.com/blog/read.php?7495</link>
<title><![CDATA[尺度空间（Scale space）理论]]></title> 
<author>renjihe1988 &lt;admin@yourname.com&gt;</author>
<category><![CDATA[CV&amp;Graphic]]></category>
<pubDate>Tue, 23 Aug 2016 12:43:26 +0000</pubDate> 
<guid>http://i.renjihe.com/blog/read.php?7495</guid> 
<description>
<![CDATA[ 
	<p style="color: #333333; font-family: Arial; font-size: 14px; line-height: 26px"><strong>尺度空间方法的基本思想是：</strong><span style="word-wrap: normal; word-break: normal; line-height: 21px; font-family: simsun; color: #494949">在视觉信息处理模型中引入一个被视为尺度的参数，通过连续变化尺度参数获得不同尺度下的视觉处理信息，然后综合这些信息以深入地挖掘图像的本质特征。尺度空间方法将传统的单尺度视觉信息处理技术纳入尺度不断变化的动态分析框架中，因此更容易获得图像的本质特征。尺度空间的生成目的是模拟图像数据多尺度特征。高斯卷积核是实现尺度变换的唯一线性核。</span></p><p style="color: #333333; font-family: Arial; font-size: 14px; line-height: 26px"><strong>尺度空间理论的动机：</strong></p><ul style="font-size: 14px; margin: 0px; padding: 0px; border: 0px; list-style-type: none; list-style-position: initial; color: #494949; font-family: simsun; line-height: 21px"><li style="margin: 0px 0px 0px 30px; padding: 0px; border: 0px; list-style-type: disc; list-style-position: initial">现实世界的物体由不同尺度的结构所组成；</li><li style="margin: 0px 0px 0px 30px; padding: 0px; border: 0px; list-style-type: disc; list-style-position: initial">在人的视觉中，对物体观察的尺度不同，物体的呈现方式也不同；</li><li style="margin: 0px 0px 0px 30px; padding: 0px; border: 0px; list-style-type: disc; list-style-position: initial">对计算机视觉而言，无法预知某种尺度的物体结构是有意义的，因此有必要将所有尺度的结构表示出来；</li><li style="margin: 0px 0px 0px 30px; padding: 0px; border: 0px; list-style-type: disc; list-style-position: initial">从测量的角度来说，对物体的测量数据必然是依赖于某个尺度的，例如温度曲线的采集，不可能是无限的，而是在一定温度范围进行量化采集。温度范围即是选择的尺度；</li><li style="margin: 0px 0px 0px 30px; padding: 0px; border: 0px; list-style-type: disc; list-style-position: initial">采用尺度空间理论对物体建模，即将尺度的概念融合入物理模型之中。</li></ul><a style="color: #378550; text-decoration: none; font-size: 14px; font-family: simsun; line-height: 21px" href="http://en.wikipedia.org/wiki/Scale-space_axioms" target="_blank">尺度空间公理</a><span style="font-size: 14px; line-height: 21px; font-family: simsun; color: #494949">：</span><br /><ul style="font-size: 14px; margin: 0px; padding: 0px; border: 0px; list-style-type: none; list-style-position: initial; color: #494949; font-family: simsun; line-height: 21px"><li style="margin: 0px 0px 0px 30px; padding: 0px; border: 0px; list-style-type: disc; list-style-position: initial">线性</li><li style="margin: 0px 0px 0px 30px; padding: 0px; border: 0px; list-style-type: disc; list-style-position: initial">平移不变性</li><li style="margin: 0px 0px 0px 30px; padding: 0px; border: 0px; list-style-type: disc; list-style-position: initial">半群特性：<span style="word-wrap: normal; word-break: normal"><em>g</em>(<em>x</em>,<em>y</em>,<em>t</em><sub>1</sub>) *&nbsp;<em>g</em>(<em>x</em>,<em>y</em>,<em>t</em><sub>2</sub>) =&nbsp;<em>g</em>(<em>x</em>,<em>y</em>,<em>t</em><sub>1</sub>&nbsp;+&nbsp;<em>t</em><sub>2</sub>)</span></li><li style="margin: 0px 0px 0px 30px; padding: 0px; border: 0px; list-style-type: disc; list-style-position: initial"><span style="word-wrap: normal; word-break: normal">旋转不变性</span></li><li style="margin: 0px 0px 0px 30px; padding: 0px; border: 0px; list-style-type: disc; list-style-position: initial"><span style="word-wrap: normal; word-break: normal">尺度不变性</span></li><li style="margin: 0px 0px 0px 30px; padding: 0px; border: 0px; list-style-type: disc; list-style-position: initial"><span style="word-wrap: normal; word-break: normal">正定性</span></li><li style="margin: 0px 0px 0px 30px; padding: 0px; border: 0px; list-style-type: disc; list-style-position: initial"><span style="word-wrap: normal; word-break: normal">正规性(积分为1)</span></li><li style="margin: 0px 0px 0px 30px; padding: 0px; border: 0px; list-style-type: disc; list-style-position: initial"><span style="word-wrap: normal; word-break: normal">不会引入新的极点</span></li><li style="margin: 0px 0px 0px 30px; padding: 0px; border: 0px; list-style-type: disc; list-style-position: initial"><span style="word-wrap: normal; word-break: normal">不会增强极点</span></li><li style="margin: 0px 0px 0px 30px; padding: 0px; border: 0px; list-style-type: disc; list-style-position: initial"><span style="word-wrap: normal; word-break: normal">存在无穷小的算子（可微性）</span></li></ul><span style="font-size: 14px; word-wrap: normal; word-break: normal; line-height: 21px; font-family: simsun; color: #494949">按照以上条件，唯一可能的尺度空间核函数是高斯核函数。<br /><br /><span style="word-wrap: normal; word-break: normal; font-weight: bold">热扩散方程：</span><br />根据微分方程理论，以上核函数家族可以表示成如下热扩散方程的解：<br /></span><dl style="font-size: 14px; margin: 0px; padding: 0px; border: 0px; list-style-type: none; list-style-position: initial; color: #494949; font-family: simsun; line-height: 21px"><dd style="margin: 0px; padding: 0px; border: 0px; list-style-type: none; list-style-position: initial"><img style="border: 0px; max-width: 100%; margin: 0px; padding: 0px; list-style-type: none; list-style-position: initial" src="http://upload.wikimedia.org/math/4/9/c/49c90789e2b059551f83d43882ea919c.png" border="0" alt="&#92;partial_t L = &#92;frac&#123;1&#125;&#123;2&#125; &#92;nabla^2 L," title="尺度空间（Scale&nbsp;&lt;wbr&gt;space）理论研究笔记" />&nbsp;初始条件是<span style="word-wrap: normal; word-break: normal"><em>L</em>(<em>x</em>,<em>y</em>;0) =&nbsp;<em>f</em>(<em>x</em>,<em>y</em>)</span></dd></dl><strong style="color: #333333; font-family: Arial; font-size: 14px; line-height: 26px">多尺度边缘检测和blob检测：</strong><br /><ul style="font-size: 14px; margin: 0px; padding: 0px; border: 0px; list-style-type: none; list-style-position: initial; color: #494949; font-family: simsun; line-height: 21px"><li style="margin: 0px 0px 0px 30px; padding: 0px; border: 0px; list-style-type: disc; list-style-position: initial">梯度算子用于边缘检测</li><li style="margin: 0px 0px 0px 30px; padding: 0px; border: 0px; list-style-type: disc; list-style-position: initial">过零点检测：二次微分不变性方程<dl style="margin: 0px; padding: 0px; border: 0px; list-style-type: none; list-style-position: initial"><dd style="margin: 0px; padding: 0px; border: 0px; list-style-type: none; list-style-position: initial"><img style="border: 0px; max-width: 100%; margin: 0px; padding: 0px; list-style-type: none; list-style-position: initial" src="http://upload.wikimedia.org/math/4/9/f/49fb9f76f450fb3aa0412dfddbaf5ccf.png" border="0" alt="&#123;&#92;tilde L&#125;_v^2 = L_x^2 &#92;, L_&#123;xx&#125; + 2 &#92;, L_x &#92;, L_y &#92;, L_&#123;xy&#125; + L_y^2 &#92;, L_&#123;yy&#125; = 0" title="尺度空间（Scale&nbsp;&lt;wbr&gt;space）理论研究笔记" /></dd><dt style="margin: 0px; padding: 0px; border: 0px; list-style-type: none; list-style-position: initial">满足三次微分不变性不等式：</dt><dd style="margin: 0px; padding: 0px; border: 0px; list-style-type: none; list-style-position: initial"><br /></dd></dl></li><li style="margin: 0px 0px 0px 30px; padding: 0px; border: 0px; list-style-type: disc; list-style-position: initial">blob检测：拉普拉斯高斯方程或者Hessian矩阵的行列式<br /></li></ul><span style="font-size: 14px; word-wrap: normal; word-break: normal; line-height: 21px; font-family: simsun; color: #494949"><span style="word-wrap: normal; word-break: normal; font-weight: bold">自动尺度选择和尺度不变特征选择：<br /></span></span><ul style="font-size: 14px; margin: 0px; padding: 0px; border: 0px; list-style-type: none; list-style-position: initial; color: #494949; font-family: simsun; line-height: 21px"><li style="margin: 0px 0px 0px 30px; padding: 0px; border: 0px; list-style-type: disc; list-style-position: initial">实际问题中可能要选择局部的尺度，然后进一步分析</li><li style="margin: 0px 0px 0px 30px; padding: 0px; border: 0px; list-style-type: disc; list-style-position: initial">尺度不变的特征是满足尺度不变性质的特征，这个特征在一个尺度下探测到，可以很容易映射到另一个尺度的对应位置。<br /></li></ul><span style="font-size: 14px; word-wrap: normal; word-break: normal; line-height: 21px; font-family: simsun; color: #494949"><span style="word-wrap: normal; word-break: normal; font-weight: bold">其他多尺度表示方法：</span><br /></span><ul style="font-size: 14px; margin: 0px; padding: 0px; border: 0px; list-style-type: none; list-style-position: initial; color: #494949; font-family: simsun; line-height: 21px"><li style="margin: 0px 0px 0px 30px; padding: 0px; border: 0px; list-style-type: disc; list-style-position: initial">金字塔表示<br /></li><li style="margin: 0px 0px 0px 30px; padding: 0px; border: 0px; list-style-type: disc; list-style-position: initial">非线性尺度空间</li><li style="margin: 0px 0px 0px 30px; padding: 0px; border: 0px; list-style-type: disc; list-style-position: initial">仿射高斯尺度空间</li><li style="margin: 0px 0px 0px 30px; padding: 0px; border: 0px; list-style-type: disc; list-style-position: initial">小波理论</li></ul>
]]>
</description>
</item><item>
<link>http://i.renjihe.com/blog/read.php?7438</link>
<title><![CDATA[蠢蠢欲动的三维扫描市场]]></title> 
<author>renjihe1988 &lt;admin@yourname.com&gt;</author>
<category><![CDATA[CV&amp;Graphic]]></category>
<pubDate>Fri, 29 Jul 2016 05:40:43 +0000</pubDate> 
<guid>http://i.renjihe.com/blog/read.php?7438</guid> 
<description>
<![CDATA[ 
	<p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><strong>讯点三维是位于杭州的三维扫描开发及三维数据运用的技术型企业，主要致力于人像三维扫描仪、三维运动补偿防抖动系统、工业级三维扫描仪系统以及移动端三维扫描解决方案等产品。</strong></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px"><em>图片来自Pinterest用户@Fuel Your Product Design&nbsp;</em></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">随着3D打印迅猛的发展，三维扫描市场也发展得如火如荼，国内外各大厂商纷纷重拳出击，抢占市场。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">&nbsp;5月，Stratasys与知名的便携式3D测量解决方案提供商Creaform签订了一项合作协议，双方将在北美市场结成联合营销的伙伴关系，这意味着双方将会在营销及联合渠道上有一个新的突破。自从全资收购了3D打印的老牌企业&mdash;&mdash;makerbot以来，Stratasys在国际市场越发显得强势，对三维扫描的巨大市场也是虎视眈眈。&nbsp;</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">已有的3D打印的巨头3D system也不甘示弱，自去年独立发布自己的新品3D sense彩色扫描仪杀向国内市场之后，在今年的CES展上，除了出人意表的发布了各类食品打印机，同时也推出了一款基于触摸重力定位的设计软件，让3D扫描跟人工结合的更为紧密。&nbsp;</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">去年，以提供数字化设计、工程软件服务和解决方案而问闻名全球的软件公司Autocdesk去年中宣布要推出自己的<a style="text-decoration: none; color: #ed5565; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline; transition: all 0.2s ease-out" href="http://www.leiphone.com/tag/3d%E6%89%93%E5%8D%B0%E6%9C%BA" target="_blank" title="3d打印机">3d打印机</a>和软件（按：Autocdesk的醉翁之意可能主要还是为了推广开源软件平台&ldquo;Spark&rdquo;），最新的消息，他们刚刚与杭州先临三维科技签订了1500万的供货协议。&nbsp;</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">看到国外的3D打印巨头都各施手段扑向三维扫描市场，国内看似平静的打印市场早已经是暗流涌动：&nbsp;</p><ul class=" list-paddingleft-2" style="margin: 20px 0px 20px 40px; padding: 0px; color: #5a5a5a; font-family: 'microsoft yahei'; font-size: 16px; line-height: 28.8px"><li style="margin: 0px; padding: 0px; list-style: disc"><p style="margin: 0px 0px 1em; padding: 0px; position: relative">台湾的打印巨头XYZ在去年12月面向美国市场推出3D打印与扫描的一体机XYZ达芬奇1.0，其自带的类似画板的调色系统Resolve也让消费者感到定制的乐趣，据传今年XYZ将布局日本，在现有基础上对日本的3D打印的市场展开攻势，预计在3年内在全球销售100万台以上的打印机；&nbsp;</p></li><li style="margin: 0px; padding: 0px; list-style: disc"><p style="margin: 0px 0px 1em; padding: 0px; position: relative">同样来自台湾的顶级3D打印公司研能科技依然保持着&ldquo;不鸣则已，一鸣惊人&rdquo;的态势，它们的喷墨式石膏打印机一经亮相就迅速地抢占了市场&mdash;&mdash;他们在高端技术上保证独立的研发能力。据悉，他们将会在今年为每一台打印机配备属于自己的三维扫描仪；&nbsp;</p></li><li style="margin: 0px; padding: 0px; list-style: disc"><p style="margin: 0px 0px 1em; padding: 0px; position: relative">而来自大陆的老牌企业&mdash;&mdash;UP3D依然是保持着不温不火的态度，不断的拓宽国外的销售渠道，而对三维扫描他们也是慎而远之。据业内传言，UP已经将研发重心转移至工业级的激光打印机，所以没有切入扫描的市场，桌面级打印机以守成为主。&nbsp;</p></li></ul><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">当然并不是所有的三维数据都需要打印出来才有价值，三维扫描并非依存3D打印而存在。我们从柯达的落幕中可以找到一些借鉴：作为感光行业的王牌，柯达公司在拍摄、分享、输出、显示领域一直处于世界领先，曾占据了世界摄影市场75%的份额，但柯达坚守&ldquo;所有拍摄的数据都需要用照片来展示&rdquo;的理念导致了它对于数码成像技术的错误评估，数码化给它的市场带来巨量的冲击，传统胶卷的市场萎缩终结了它130年的历史，到如今，我们的照片都是数据的形式在互联网上传播，谁还记得当年那个傻瓜式相机的辉煌。&nbsp;</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">无数互联网行业的巨头也都看到三维行业未来的趋势，无论是工业4.0还是三维的大数据都是未来不可忽视的变量，尤其是三维扫描在AR，VR上的探索更是值得期待。&nbsp;</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px; text-align: center"><img style="border: medium none; max-width: 100%; height: auto" src="http://static.leiphone.com/uploads/new/article/600_600/201506/557a92ae2c630.jpg?imageMogr2/format/jpg/quality/80" border="0" alt="蠢蠢欲动的三维扫描市场" /></p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">在今年5月的旧金山Build 2015大会上，微软发布了它的压轴产品&mdash;&mdash;增强现实眼镜HoloLens，悬浮的操作界面，极致的视觉体验，全息的展示都让人惊叹；更让人惊讶的是微软在三维扫描方向的应用：视觉的传输，数据的采集，虚现的交互，三维扫描为虚拟世界的交互提供了可能性。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">当微软在去年微软以25亿的天价收购Mojang AB以及Minecraft的时候，很多人表示费解，但是HoloLens的横空出世意味着微软的布局正在逐步显现，而Minecraft的技术将会让微软在未来的AR交互中占据先发优势。&nbsp;</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">同样看到这个趋势的还有Apple，这家最懂客户的公司在2013年斥资3.25亿美金收购了以色列传感器公司 PrimeSense，后者的3D扫描技术已经被应用在超过 2000 万台设备上并且可被植入于<a style="text-decoration: none; color: #ed5565; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline; transition: all 0.2s ease-out" href="http://www.leiphone.com/tag/%E6%99%BA%E8%83%BD%E6%89%8B%E6%9C%BA" target="_blank" title="智能手机">智能手机</a>及平台电脑上，也是国内外众多三维扫描厂商的芯片供应商。如果需要让<a style="text-decoration: none; color: #ed5565; border: 0px; margin: 0px; padding: 0px; vertical-align: baseline; transition: all 0.2s ease-out" href="http://www.leiphone.com/tag/%E8%99%9A%E6%8B%9F%E7%8E%B0%E5%AE%9E" target="_blank" title="虚拟现实">虚拟现实</a>变得更为逼真，那么三维扫描的技术必然是不可或缺的，而恰巧Primesense就是为了三维成像而存在的， 这也是为什么在Vuforia AR平台的早期版本中，Primesense是不可或缺的角色。&nbsp;</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">今年苹果公司申请了一项独特的激光测绘系统，该技术主要在iPhone上使用，该专利使得苹果能够在此基础上开发在iPhone上使用的精准3D扫描应用。&nbsp;</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">当然这也就不得不提到一家初创公司Occipital，他们针对iPad开发的三维扫描仪Structure Sensor也告诉了我们一个可能，移动端的三维扫描已经变得越来越近，这也是苹果之类的大厂商试图优化的问题&mdash;&mdash;去硬件化的三维扫描。</p><p style="margin: 0px 0px 1em; padding: 0px; position: relative; font-size: 16px; color: #5a5a5a; font-family: 'microsoft yahei'; line-height: 28.8px">在这点上Google走的更为靠前，在去年2月，Google宣布了一项全新的智能手机项目Project Tango，专注于3D场景的捕获。谷歌的Tango手机使用了多个摄像头，可以扫描整个房间，通过机械视觉来还原这个三维的世界。</p>
]]>
</description>
</item><item>
<link>http://i.renjihe.com/blog/read.php?7437</link>
<title><![CDATA[验证码——去除干扰线]]></title> 
<author>renjihe1988 &lt;admin@yourname.com&gt;</author>
<category><![CDATA[CV&amp;Graphic]]></category>
<pubDate>Fri, 29 Jul 2016 05:40:21 +0000</pubDate> 
<guid>http://i.renjihe.com/blog/read.php?7437</guid> 
<description>
<![CDATA[ 
	<p style="margin: 0px; padding: 0px; color: #555555; font-family: 'microsoft yahei'; font-size: 15px; line-height: 35px"><span style="font-size: 24px">去除干扰线</span></p><ol style="color: #555555; font-family: 'microsoft yahei'; font-size: 15px; line-height: 35px"><li class="L0"><span style="font-size: 18px"><span class="pun">干扰线对于识别验证码增加了一些难度，不过干扰线只有很小的几率会以大角度曲线的方式出现，大部分时间还是小角度直线，去除算法可以参考</span><span class="pln">http</span><span class="pun">:</span><span class="com">//wenku.baidu.com/view/63bac64f2b160b4e767fcfed.html</span></span></li><li class="L1"><span style="font-size: 18px"><span class="pun">对于</span><span class="lit">1</span><span class="pun">个像素粗细的干扰线，在字符为</span><span class="lit">2</span><span class="pun">个像素以上的时候，可以用去噪点算法作为滤镜，多执行几次，就可以完美的把细干扰线去掉。</span></span></li><li class="L2"><span class="pun"><span style="font-size: 18px">对于像素数比干扰点稍大的干扰色块，可以采用的算法有：</span></span></li></ol><p style="margin: 0px; padding: 0px; color: #555555; font-family: 'microsoft yahei'; font-size: 15px; line-height: 35px"><span style="font-size: 18px"><strong>油漆桶算法（又叫种子填充算法，Floodfill）<br /></strong>&nbsp;&nbsp;&nbsp; 种子填充算法可以方便的计算出任意色块的面积，对于没有粘连字符或者粘连但是字符每个颜色不一样的验证码来说，去除干扰色块的效果很好，你只需要大概计算一下最小的和最大的字符平均占多少像素，然后把这段区间之外像素数的色块排除掉即可。<br /><img style="border: none" src="http://static.wooyun.org/20131004/2013100410270648577.gif" border="0" /><br /><img style="border: none" src="http://static.wooyun.org/20131004/2013100410270736449.gif" border="0" /><br />上下左右4个方向填充还有8个方向填充的不同<br />判断颜色分布：<br />&nbsp;&nbsp;&nbsp; 对于大多数彩色验证码来说，文字基本在图片中心的位置，每个字符本身的颜色是一样的，也就是说对于文字来说，同一种颜色基本都集中在一个固定的区域范围内，通过统计图片中的像素，按近似颜色分组，同时分析每个颜色组在图片中的分布范围，假如说有一种颜色大部分像素都在图片边缘，那么这个颜色肯定不属于要识别的字符，可以去掉。<br />&nbsp;&nbsp;&nbsp; 对于干扰线，并没有一种十分有效的方式能完全去除并且不影响到文字，不过如果能够成功分割字符的话，少量干扰线对于识别率影响不大。</span></p>
]]>
</description>
</item><item>
<link>http://i.renjihe.com/blog/read.php?7418</link>
<title><![CDATA[齐次坐标的理解]]></title> 
<author>renjihe1988 &lt;admin@yourname.com&gt;</author>
<category><![CDATA[CV&amp;Graphic]]></category>
<pubDate>Tue, 26 Jul 2016 08:59:21 +0000</pubDate> 
<guid>http://i.renjihe.com/blog/read.php?7418</guid> 
<description>
<![CDATA[ 
	<p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">一直对齐次坐标这个概念的理解不够彻底，只见大部分的书中说道&ldquo;齐次坐标在仿射变换中非常的方便&rdquo;，然后就没有了后文，今天在一个叫做&ldquo;三百年 重生&rdquo;的博客上看到一篇关于透视投影变换的探讨的文章，其中有对齐次坐标有非常精辟的说明，特别是针对这样一句话进行了有力的证明：<em><span style="font-family: 宋体">&ldquo;齐次坐标表示是计算机图形学的重要手段之一，它既能够用来明确区分向量和点，同时也更易用于进行仿射（线性）几何变换。&rdquo;&mdash;&mdash;</span>&nbsp;</em>F.S. Hill, JR。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp; 由于作者对齐次坐标真的解释的不错，我就原封不动的摘抄过来：</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;<span style="font-family: 'Times New Roman'">&nbsp;对于一个</span>&nbsp;<em style="font-family: 'Times New Roman'">向量</em>&nbsp;<strong style="font-family: 'Times New Roman'"><span>v&nbsp;</span></strong><span style="font-family: 'Times New Roman'">以及基</span>&nbsp;<strong style="font-family: 'Times New Roman'"><span>oabc&nbsp;</span></strong>，<span style="font-size: small"><span style="font-size: 12pt; font-family: 'Times New Roman'">可以找到一组坐标</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">(v1,v2,v3)</span>&nbsp;</span></span><span style="font-size: 12pt; font-family: 'Times New Roman'">，使得</span>&nbsp;</span><span style="font-size: small"><span style="font-family: 'Times New Roman'"><strong><span style="font-size: 12pt">v</span>&nbsp;</strong><span style="font-size: 12pt">= v1&nbsp;</span><span style="font-size: 12pt"><strong>a</strong>&nbsp;+ v2&nbsp;<strong style="font-size: 10pt">b +&nbsp;</strong></span><span style="font-size: 12pt">v3</span>&nbsp;<span style="font-size: 12pt"><strong>c</strong>&nbsp;</span><span><strong>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;</strong>&nbsp;</span></span><strong><span style="font-family: 宋体">（</span>&nbsp;<span><span style="font-family: 'Times New Roman'">1</span>&nbsp;</span></strong><strong><span style="font-family: 宋体">）</span></strong></span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><strong><span><span style="font-size: small; font-family: 'Times New Roman'">&nbsp;</span>&nbsp;</span></strong><span style="font-size: small"><span style="font-size: 12pt; font-family: 宋体">而对于一个</span>&nbsp;<span style="font-size: 12pt; font-family: 宋体"><em>点</em>&nbsp;</span><strong><span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">p</span>&nbsp;</span></span></strong><span style="font-size: 12pt; font-family: 宋体">，则可以找到一组坐标（</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">p1,p2,p3</span>&nbsp;</span></span><span style="font-size: 12pt; font-family: 宋体">），使得</span>&nbsp;</span><span><span style="font-size: small; font-family: 'Times New Roman'">&nbsp;</span>&nbsp;</span><span style="font-size: small"><span style="font-family: 'Times New Roman'"><strong><span style="font-size: 12pt">p</span>&nbsp;</strong><span style="font-size: 12pt">&ndash;&nbsp;</span><span style="font-size: 12pt"><strong>o</strong>&nbsp;= p1&nbsp;<strong style="font-size: 12pt">a +&nbsp;</strong>p2&nbsp;<strong>b</strong>&nbsp;+ p3&nbsp;<strong>c&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</strong></span></span><span style="font-family: 宋体"><strong>（</strong>&nbsp;</span><strong><span style="font-family: 'Times New Roman'">2</span>&nbsp;），</strong></span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span style="font-size: small">&nbsp;</span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span style="font-size: small"><span style="font-size: 12pt">从上面对</span>&nbsp;<em style="font-size: 12pt">向量</em>&nbsp;<span style="font-size: 12pt">和</span>&nbsp;<em style="font-size: 12pt">点</em>&nbsp;<span style="font-size: 12pt">的表达，我们可以看出为了在坐标系中表示一个</span>&nbsp;<em style="font-size: 12pt">点</em>&nbsp;<span style="font-size: 12pt">（如</span>&nbsp;<span style="font-size: 12pt; font-family: 'Times New Roman'">p</span>&nbsp;<span style="font-size: 12pt">），我们把点的位置看作是对这个基的原点</span>&nbsp;<span style="font-size: 12pt; font-family: 'Times New Roman'">o</span>&nbsp;<span style="font-size: 12pt">所进行的一个位移，即一个向量&mdash;&mdash;</span>&nbsp;<span style="font-size: 12pt; font-family: 'Times New Roman'">p &ndash; o</span>&nbsp;<span style="font-size: 12pt; font-family: 宋体">（有的书中把这样的向量叫做<em>位置向量</em>&nbsp;&mdash;&mdash;起始于坐标原点的特殊向量），我们在表达这个向量的同时用等价的方式表达出了点</span></span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span style="font-size: small"><span style="font-size: 12pt; font-family: 'Times New Roman'">p：<span style="font-size: small"><strong><span>p&nbsp;</span></strong><span>=&nbsp;<strong>o</strong>&nbsp;+ p1&nbsp;<strong>a +&nbsp;</strong>p2&nbsp;<strong>b</strong>&nbsp;+ p3&nbsp;<strong>c (3)</strong></span></span></span></span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span style="font-size: small"><span style="font-family: 'Times New Roman'"><span>&nbsp;</span></span></span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span style="font-size: small"><span style="font-family: 'Times New Roman'"><span><span style="font-size: 12pt">(1)(3)</span>&nbsp;</span><span style="font-size: 12pt; font-family: 宋体">是坐标系下表达一个</span>&nbsp;<span style="font-size: 12pt; font-family: 宋体"><em>向量</em>&nbsp;和<em>点</em>&nbsp;的不同表达方式。这里可以看出，虽然都是用代数分量的形式表达向量和点，但表达一个点比一个向量需要额外的信息。如果我写出一个代数分量表达</span>&nbsp;<span><span style="font-size: 12pt">(1, 4, 7)</span>&nbsp;</span><span style="font-size: 12pt; font-family: 宋体">，谁知道它是个向量还是个点！</span></span></span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span style="font-size: small"><span style="font-family: 'Times New Roman'"><span style="font-family: 宋体">&nbsp;&nbsp;&nbsp;&nbsp;<span style="font-size: 12pt">我们现在把（</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">1</span>&nbsp;</span></span><span style="font-size: 12pt">）（</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">3</span>&nbsp;</span></span><span style="font-size: 12pt">）写成矩阵的形式：<span style="font-size: 12pt; color: red">v = (v1 v2 v3 0)&nbsp;X&nbsp;(a b c o)</span></span></span></span></span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span style="font-size: small"><span style="font-family: 'Times New Roman'"><span style="font-family: 宋体"><span style="color: red"><span style="font-size: 12pt">p = (p1 p2 p3 1) X (a b c o),</span>&nbsp;</span><span style="font-size: 12pt">这里</span>&nbsp;<strong><span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">(a,b,c,o)</span>&nbsp;</span></span></strong><span style="font-size: 12pt">是坐标基矩阵，右边的列向量分别是向量</span>&nbsp;<strong><span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">v</span>&nbsp;</span></span></strong><span style="font-size: 12pt">和点</span>&nbsp;<strong><span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">p</span>&nbsp;</span></span></strong><span style="font-size: 12pt">在基下的坐标。</span>&nbsp;<span style="font-size: 12pt">这样，向量和点在同一个基下就有了不同的表达：<em><span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">3D</span>&nbsp;</span></span></em><em><span style="font-size: 12pt">向量</span>&nbsp;</em><span style="font-size: 12pt">的第</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">4</span>&nbsp;</span></span><span style="font-size: 12pt">个代数分量是</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">0</span>&nbsp;</span></span><span style="font-size: 12pt">，而</span>&nbsp;<em><span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">3D</span>&nbsp;</span></span></em><em><span style="font-size: 12pt">点</span>&nbsp;</em><span style="font-size: 12pt">的第</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">4</span>&nbsp;</span></span><span style="font-size: 12pt">个代数分量是</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">1</span>&nbsp;</span></span><span style="font-size: 12pt">。像这种这种用</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">4</span>&nbsp;</span></span><span style="font-size: 12pt">个代数分量表示</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">3D</span>&nbsp;</span></span><span style="font-size: 12pt">几何概念的方式是一种齐次坐标表示。</span></span></span></span></span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span style="font-size: small"><span style="font-family: 'Times New Roman'"><span style="font-family: 宋体">&nbsp;</span></span></span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span style="font-size: small"><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt; font-family: 宋体">这样，上面的</span>&nbsp;<span><span style="font-size: 12pt">(1, 4, 7)</span>&nbsp;</span><span style="font-size: 12pt; font-family: 宋体">如果写成（</span>&nbsp;<span><span style="font-size: 12pt">1,4,7,0</span>&nbsp;</span><span style="font-size: 12pt; font-family: 宋体">），它就是个向量；如果是</span>&nbsp;<span><span style="font-size: 12pt">(1,4,7,1)</span>&nbsp;</span><span style="font-size: 12pt; font-family: 宋体">，它就是个点。</span>&nbsp;<span style="font-size: 12pt; font-family: 宋体">下面是如何在普通坐标</span>&nbsp;<span><span style="font-size: 12pt">(Ordinary Coordinate)</span>&nbsp;</span><span style="font-size: 12pt; font-family: 宋体">和齐次坐标</span>&nbsp;<span><span style="font-size: 12pt">(Homogeneous Coordinate)</span>&nbsp;</span><span style="font-size: 12pt; font-family: 宋体">之间进行转换：</span></span></span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span style="font-size: small"><span style="font-family: 'Times New Roman'"><span style="font-family: 宋体"><span style="font-size: 12pt">(1)</span>&nbsp;<span style="font-size: 12pt; color: red">从普通坐标转换成齐次坐标时</span></span></span></span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span style="font-size: small"><span style="font-family: 'Times New Roman'"><span style="font-family: 宋体">&nbsp;&nbsp;&nbsp;</span><span style="font-size: 12pt; font-family: 宋体">如果</span>&nbsp;<span><span style="font-size: 12pt">(x,y,z)</span>&nbsp;</span><span style="font-size: 12pt; font-family: 宋体">是个点，则变为</span>&nbsp;<span><span style="font-size: 12pt">(x,y,z,1);</span></span></span></span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span style="font-size: small"><span style="font-family: 'Times New Roman'"><span style="font-family: 宋体">&nbsp;&nbsp;&nbsp;</span><span style="font-size: 12pt; font-family: 宋体">如果</span>&nbsp;<span><span style="font-size: 12pt">(x,y,z)</span>&nbsp;</span><span style="font-size: 12pt; font-family: 宋体">是个向量，则变为</span>&nbsp;<span><span style="font-size: 12pt">(x,y,z,0)</span></span></span></span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span style="font-size: small"><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">(2)<span style="font-family: 宋体"><span style="font-size: small"><span style="color: red"><span><span style="font-size: 12pt">从齐次坐标转换成普通坐标时</span>&nbsp;</span></span></span></span></span><span><span style="font-family: 宋体">&nbsp;&nbsp;&nbsp;</span></span></span></span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span style="font-size: small"><span style="font-family: 'Times New Roman'"><span><span style="font-family: 宋体">&nbsp;&nbsp;&nbsp;<span style="font-size: 12pt">如果是</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">(x,y,z,1)</span>&nbsp;</span></span><span style="font-size: 12pt">，则知道它是个点，变成</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">(x,y,z);</span></span></span></span></span></span></span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span style="font-size: small"><span style="font-family: 'Times New Roman'"><span style="font-family: 宋体">&nbsp;&nbsp;&nbsp;</span><span style="font-size: 12pt; font-family: 宋体">如果是</span>&nbsp;<span><span style="font-size: 12pt">(x,y,z,0)</span>&nbsp;</span><span style="font-size: 12pt; font-family: 宋体">，则知道它是个向量，仍然变成</span>&nbsp;<span><span style="font-size: 12pt">(x,y,z)</span></span></span></span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span style="font-size: small"><span style="font-family: 'Times New Roman'">&nbsp;</span></span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span style="font-size: small"><span style="font-family: 'Times New Roman'"><span><span style="font-size: 12pt; font-family: 宋体">以上是通过齐次坐标来区分向量和点的方式。从中可以思考得知，对于平移</span>&nbsp;<span><span style="font-size: 12pt">T</span>&nbsp;</span><span style="font-size: 12pt; font-family: 宋体">、旋转</span>&nbsp;<span><span style="font-size: 12pt">R</span>&nbsp;</span><span style="font-size: 12pt; font-family: 宋体">、缩放</span>&nbsp;<span><span style="font-size: 12pt">S</span>&nbsp;</span><span style="font-size: 12pt; font-family: 宋体">这</span>&nbsp;<span><span style="font-size: 12pt">3</span>&nbsp;</span><span style="font-size: 12pt; font-family: 宋体">个最常见的仿射变换，平移变换只对于点才有意义，因为普通向量没有位置概念，只有大小和方向.</span></span></span></span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span style="font-size: small"><span style="font-family: 'Times New Roman'">&nbsp;</span></span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span style="font-size: small"><span style="font-family: 'Times New Roman'"><span><span style="font-family: 宋体"><span style="font-size: 12pt">而旋转和缩放对于向量和点都有意义，你可以用类似上面齐次表示来检测。从中可以看出，齐次坐标用于仿射变换非常方便。</span></span></span></span></span></p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px"></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span style="font-size: small">&nbsp;</span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span><span style="font-size: small"><span style="font-family: 宋体"><span style="color: red"><span><span style="font-size: 12pt">此外，对于一个普通坐标的</span>&nbsp;<span style="font-size: 12pt"><em>点</em>&nbsp;</span><span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">P=(Px, Py, Pz)</span>&nbsp;</span></span><span style="font-size: 12pt">，有对应的一族齐次坐标</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">(wPx, wPy, wPz, w)</span>&nbsp;</span></span><span style="font-size: 12pt">，其中</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">w</span>&nbsp;</span></span><span style="font-size: 12pt">不等于零</span>&nbsp;</span></span></span><span style="font-size: 12pt; font-family: 宋体">。比如，</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">P(1, 4, 7)</span>&nbsp;</span></span><span style="font-size: 12pt; font-family: 宋体">的齐次坐</span>&nbsp;<span style="font-size: 12pt; font-family: 宋体">标有</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">(1, 4, 7, 1)</span>&nbsp;</span></span><span style="font-size: 12pt; font-family: 宋体">、（</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">2, 8, 14, 2</span>&nbsp;</span></span><span style="font-size: 12pt; font-family: 宋体">）、（</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">-0.1, -0.4, -0.7, -0.1</span>&nbsp;</span></span><span style="font-size: 12pt; font-family: 宋体">）等等</span>&nbsp;<span style="font-family: 宋体">。</span>&nbsp;<span style="font-size: 12pt; font-family: 宋体">因此，如果把一个点从普通坐标变成齐次坐标，给</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">x,y,z</span>&nbsp;</span></span><span style="font-size: 12pt; font-family: 宋体">乘上同一个非零数</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">w</span>&nbsp;</span></span><span style="font-size: 12pt; font-family: 宋体">，然后增加第</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">4</span>&nbsp;</span></span><span style="font-size: 12pt; font-family: 宋体">个分量</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">w</span>&nbsp;</span></span><span style="font-size: 12pt; font-family: 宋体">；如果把一个齐</span>&nbsp;<span style="font-size: 12pt; font-family: 宋体">次坐标转换成普通坐标，把</span>&nbsp;<span style="font-size: 12pt; font-family: 宋体">前三个坐标同时除以第</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">4</span>&nbsp;</span></span><span style="font-size: 12pt; font-family: 宋体">个坐标，然后去掉第</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">4</span>&nbsp;</span></span><span style="font-size: 12pt; font-family: 宋体">个分量。</span></span></span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span><span style="font-size: small">&nbsp;</span></span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span style="font-size: small"><span style="font-size: 12pt; font-family: 宋体">由于齐次坐标使用了</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">4</span>&nbsp;</span></span><span style="font-size: 12pt; font-family: 宋体">个分量来表达</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">3D</span>&nbsp;</span></span><span style="font-size: 12pt; font-family: 宋体">概念，使得平移变换可以使用矩阵进行，从而如</span>&nbsp;<span><span style="font-family: 'Times New Roman'"><span style="font-size: 12pt">F.S. Hill, JR</span>&nbsp;</span></span><span style="font-size: 12pt; font-family: 宋体">所说，仿射（线性）变换的进行</span><span style="font-size: 12pt; font-family: 宋体">更加方便。由于图形硬件已经普遍地支持齐次坐标与矩阵乘法，因此更加促进了齐次坐标使用，使得它似乎成为图形学中的一个标准。</span></span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span style="font-size: small">&nbsp;</span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span style="font-size: small"><span style="font-family: 宋体">&nbsp;&nbsp;&nbsp;</span>&nbsp;<span style="font-size: 12pt; font-family: 宋体">以上很好的阐释了齐次坐标的作用及运用齐次坐标的好处。其实在图形学的理论中，很多已经被封装的好的API也是很有研究</span><span style="font-size: 12pt; font-family: 宋体">的，要想成为一名专业的计算机</span>&nbsp;<span style="font-size: 12pt; font-family: 宋体">图形学</span>&nbsp;<span style="font-size: 12pt; font-family: 宋体">的</span>&nbsp;<span style="font-size: 12pt; font-family: 宋体">学习者，除了知其然必须还得知其所以然。</span>&nbsp;<span style="font-size: 12pt; font-family: 宋体">这样在遇到问题的时候才能迅速定位问题的根源，从而解决问题。</span></span></p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal">&nbsp;</p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal">&nbsp;</p><p style="margin: 0cm 0cm 0pt; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" class="MsoNormal"><span style="font-size: small"><span style="font-size: 12pt; font-family: 宋体">另一个帖子的介绍：</span>&nbsp;</span><a style="color: #ff9900; text-decoration: none" href="http://www.cnblogs.com/kesalin/archive/2009/09/09/homogeneous.html">http://www.cnblogs.com/kesalin/archive/2009/09/09/homogeneous.html</a></p><h3 style="margin: 0px; padding: 0px; font-family: Arial; line-height: 26px"><a style="color: #ff9900" name="t0"></a>问题: 两条平行线会相交</h3><div style="font-family: Arial; font-size: 14px; line-height: 26px; float: right; text-align: center"><img style="border: none; max-width: 100%" src="http://images.cnblogs.com/cnblogs_com/kesalin/209114/r_railroad.jpg" border="0" width="256" height="256" />&nbsp;<br /><span class="caption">铁轨在无限远处相交于一点</span></div><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">在欧几里得几何空间里，两条平行线永远都不会相交。但是在投影空间中，如右图中的两条铁轨在地平线处却是会相交的，因为在无限远处它们看起来相交于一点。<br /><br />在欧几里得（或称笛卡尔）空间里描述2D/3D 几何物体是很理想的，但在投影空间里面却并不见得。 我们用&nbsp;<span class="font_serif">(<em>x, y</em>&nbsp;)</span>&nbsp;&nbsp;表 示笛卡尔空间中的一个 2D 点，而处于无限远处的点&nbsp;(&infin;,&infin;) 在笛卡尔空间里是没有意义的。投影空间里的两条平行线会在无限远处相交于一点，但笛卡尔空间里面无法搞定这个问题（因为无限远处的点在笛卡尔空间里是没有 意义的），因此数学家想出齐次坐标这个点子来了。</p><h3 style="margin: 0px; padding: 0px; font-family: Arial; line-height: 26px; clear: both"><a style="color: #ff9900" name="t1"></a>解决办法: 其次坐标</h3><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">由&nbsp;August Ferdinand M&ouml;bius 提出的齐次坐标（Homogeneous coordinates）让我们能够在投影空间里进行图像和几何处理，齐次坐标用 N + 1个分量来描述 N 维坐标。比如，2D 齐次坐标是在笛卡尔坐标(X, Y)的基础上增加一个新分量 w，变成(x, y, w)，其中笛卡尔坐标系中的大X，Y 与齐次坐标中的小x，y有如下对应关系：</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px"><span class="font_serif">X = x/w<br />Y = y/w</span>&nbsp;<br /><br />笛卡尔坐标中的点 (1, 2) 在齐次坐标中就是 (1, 2, 1) 。如果这点移动到无限远(&infin;,&infin;)处，在齐次坐标中就是 (1, 2, 0) ，这样我们就避免了用没意义的&quot;&infin;&quot; 来描述无限远处的点。</p><h3 style="margin: 0px; padding: 0px; font-family: Arial; line-height: 26px"><a style="color: #ff9900" name="t2"></a>为什么叫齐次坐标？</h3><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">前面提到，我们分别用齐次坐标中的 x 和 y 除以 w 就得到笛卡尔坐标中的 x&nbsp;和 x，如图所示：</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px"><img style="border: none; max-width: 100%" src="http://images.cnblogs.com/cnblogs_com/kesalin/209114/r_homogeneous01.png" border="0" width="208" height="64" />&nbsp;<br /><br />仔细观察下面的转换例子，可以发现些有趣的东西：<br /><img style="border: none; max-width: 100%" src="http://images.cnblogs.com/cnblogs_com/kesalin/209114/r_homogeneous02.png" border="0" width="263" height="208" />&nbsp;<br />上 图中，点 (1, 2, 3), (2, 4, 6) 和 (4, 8, 12) 对应笛卡尔坐标中的同一点 (1/3, 2/3)。 任意数量积的(1a, 2a, 3a) 始终对应于笛卡尔坐标中的同一点 (1/3, 2/3)。因此这些点是&ldquo;齐次&rdquo;的，因为他们始终对应于笛卡尔坐标中的同一点。换句话说，齐次坐标描述缩放不变性（<span style="line-height: 17px; white-space: pre; font-family: Verdana; color: #336699">scale invariant<span style="line-height: 25px; white-space: normal; font-family: verdana; color: #000000">）。</span> </span></p><h3 style="margin: 0px; padding: 0px; font-family: Arial; line-height: 26px"><a style="color: #ff9900" name="t3"></a>证明: 两平行线可以相交</h3><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">笛卡尔坐标系中，对于如下两个直线方程：</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px"><img style="border: none; max-width: 100%" src="http://images.cnblogs.com/cnblogs_com/kesalin/209114/r_homogeneous03.png" border="0" width="117" height="48" />&nbsp;<br />如果&nbsp;C &ne; D，以上方程组无解；如果&nbsp;<span class="font_serif">C = D，那这两条线就是同一条线了。</span></p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">下面我们用 x/w, y/w 代替 x, y 放到投影空间里来求解：</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px"><img style="border: none; max-width: 100%" src="http://images.cnblogs.com/cnblogs_com/kesalin/209114/r_homogeneous04.png" border="0" width="304" height="83" />&nbsp;<br />现在我们就可以在 C&nbsp;&ne;&nbsp;D 的情况得到一组解&nbsp;<span class="font_serif">(x, y, 0)，代入得&nbsp;</span>&nbsp;<span class="font_serif">(C - D)w = 0，因为&nbsp;C&nbsp;&ne;&nbsp;D，<span class="font_serif">所以 w = 0。因而，两条平行线相交于投影空间中无限远处的一点</span>&nbsp;&nbsp;<span class="font_serif">(x, y, 0)。</span></span></p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">齐次坐标在计算机图形学中是有用的，将 3D 场景投影到 2D 平面的过程中就用到它了。</p>
]]>
</description>
</item><item>
<link>http://i.renjihe.com/blog/read.php?7405</link>
<title><![CDATA[”计算摄影学“用照片重现眼中的场景]]></title> 
<author>renjihe1988 &lt;admin@yourname.com&gt;</author>
<category><![CDATA[CV&amp;Graphic]]></category>
<pubDate>Fri, 22 Jul 2016 12:59:23 +0000</pubDate> 
<guid>http://i.renjihe.com/blog/read.php?7405</guid> 
<description>
<![CDATA[ 
	<p style="margin: 0px; padding: 8px 0px; border: 0px; outline: 0px; font-size: 16px; vertical-align: baseline; color: #555555; line-height: 30px; font-family: Arial, sans-serif; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial">经常在电影里看到这样的桥段，一张颗粒感很强的图像，其中的面容或者是车牌号都难以辨认，但是只需要轻触屏幕或者轻敲几个按键，就可以获得清晰的局部放大图，犯罪信息一览无余，案件立刻获得侦破。蒙妮坦<a style="margin: 0px; padding: 0px; vertical-align: baseline; text-decoration: none; transition: 0.25s; color: #555555; background: transparent" href="http://photo.dlmonita.com/" target="_blank" class="keylink">摄影学校</a>为您讲解&rdquo;计算摄影学&ldquo;用照片重现眼中的场景。</p><p style="margin: 0px; padding: 8px 0px; border: 0px; outline: 0px; font-size: 16px; vertical-align: baseline; color: #555555; line-height: 30px; font-family: Arial, sans-serif; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial">然而在现实生活中，这种图像无损放大和增强的技术还没有得到实现。不过，科学家们却从这样的情节中寻找到了灵感。近年来，学术界出现了一个新的研究领域叫做&ldquo;计算摄影学（computational photography）&rdquo;。据该领域的领军人物，斯坦福大学的马克&middot;勒沃伊（Marc Levoy）教授介绍说：&ldquo;在很长一段时间里，相机制造商们都着眼于推出高像素高分辨率的相机。但是，随着微软的10亿像素级相机的出现，&lsquo;像素战&rsquo;理应告一段落。当务之急，是寻找到新的研究热点，创造出新的消费热点。&rdquo;</p><p style="margin: 0px; padding: 8px 0px; border: 0px; outline: 0px; font-size: 16px; vertical-align: baseline; color: #555555; line-height: 30px; font-family: Arial, sans-serif; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial">在计算摄影学中，研究人员结合相机的成像原理，结合光学的知识，设计出新型的高效的算法，力图改变传统相机对于场景的捕捉方式。目前，已出现并且得到认可的两项研究成果，一个是发现站在墙角背后的埋伏者或是隐藏者，另一项是能够通过罪犯眼睛中的反射图像来辨认出受害者的身份。除此以外，还有一些力图进军消费市场的功能，着眼于家用数码相机和智能手机上的应用，比如可以让摄影师以独特的方式进入照片中。</p><p style="margin: 0px; padding: 8px 0px; border: 0px; outline: 0px; font-size: 16px; vertical-align: baseline; color: #555555; line-height: 30px; font-family: Arial, sans-serif; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial">此前，我们也介绍过几款新型相机，比如可以先拍照后对焦的Lytro。还有，斯坦福大学最近研发出可自行编程的相机&ldquo;Frankencamera&rdquo;，意味着相机也在向开源的路线并进，为更多有想法的用户提供了可自行定制的相机开放平台。</p><p style="margin: 0px; padding: 8px 0px; border: 0px; outline: 0px; font-size: 16px; vertical-align: baseline; color: #555555; line-height: 30px; font-family: Arial, sans-serif; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial">数码相机的出现，冲垮了胶片行业。智能手机的风靡，又影响着数码相机的地位。下一次的相机风暴将以何种方式席卷而来呢？</p><p style="margin: 0px; padding: 8px 0px; border: 0px; outline: 0px; font-size: 16px; vertical-align: baseline; color: #555555; line-height: 30px; font-family: Arial, sans-serif; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial"><strong style="margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: baseline; background: transparent">1. 眼中世界，用照片重现眼中的场景</strong></p><p style="margin: 0px; padding: 8px 0px; border: 0px; outline: 0px; font-size: 16px; vertical-align: baseline; color: #555555; line-height: 30px; font-family: Arial, sans-serif; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial">十年前，数码相机是个稀罕物，市场上胶片照相机仍是主流，电子传感器是&ldquo;挑大梁&rdquo;的部件。相机成像原理即为，镜头捕捉到三维场景中反射的光，真实将其记录在胶片上，形成二维图像。</p><p style="margin: 0px; padding: 8px 0px; border: 0px; outline: 0px; font-size: 16px; vertical-align: baseline; color: #555555; line-height: 30px; font-family: Arial, sans-serif; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial">但是，在数码照相机中，&ldquo;真实重现&rdquo;这个词语就不复存在了。数码相机里都有一个小型计算机，对镜头搜集到的光学信号进行处理，包括滤波、转换盒添加一些图像处理的操作，最后处理结果放进存储卡。对于专业摄影师而言，他们只能挑选相机，而不能改变相机内部的操作。如果想要拍出与众不同的照片，也只能在镜头上玩一些光学的小把戏，比如说通过镜头叠加，或者在镜头前加上蒙版，诸如此类。</p><p style="margin: 0px; padding: 8px 0px; border: 0px; outline: 0px; font-size: 16px; vertical-align: baseline; color: #555555; line-height: 30px; font-family: Arial, sans-serif; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial">所以，我们经常看到，专业的摄影大哥玩设备，&ldquo;非主流&rdquo;的菜鸟玩家用PS。那么，这两者能否结合起来呢？</p><p style="margin: 0px; padding: 8px 0px; border: 0px; outline: 0px; font-size: 16px; vertical-align: baseline; color: #555555; line-height: 30px; font-family: Arial, sans-serif; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial">哥伦比亚大学计算机视觉实验室的负责人希瑞&middot;纳亚尔（Shree Nayar）教授他介绍说：&ldquo;此前，图像处理中的数学知识和物理成像中得光学知识均已应用到了相机业界。下一步，这两个研究领域的强强联手一定是主流的研究方法。只要你同时考虑这两个领域的知识，就能够创造出新的其乐无穷的玩意儿。&rdquo;</p><p style="margin: 0px; padding: 8px 0px; border: 0px; outline: 0px; font-size: 16px; vertical-align: baseline; color: #555555; line-height: 30px; font-family: Arial, sans-serif; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial"></p><div align="center" style="margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 16px; vertical-align: baseline; color: #555555; line-height: 30px; font-family: Arial, sans-serif; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial"><img style="margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: middle; max-width: 800px; height: auto; background: transparent" src="http://www.dlmonita.com/data/attachment/portal/201203/24/163425xjgjkjrrrrypqxk3.gif" border="0" /></div><span style="margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 16px; vertical-align: baseline; line-height: 30px; font-family: Arial, sans-serif; color: #555555; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial">研究人员最近设计出一款相机，可以扫描拐角处。相继发射出激光（红线），由门反射后撞击到隐藏在拐角处的物体（蓝线）。反射线（绿色）回馈给相机处理，得到肉眼盲区的拐角后的图像。</span><p style="margin: 0px; padding: 8px 0px; border: 0px; outline: 0px; font-size: 16px; vertical-align: baseline; color: #555555; line-height: 30px; font-family: Arial, sans-serif; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial"></p><p style="margin: 0px; padding: 8px 0px; border: 0px; outline: 0px; font-size: 16px; vertical-align: baseline; color: #555555; line-height: 30px; font-family: Arial, sans-serif; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial">早在2009年，麻省理工大学和加州大学就联合开发出来的一款相机，可以拍摄到拐角后面的人像。它选用了安置了一台钛蓝宝石激光脉冲器作为光源，以1秒100万次的频率放射出激光脉冲，再利用反射面使光传播到藏匿物，再从藏匿物反射回相机镜头，即可捕捉到&ldquo;看不到&rdquo;的物体。</p><p style="margin: 0px; padding: 8px 0px; border: 0px; outline: 0px; font-size: 16px; vertical-align: baseline; color: #555555; line-height: 30px; font-family: Arial, sans-serif; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial">这项技术不仅可以看到拐角处的物体，还可以在狭窄区间内获得较宽的视野。从侦察角度考虑，可以用于团队作战的配合、掩护和救援，也可以形成&ldquo;敌人在明我在暗&rdquo;的优势。</p><p style="margin: 0px; padding: 8px 0px; border: 0px; outline: 0px; font-size: 16px; vertical-align: baseline; color: #555555; line-height: 30px; font-family: Arial, sans-serif; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial">该研究团队的另一项研究成果叫做&ldquo;眼中世界（world in an eye）&rdquo;，它能够通过照片中，单只眼球上映射出的图像，来重建出眼睛主人周围的场景。该项目的研发者纳亚尔介绍说，这项技术充分利用了眼睛角膜的几何模型，然后将角膜上类似&ldquo;鱼眼&rdquo;成像的图像模型转换成周围场景在角膜上的映射，从而进行重构。同时，需要考虑的因素还包括，相机的倾斜角度和人物的眼球位置。</p><p style="margin: 0px; padding: 8px 0px; border: 0px; outline: 0px; font-size: 16px; vertical-align: baseline; color: #555555; line-height: 30px; font-family: Arial, sans-serif; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial">有了这项技术，在场景中，眼球关注的焦点就可以被找到。所以，这项技术的实现，对于眼球跟踪的研究也是促进作用的。</p><p style="margin: 0px; padding: 8px 0px; border: 0px; outline: 0px; font-size: 16px; vertical-align: baseline; color: #555555; line-height: 30px; font-family: Arial, sans-serif; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial"></p><div align="center" style="margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 16px; vertical-align: baseline; color: #555555; line-height: 30px; font-family: Arial, sans-serif; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial"><img style="margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: middle; max-width: 800px; height: auto; background: transparent" src="http://www.dlmonita.com/data/attachment/portal/201203/24/163425qtzu66uuscqda7z8.jpg" border="0" /></div><span style="margin: 0px; padding: 0px; border: 0px; outline: 0px; font-size: 16px; vertical-align: baseline; line-height: 30px; font-family: Arial, sans-serif; color: #555555; background-image: initial; background-attachment: initial; background-size: initial; background-origin: initial; background-clip: initial; background-position: initial; background-repeat: initial">通过一张眼睛的图像，复原出眼睛的主人究竟看到了什么。这是哥伦比亚大学计算机视觉实验室的研究成果。</span>
]]>
</description>
</item><item>
<link>http://i.renjihe.com/blog/read.php?7400</link>
<title><![CDATA[图形学创世纪：当科学照进影视与生活]]></title> 
<author>renjihe1988 &lt;admin@yourname.com&gt;</author>
<category><![CDATA[CV&amp;Graphic]]></category>
<pubDate>Fri, 22 Jul 2016 06:38:11 +0000</pubDate> 
<guid>http://i.renjihe.com/blog/read.php?7400</guid> 
<description>
<![CDATA[ 
	<p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 21px; color: #464646; font-family: simsun; font-size: 14px"><span style="word-wrap: normal; word-break: normal; color: #333333"><strong>点评：现在的IT技术真的越来越厉害了，特别是模式识别方面。&ldquo;3-Sweep&rdquo;演示确实很震撼。&ldquo;人眼已经完全无法识别的模糊图像，经过算法处理，能自动分析出相机的抖动方向，再据此还原出清晰的原貌&rdquo;，人眼说白了也是个模式识别装置（与大脑配合），现在电脑竟然能超过人眼，不可思议。&ldquo;你在现实中的所见都能在无意识的状态下，自动于虚拟世界中建模；而通过三维打印，虚拟世界中的模型也能在真实世界中重建&rdquo;，如果真的实现了这一步，传统的制造业大部分就game over了。</strong></span></p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体"><strong style="font-family: 宋体, Verdana, Arial, Helvetica, sans-serif; line-height: 1.5"><br /></strong></p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体"><a style="text-decoration: none; color: #3e73a0" href="http://tech.sina.com.cn/zl/post/detail/it/2013-10-31/pid_8436547.htm">http://tech.sina.com.cn/zl/post/detail/it/2013-10-31/pid_8436547.htm</a></p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体"><span style="word-wrap: normal; word-break: normal; line-height: 21px; font-family: 楷体, 楷体_gb2312, simkai">　编者注：本文原题&ldquo;图形学创世纪&mdash;&mdash;写在SIGGRAPH 40年的边上&rdquo;，作者为微软亚洲研究院研究员童欣博士。文章从影视工业、生活等方面阐述了图形学的应用，全文略长，耐心看完可以了解到不少科学照进生活之美。</span></p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体"><strong>　　引言：</strong></p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　SIGGRAPH是由ACM SIGGRAPH(美国计算机协会计算机图形专业组)主办的计算机图形与交互技术年度顶级会议，它集科学、艺术、商业于一身。历年大会都有丰富的成果展示，我们熟知的像素、图层、顶点等概念都是在SIGGRAPH上发表的学术报告，Pixar著名的《小台灯》动画短片也是首先在SIGGRAPH上展示的。2013年7月21日&ndash;25日，这一盛会迎来了它的40周年庆典。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　今年的SIGGRAHP在美国加州西南部城市阿纳海姆举行，有超过一万七千名参会者，近两百家商业公司参展。在大会的演讲、圆桌、论文、展示等环节，超过一千三百位演讲人参与其中。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　借着这次大会，我们也回顾了一下，这些年来图形学在影视工业得到应用的里程碑事件，以及它对人们生活日渐加深的影响。我们会发现，从最初的光影和水滴，到复杂一些的植物和动物，再到人的表情和毛发，这恰好是一段图形学的创世纪故事。展望未来，还有更广袤、更让人惊奇的三维世界，等待着我们一起去探索，去创造。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体"><strong>　　图形学的创世纪：从光影、怪兽毛发到人的表情</strong></p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　对普通人来说，电影动画是我们在日常生活中与计算机图形学接触最多也是最直观的领域之一。计算机动画节(Computer Animation Festival)是SIGGRAPH的一项重要活动，展示最前沿的电影、数字游戏和视频成果。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　许多朋友可能被最近上映的《环太平洋》中真实、绚丽的光影效果所震撼。围绕这部电影涉及的技术，SIGGRAPH上有许多相关展示。在这部电影之前，由于CG技术的限制，许多效果还无法通过计算生成，画面中的雨滴不是高反光，倒更像是发光的小灯泡，夜景中的主体轮廓也很难显示清楚，制作公司更多地是做贴图方面的工作，比拼的是合成与后期调整。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体; text-align: center"><img style="margin: 0px; padding: 0px; border: 0px none; list-style: none" src="http://upload.service.mix.sina.com.cn/cdb3f5c39bdbe0bf56901f524baf9224.jpg" border="0" alt="图形学创世纪：当科学照进影视与生活" title="环太平洋" /></p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　不过工业光魔(ILM)在这部电影中迈出了一大步：决战场景设在香港雨夜，使用霓虹灯与海浪打光，主光源照在动态怪兽身上，烘托出真实凝重的气氛。新技术的应用是这部电影成功的关键因素之一，这是全球电影行业等待了十年的结果。明年，我们将在更多新作品中见到CG的光影。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　不过更多时候，观众已经很自然地接受了电影中计算机生成的图像，察觉不出细微之处的改进。不过，其中涉及的图形学技术，在这些年已取得了长足的进步。见微知著，用发丝就可以说明。《玩具总动员》是第一部由计算机运用图形学技术制作的长篇动画，也是计算机图形学技术应用的一个里程碑。不过在这部电影中，所有角色都只有光滑的表面&mdash;&mdash;它们没有毛发，而到了《怪兽公司》，角色身上开始长出毛发，再到去年Disney的电影《勇敢传说》和今年的《怪兽大学》，主角已经拥有了蓬松、卷曲、自然的长发。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体; text-align: center"><img style="margin: 0px; padding: 0px; border: 0px none; list-style: none" src="http://upload.service.mix.sina.com.cn/4e5d89e7b113bbd1091cdf7bdc1dffe6.jpg" border="0" alt="图形学创世纪：当科学照进影视与生活" title="玩具总动员" /></p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体; text-align: center"><img style="margin: 0px; padding: 0px; border: 0px none; list-style: none" src="http://upload.service.mix.sina.com.cn/db26269ac77d098e053758195062d39e.jpg" border="0" alt="图形学创世纪：当科学照进影视与生活" title="勇敢传说" /></p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　从技术角度来看，直发的运动相对规律，而卷发的物理特性则复杂很多，尤其是运动中会涉及大量碰撞、摩擦，传统技术很难真实模拟。为了克服这些困难，工程师们使用了&ldquo;粒子弹簧&rdquo;模型等技术，假设头发之间用弹簧连接，这样既能真实地呈现自然效果，还能方便艺术家控制人物的造型。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　可不能小看了毛发和表情的作用&mdash;&mdash;如何让电脑制作出的人物栩栩如生，一直是困扰艺术家和图形学研究人员的难题，因为观众对人的动作、皮肤、毛发、表情特别敏感。2005年上映的CG动画电影《最终幻想：降临之子》，仅女主角的头发就花费了600万美元一根根绘制出来，但票房上却未达到预期，其中一个很重要的原因就是人物的毛发、表情、动作显得呆板，给观众一种虚假的感觉，无法将他们带入到电影情节当中。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　不过这一难题正被研究人员逐步克服。《指环王》中一些由电脑制作的角色已经拥有与人十分相似的表情，不过因为它们还不是人，所以观众们对效果并不十分挑剔。而到了《阿凡达》，计算机制作的人物非常细腻，即使是挑剔的观众也感觉不到他们全出自计算机之手，这部电影是图形学技术应用的另一个里程碑。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　每个里程碑，都意味着一系列技术走向成熟。因为制作长篇作品，不单要通过建模技术塑造人物和场景，也要靠绘制技术渲染光影效果，还需要具备人物动作的相关技术。最重要的是，能有一套可用系统，在有限的时间和资金前提下，工业化地生产出一部成品，它们是一个时代图形学技术的集大成之作。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体"><strong>　　图形学照进生活</strong></p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　专业技术令电影越来越震撼的同时，研究人员也正努力让它们走进普通人的生活。《Dynamic Hair Manipulation in Images and Videos》是微软亚洲研究院在SIGGRAPH 2013上入选的10篇论文之一，它提出了一种新方法创建3D头发模型。相对传统基于多图像的建模方式，新方法对输入设备几乎没有要求，普通手机内置摄像头拍摄的照片就可以满足。它还允许用户操纵图片和视频中的发型。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　真实感绘制的终极目标是既好又快地重现真实环境，过去的主要思路是直接计算场景对入射光照的反馈，但是由于光在场景中要经过无数次碰撞的复杂性，这些方法要么速度慢，难以满足实时应用的需要，要么牺牲绘制质量，难以达到照片级的真实效果。电影中为了达到逼真的效果，需要花费大量时间进行离线渲染。对计算能力的苛刻要求，几乎让它无法走近普通人的生活。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体; text-align: center"><img style="margin: 0px; padding: 0px; border: 0px none; list-style: none" src="http://upload.service.mix.sina.com.cn/503228cd573c636f841ce3e9ce166f61.jpg" border="0" alt="图形学创世纪：当科学照进影视与生活" title="用户操纵图片和视频中的发型" /></p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　《Global Illumination with Radiance Regression Functions》是微软亚洲研究院另一篇入选SIGGRAPH大会的论文，面对上述问题，它提出了一套全新的解决方案。神经网络与全局光照两个技术在各自的领域里，都各自发展了许久，但从没有人试着将这两者结合。新的研究思路避开复杂的光线模拟，而通过场景各处的位置、纹理及光源信息，运用机器学习的方法直接预测图像输出。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体; text-align: center"><img style="margin: 0px; padding: 0px; border: 0px none; list-style: none" src="http://upload.service.mix.sina.com.cn/249af68d8abdd763d5337fbf7e9d4198.jpg" border="0" alt="图形学创世纪：当科学照进影视与生活" title="运用机器学习的方法直接预测图像输出" /></p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　这样的想法，源自研究员对画家作画的观察&mdash;&mdash;尽管现实中三维场景的光线十分复杂，但画家笔下描绘的二维图像却很有规律，有些画家的作品其真实感甚至能与照片一较高低。既然画家可以凭借经验和想象作画，计算机为什么不能从数据中学习？</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体"><strong>　　计算摄像学：给你个清晰的世界</strong></p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　过去几年，随着计算摄像学(它是图形学与视觉的交叉学科)的发展，研究人员发展了很多图像处理和数据捕捉新技术，用于弥补拍摄图片或视频时的不足。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　这些技术的背后都得益于图形学理论的发展，<strong>在最新的一些案例展示中，人眼已经完全无法识别的模糊图像，经过算法处理，能自动分析出相机的抖动方向，再据此还原出清晰的原貌。不禁让人感叹计算机和算法是不是已经超过了我们人类。</strong></p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　微软亚洲研究院也在SIGGRAPH上展示了两项计算摄像学成果：一项是实时视频稳定技术。使用手机或手持摄像机拍摄视频，往往伴随着不必可避免的抖动，造成画面模糊不清，而视频稳定技术能消除额外的晃动，提升视频质量。在拍摄和分享视频越来越流行的今天，这种技术颇具实用价值。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　以往的视频稳定技术大致可以分为二维和三维相机抖动估算两种。二维方式稳定、快速，但模型相对简单，并不能处理复杂场景中的视差等问题。另一方面，三维方式可以修正视差，获得更好的质量，但它的估算模型不稳定，容易在摄像机快速旋转、镜头变焦等情况下失效。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　微软亚洲研究院提出的这项新技术，将视频中的图像分割为多个矩形网格，每个区有都有单独的相机路径，这种灵活的模型可以处理由视差或卷帘式快门引起的复杂抖动和变形，同时又不失稳定和高效的特点。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　另一项计算摄像学成果是&ldquo;矩形全景图&rdquo;。我们都有这样的经验，手机拍摄的全景图，边界往往并不规则，但无论打印、分享还是发布图片，多数用户更希望图片具有规则的矩形边缘。这时我们通常有两个选择：一是选择其中边界规则的矩形部分进行裁剪，但关键信息刚好处在不规则的边缘时，只好舍弃，原本宽广视角带来的震撼效果也会大打折扣。二是保留所有图像，但不得不接受难看的边缘色块。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　而&ldquo;矩形全景图&rdquo;则分两步将图片巧妙变形：先将图片拉伸为矩形，再根据原始图片优化拉伸后的形状和线条，这种方式尽可能地保留了边缘部分，同时又能生成没有色块的矩形全景图。这些变形很聪明，能保留照片中原始线条的方向，让使用者几乎察觉不到变形后的图片与现实的区别。虽然这项技术并没有很深的理论背景，但能解决现实生活中一个很影响用户体验的问题，是个十分出色的想法。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体"><strong>　　身临其境的未来视频通话</strong></p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　SIGGRAPH上一个关于人脸建模的技术演示引起了很多关注，它能利用视频或深度摄像机，实时对人脸进行建模，捕获面部表情并映射到另一个对象身上，这对将来提升实时会话体验很有帮助。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　难道我们现在利用手机、平板电脑进行视频通话的效果不够好么？经常视频聊天的朋友可能常常感觉眼神并不能与对方相接，这与我们当面交流还有微妙的差异。原因在于，摄像头通常在屏幕上方，而聊天中的两个人通常只会注视屏幕，而不会紧盯摄像头。更麻烦的在于，多人视频会议中，由于多个对象并行会话，为了实现高质量的视频效果，设置复杂，设备也非常昂贵。而将头扭向一侧时，在其他人看来往往会产生错觉，不知道对方正在与谁交流。这些问题都很难通过传统的视频技术解决，而实时人脸建模则是一个可行的方案，目前已经有一些初创公司正在以此为方向进行技术和产品的探索。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体"><strong>　　图形学之外的带感新思路</strong></p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　今年的SIGGRAPH大会还有一些精彩展示让人眼前一亮，Disney Research的<a style="text-decoration: none; color: #3e73a0" href="http://www.disneyresearch.com/project/aireal/" target="_blank">AIREAL</a>就是其中一个，它将人与计算机的交互带到了现实世界中。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　近年来低成本的动作捕捉设备让不少用户有机会能通过手势与电脑交互，然而这其中还缺少重要的一环&mdash;&mdash;物理反馈。当使用者隔空与计算机生成的虚拟元素交互(例如接球、撞车)，与我们在现实世界中有触感的体验差别很大。过去，为了让使用者有这方面的体验，需要他们戴上力反馈手套、穿上力反馈背心。这些额外装备不单价格不菲，更让使用者平添束缚。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　AIREAL配合深度摄像头，以及能扭转角度的喷嘴，对使用者的姿态做出实时反馈，让使用者触摸虚拟物体、感受不同纹理。它射出气体涡环(Vortex Ring，类似我们平时见过的烟圈)&mdash;&mdash;这是一种能长距离保持形状和速度的空气环，当它接触皮肤，涡环破裂，由于内部压力较低，便将触觉传递给用户。尽管这还是一项概念性的技术，但为我们带来了有益的启发。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体; text-align: center"><img style="margin: 0px; padding: 0px; border: 0px none; list-style: none" src="http://upload.service.mix.sina.com.cn/cc11becf3d7afa320689ec88db013ba3.jpg" border="0" alt="图形学创世纪：当科学照进影视与生活" title="对使用者的姿态做出实时反馈" /></p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体"><strong>　　图形学的梦想：消弭现实与虚拟的边界</strong></p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　<strong>倘若每个用户都能产生内容，将为一个市场带来空前的繁荣</strong>。回顾历史，计算机视觉起初只应用在工业和军事上，那时设备价格昂贵，普通人很少从中受益。而当摄像头成为手机标配，在技术与应用的相互促进下，这个领域变得绝然不同。互联网上已经有像YouTube、Flickr、Instagram许多家市值上亿美元的二维图片、视频服务公司，而三维领域还是一片无比巨大的荒原。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　假如，每个普通用户都能产生三维内容，可以想象，后续的绘制、动画等技术也都将发挥功效。而作为源头的三维内容产生技术，是目前限制这个领域发展的瓶颈&mdash;&mdash;普通用户并没有方便、易学的工具可用。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　如果你曾使用3ds Max或Maya这样的三维建模软件，一定能体会它们的学习难度与手机上的图片处理软件间的巨大差别。即便是艺术家和专业人士，也需要长时间学习才能掌握创建复杂3D图形的技能，对普通人来说，难度则更大。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　以往用户需要从头开始输入参数创造模型，而以Kinect为代表的新一代体感控制器，能以一种易用、直接、低成本的方式，从现实世界中抽取物体的三维信息，然后在这一基础上做进一步地修改或调整，这将大大降低用户上手的难度。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　我们可以看看，<strong>以色列特拉维夫大学最近所做<a style="text-decoration: none; color: #3e73a0" href="http://v.youku.com/v_show/id_XNjA3MjAxMDk2.html" target="_blank">&ldquo;3-Sweep&rdquo;演示</a>就能体会解决这一问题，能孕育多少新创造。</strong></p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　另一方面，虽然深度摄像头、激光扫描器的出现大大方便了场景扫描，但得到的数据还无法直接使用&mdash;&mdash;因为不能分辨扫描得到的具体物体。一旦有技术能将扫描场景中的物体分离、识别(例如分辨出桌椅)，应用就会大不相同。就像从二维图片中搜索物体的名称，未来通过关键字就能找到相应3D素材。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　当用户创造、记录、使用三维数据的成本越来越低，拍摄三维物体能像现在拍摄图片、视频一样轻松容易时，拥抱三维世界的时机就真正成熟了。三维内容的增加会促进交互界面的发展，进而又将促进三维应用的发展。当每个人都能轻松地贡献三维内容，同时又能方便地消费三维内容时，整个产业将变得完全不同。</p><p style="margin: 15px 0px; padding: 0px; border: 0px; list-style: none; word-wrap: normal; word-break: normal; line-height: 23px; font-size: 14px; color: #333333; font-family: 'Microsoft YaHei', 微软雅黑, simsun, 宋体">　　未来的某天，我们或许会看到这样一幅图景&mdash;&mdash;<strong>你在现实中的所见都能在无意识的状态下，自动于虚拟世界中建模；而通过三维打印，虚拟世界中的模型也能在真实世界中重建</strong>。此时，现实与虚拟世界的边界将不再像今天这样清晰，我们将迎来虚拟与现实的融合&mdash;&mdash;在你的Cyber Space里，你就是&ldquo;造物主&rdquo;。</p>
]]>
</description>
</item><item>
<link>http://i.renjihe.com/blog/read.php?7399</link>
<title><![CDATA[漫谈计算摄像学 (二)：利用光场实现“先拍照后对焦”]]></title> 
<author>renjihe1988 &lt;admin@yourname.com&gt;</author>
<category><![CDATA[CV&amp;Graphic]]></category>
<pubDate>Fri, 22 Jul 2016 06:37:25 +0000</pubDate> 
<guid>http://i.renjihe.com/blog/read.php?7399</guid> 
<description>
<![CDATA[ 
	<div class="postText" style="margin: 0px; padding: 0px; color: #333333; font-family: verdana, Arial, Helvetica, sans-serif; font-size: 13.3333px; line-height: 24px"><p style="margin: 0px; padding: 0px">在上一篇<a style="margin: 0px; padding: 0px; text-decoration: none; color: #399ab2" href="http://www.cnblogs.com/frombeijingwithlove/p/4205907.html" target="_blank">直观理解光场</a>中，谈到了光场的基本概念、3D性质、实际应用中的采集办法和插值求任意光线的办法。这一篇继续上一篇的基础上给出利用光场实现&ldquo;先拍照后聚焦&rdquo;的原理和基本步骤。</p><h2 style="margin: 0px; padding: 0px; color: #000000">对焦与光路</h2><p style="margin: 0px; padding: 0px">首先，什么是对焦呢，我们先简单回顾一下中学物理。</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/02/26/A182157246-130912.jpg_small.jpg" border="0" /></p><p style="margin: 0px; padding: 0px">先看左图，物体端的对焦面就是最上方的平面，从这个平面上的每一点发出的光线最后都汇聚在另一端的像平面上，一个典型的光路如加粗的四色直线所示。如果希望物体端的焦面移动到和原焦面到透镜之间的位置，可以看到光线仍然是那些光线，但是聚焦到像面的光线组合就不再是之前的光线了，比如右图里，加粗的光线除了红线以外，黑绿蓝三色的光线都不再是原来的那几根。对应对焦的基本光路，再回来看光场，根据<a style="margin: 0px; padding: 0px; text-decoration: none; color: #399ab2" href="http://www.cnblogs.com/frombeijingwithlove/p/4205907.html" target="_blank">上一篇文章</a>中介绍过的光场的基本原理，很自然的，我们会想到，只要把在一个物平面上发出的光线所对应的像素叠加在一起，不就实现了重聚焦了吗？事实上这就是最简单的基于光场的重聚焦算法，叫Shift-and-Add<a style="margin: 0px; padding: 0px; text-decoration: none; color: #399ab2" href="http://doc.okbase.net/frombeijingwithl/archive/130912.html#ref.1" target="_blank">[1]</a>。</p><h2 style="margin: 0px; padding: 0px; color: #000000">先拍照后对焦的算法</h2><p style="margin: 0px; padding: 0px">还是借助<a style="margin: 0px; padding: 0px; text-decoration: none; color: #399ab2" href="http://www.cnblogs.com/frombeijingwithlove/p/4205907.html" target="_blank">上一篇文章</a>中的配图来讲解Shift-and-Add算法：</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/02/26/A182159605-130912.png_small.png" border="0" /></p><p style="margin: 0px; padding: 0px">如左图所示，在原始的采集位置上，蓝色光线在两幅采集到的图像里分别对应于不同的位置，所以如果要对焦于蓝色的方块，则需要将他们的相对位移消除，这一步就是Shift，然后在把两个像素的平均值求出作为对焦后的新图像的像素值，则得到了对焦于蓝色方块的图像。同样道理，对于更远的绿色三角，则进行更大距离的位移来消除对应像素之间的相对距离，然后叠加得到新的对焦于绿色三角的图像。需要注意的是，如上面的小图所示，移动叠加之后，边缘部分总是有些像素是不重合的，所以或多或少都会形成瑕疵。</p><p style="margin: 0px; padding: 0px">具体到<a style="margin: 0px; padding: 0px; text-decoration: none; color: #399ab2" href="http://www.cnblogs.com/frombeijingwithlove/p/4205907.html" target="_blank">上篇文章</a>里手机拍的照片例子，就是按照每张照片采样位置相对于中心位置进行等比例的移动，就可以得到在不同物平面上重聚焦的图像，比如我们选取9个采样点的中心点作为中心位置的话，将其他8个采样点放置到不同位置上，就对应得到不同的重聚焦图片：</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/02/26/A182201871-130912.jpg_small.jpg" border="0" /></p><p style="margin: 0px; padding: 0px">绿圈位置对应图像：</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/02/26/A182204262-130912.jpg_small.jpg" border="0" /></p><p style="margin: 0px; padding: 0px">蓝圈位置对应图像：</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/02/26/A182206543-130912.jpg_small.jpg" border="0" /></p><p style="margin: 0px; padding: 0px">就这么简单。那么，Lytro中的算法是不是Shift-and-Add呢？答案是否定的，Lytro的算法是把平移-叠加这种空域的算法放到了频域执行。基于的原理叫做<a style="margin: 0px; padding: 0px; text-decoration: none; color: #399ab2" href="http://en.wikipedia.org/wiki/Projection-slice_theorem" target="_blank">中心切片定理</a>，这里只简单提两句，中心切片定理是二维的，不过其基本原理可以拓展到任意维度，Lytro中用的是其在4维时的应用。简单来说就是把4维的光场进行傅里叶变换之后，在4D的傅里叶空间内，不同位置的重聚焦图片分别对应一个穿过中心的不同角度的二维傅里叶空间的插值切片的逆傅里叶变换。所以本质上而言，这种办法和Shift-and-Add没有区别，只不过是把线性操作换到了频域空间。shift-and-Add每次产生新的重聚焦图片时都需要用到所有采集的光场信息，算法复杂度是&#92;(O&#92;left( &#123;&#123;n&#125;^&#123;4&#125;&#125; &#92;right)&#92;)。而如果是从变换后4D数据里产生新的重聚焦图片，则分为两步：1) 求插值得到2D的傅里叶空间切片，复杂度是&#92;(O&#92;left( &#123;&#123;n&#125;^&#123;2&#125;&#125; &#92;right)&#92;)；2) 二维傅里叶逆变换，复杂度是&#92;(O&#92;left( &#123;&#123;n&#125;^&#123;2&#125;&#125;&#92;log n &#92;right)&#92;)，当然为了得到4D的傅里叶变换还有一步初始化计算，复杂度是&#92;(O&#92;left( &#123;&#123;n&#125;^&#123;4&#125;&#125;&#92;log n &#92;right)&#92;)。所以在已经有了采集到的4D数据需要不断生成新的重聚焦图片的场景下，在频域的重聚焦算法时间上更经济一些。更多关于频域重聚焦算法的详细，有兴趣的朋友可以参考<a style="margin: 0px; padding: 0px; text-decoration: none; color: #399ab2" href="http://doc.okbase.net/frombeijingwithl/archive/130912.html#ref.1" target="_blank">[1]</a>。</p><p style="margin: 0px; padding: 0px">另外特别要提的一点是，在这种Shift-and-Add框架下的重聚焦算法，和实际相机成像的图片是有区别的。原因就是第一节中对焦与光路部分。可以看到在凸透镜光路中，不同位置上对焦的光线是互相不平行的，而Shift-and-Add算法下，所有光线都被认为是&ldquo;平行&rdquo;移动的，所以在重聚焦后的照片中，虚化的部分图像是不一样的，然而这种差距对于人眼来说，其实也没那么大差别。</p><h2 style="margin: 0px; padding: 0px; color: #000000">插值法去重影</h2><p style="margin: 0px; padding: 0px">可能有的朋友看到这里已经发现了，虽然重聚焦是完成了，可是重对焦后图像的质量并不好，比如上一节中对焦在Dell标志上的一张：</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/02/26/A182208746-130912.jpg" border="0" /></p><p style="margin: 0px; padding: 0px">花朵的部分有很明显的重影，和用相机镜头照出来的显然不一样。通过前面部分的原理讲解，这个原因也是很显然的：因为只有9个采样点，在移动-叠加的过程中，不同图像对应像素的移动超过了一个像素，则叠加后的图像就会出现这种类似于重影的瑕疵。其实这个问题解决起来也很简单，记得在<a style="margin: 0px; padding: 0px; text-decoration: none; color: #399ab2" href="http://www.cnblogs.com/frombeijingwithlove/p/4205907.html" target="_blank">上篇文章</a>中，已经讲过如何通过插值得到虚拟位置采样的图像，所以很自然地，我们只要通过插值，让采样点更密，密到每一个采样点和相邻采样点的图像上的对应像素的位移都小于或接近一个像素，那么视觉上这种重影的现象就可以消除了。得到的结果如下：</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/02/26/A182210809-130912.jpg" border="0" /></p><p style="margin: 0px; padding: 0px">最后来个连续变焦的动图：</p><p style="margin: 0px; padding: 0px; text-align: center"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/02/26/A182213527-130912.gif" border="0" /></p><h2 style="margin: 0px; padding: 0px; color: #000000">光圈的模拟</h2><p style="margin: 0px; padding: 0px">许多人在用传统相机拍摄&ldquo;虚化&rdquo;照片时喜欢通过调整光圈来控制虚化的程度。这在基于光场的重聚焦中也是可以模拟的，道理很简单，就是将采样的范围调整就可以了。还是用<a style="margin: 0px; padding: 0px; text-decoration: none; color: #399ab2" href="http://www.cnblogs.com/frombeijingwithlove/p/4205907.html" target="_blank">上一篇文章</a>中的例子，比如用所有的采样点(包括插值得到的)：</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/02/26/A182215605-130912.png_small.png" border="0" /></p><p style="margin: 0px; padding: 0px">得到的图像：</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/02/26/A182217824-130912.jpg_small.jpg" border="0" /></p><p style="margin: 0px; padding: 0px">而如果只采用中间一小部分的采样点的话，相当于小光圈：</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/02/26/A182220230-130912.jpg_small.jpg" border="0" /></p><p style="margin: 0px; padding: 0px">则得到虚化程度比较低的图片：</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/02/26/A182222527-130912.jpg_small.jpg" border="0" /></p><p style="margin: 0px; padding: 0px"><a style="margin: 0px; padding: 0px; color: #399ab2" name="ref.1"></a>[1] R. Ng, &quot;Digital Light Field Photography,&quot; PhD thesis, Stanford University, Stanford, CA (2006)</p></div><div class="srcurl" style="margin: 0px; padding: 0px; color: #333333; font-family: verdana, Arial, Helvetica, sans-serif; font-size: 13.3333px; line-height: 24px">原文链接:<a style="margin: 0px; padding: 0px; text-decoration: none; color: #399ab2" href="http://www.cnblogs.com/frombeijingwithlove/p/4238608.html" target="_blank">http://www.cnblogs.com/frombeijingwithlove/p/4238608.html</a></div>
]]>
</description>
</item><item>
<link>http://i.renjihe.com/blog/read.php?7398</link>
<title><![CDATA[漫谈计算摄像学 (一)：直观理解光场(Light Field)]]></title> 
<author>renjihe1988 &lt;admin@yourname.com&gt;</author>
<category><![CDATA[CV&amp;Graphic]]></category>
<pubDate>Fri, 22 Jul 2016 06:36:52 +0000</pubDate> 
<guid>http://i.renjihe.com/blog/read.php?7398</guid> 
<description>
<![CDATA[ 
	<div class="postText" style="margin: 0px; padding: 0px; color: #333333; font-family: verdana, Arial, Helvetica, sans-serif; font-size: 13.3333px; line-height: 24px"><h1 style="margin: 0px; padding: 0px; color: #000000">什么是计算摄像学</h1><p style="margin: 0px; padding: 0px">计算摄像学(Computational Photography)是近年来越来越受到注意的一个新的领域，在学术界早已火热。本来计算摄像学的业界应用在群众中一直没什么知名度，直到Lytro公司推出了外观十分酷炫的光场相机，打着&ldquo;先拍照再对焦&rdquo;的噱头，这个学科一下子被很多研究领域以外的人开始注意到。那什么是计算摄像学呢？让我们看看清华大学和中科院的教授们怎么说<a style="margin: 0px; padding: 0px; text-decoration: none; color: #399ab2" href="http://doc.okbase.net/frombeijingwithl/archive/124625.html#ref.1" target="_blank">[1]</a>：</p><p style="margin: 0px; padding: 0px">&ldquo;计算摄影学是一门将计算机视觉、数字信号处理、图形学等深度交叉的新兴学科，旨在结合计算、数字传感器、光学系统和智能光照等技术，从成像机理上来改进传统相机，并将硬件设计与软件计算能力有机结合，突破经典成像模型和数字相机的局限性，增强或者扩展传统数字相机的数据采集能力，全方位地捕捉真实世界的场景信息。&rdquo;</p><p style="margin: 0px; padding: 0px">这种定义虽然没什么错误，可其实相当于什么都没说。。个人觉得计算摄像学的定义得从一般的数码摄影对比着来理解。一般的数码摄影分为两个大步骤：1) 通过相机采集图像；2) 后期处理。而在每个大步骤里又有很多小的要素，比如1)里，需要考虑光照，相机角度，镜头组(光学系统)，传感器等等，2)里的方方面面就更多了，降噪，调曲线，各种PS滤镜等等。如果这其中的每一个要素，我们都想办法进行拓展和改变。比如用特殊手段照明，可以从不同角度，或者按一定的时序打闪光灯，再或者用可见光之外的光。又比如改变光学系统，可以调整光圈大小，调整相机镜头位置，或是改变光圈形状等。而每一项采集图像的改变，往往都需要相应的计算机算法后期处理，甚至采集到的数据可以用除了普通显示器以外的方式呈现，那么前面这些一套的成像办法，就都可以归入计算摄像学的范畴。更笼统一下，就是拓展了传统数码摄影中的某个或多个因素的维度来成像的方法，就是计算摄像学。其实现在早就被用的烂熟的HDR就是计算摄像学中的一种办法，拓展的是传统成像中的光圈大小。那么，就当前计算摄像学的发展而言，这些拓展和改变都主要集中在哪些因素上呢？MIT的Raskar教授早就给出过结论：<strong style="margin: 0px; padding: 0px">光学系统</strong>、<strong style="margin: 0px; padding: 0px">传感器</strong>、<strong style="margin: 0px; padding: 0px">照明</strong>和<strong style="margin: 0px; padding: 0px">后期处理</strong><a style="margin: 0px; padding: 0px; text-decoration: none; color: #399ab2" href="http://doc.okbase.net/frombeijingwithl/archive/124625.html#ref.2" target="_blank">[2]</a>。作为漫谈计算摄像学的第一篇，今天要谈的光场，就是基于光学系统和后期处理上的拓展。</p><h1 style="margin: 0px; padding: 0px; color: #000000">光场的定义</h1><p style="margin: 0px; padding: 0px">光场，顾名思义，就是关于光的某个物理量在空间内的分布。这个概念第一次被明确提出是在1939年A. Gershun的一篇论文中<a style="margin: 0px; padding: 0px; text-decoration: none; color: #399ab2" href="http://doc.okbase.net/frombeijingwithl/archive/124625.html#ref.3" target="_blank">[3]</a>，后来被E. H. Adelson和J. R. Bergen在上世纪末的一篇论文中完善，并给出了<strong style="margin: 0px; padding: 0px">全光函数</strong>(Plenoptic Function)的形式。简单来说，光场描述空间中任意一点向任意方向的光线的强度。而完整描述光场的全光函数是个7维函数，包含任意一点的位置(x, y, z)，任意方向(极坐标中的&Theta;, &Phi;)，波长(&lambda;)和时间(t)。附上从Raskar教授的讲义里截的图：</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133700718-124625.png_small.png" border="0" /></p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133703280-124625.png_small.png" border="0" /></p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133705936-124625.png_small.png" border="0" /></p><p style="margin: 0px; padding: 0px">在实际应用中，颜色和时间维度的信息通常是被RGB通道和不同帧表示，所以就光场而言，只关注光线的方向和位置就可以了，这样就从7维降到了5维。而再一般的，大部分成像系统中光线都是在一个有限的光路里传播，所以一种更简单的，用两个平面表示光场的方式被引入：</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133708202-124625.jpg" border="0" /></p><p style="margin: 0px; padding: 0px">这种表示方式中，分别用两个平面上的两个点表示光线经过的两个点，这样一来光线的方向和位置都可以确定，并且维度降到了4个。注意到这样虽然简化了处理，可是局限性是，在实际应用中，两个平面都不是无限大的(即使是无限大也只能描述一半空间)，光场可以描述的范围被两个平面的有效面积限制住了。</p><h1 style="margin: 0px; padding: 0px; color: #000000">用数码相机采集光场</h1><p style="margin: 0px; padding: 0px">知道了光场的定义，那么是不是有什么专门的神奇设备能够在空间中采集这样的4维信息呢？没有的，光场虽然听上去比较高大上，可通常采集的办法还是传统的成像系统：相机。最经典的光场采集办法就是相机阵列，比如下图是Stanford&nbsp;Multi-Camera Array：</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133710452-124625.jpg_small.jpg" border="0" /></p><p style="margin: 0px; padding: 0px">所以就是把相机排列在了一个平面上而已。为什么这样的相机阵列就采集了光场呢？我们先从最原始的针孔(Pinhole)相机模型谈起：</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133712749-124625.jpg_small.jpg" border="0" /></p><p style="margin: 0px; padding: 0px">小孔成像模型是最直观也是最古老的成像模型，小孔相当于把光束的宽度限制得很小，所以如左图光束通过小孔之后再像面上成了一个倒像。这种成像虽然简单，然而一个重大不足是成像的分辨率被小孔大小限制着，小孔越小，则成像越清晰，然而光量也越小，像会很黯淡。为了成明亮的像我们希望光束的量大，也就是小孔大，但也不希望光束的不集中导致成像模糊，所以很自然的，凸透镜成像解决了这个问题。在凸透镜成像系统中，不过镜头怎么复杂，模式都是和中间的示意图一样，一个空间中的点发出的光束，打在透镜的一块面积上后，折射，然后汇聚到一点。所以单从光线采集的角度而言，和小孔成像系统的没有差别。那么这和光场的联系在哪呢，回顾前面说的用两个平面上的两点坐标表示广场的办法，如果我们这里把镜头中心所在平面看成uv平面，定义镜头中心为(0,0)，而成像平面，也就是传感器所在平面看成xy平面，则在普通的成像系统中捕捉到的一幅图像可以看成是u=0, v=0出发的光线在传感器平面上的采样，也就是说我们采集了</p><p style="margin: 0px; padding: 0px">&#92;[L&#92;left( 0,0,x,y &#92;right)&#123;&#123;&#124;&#125;_&#123;x,y&#92;in &#92;text&#123;sensor plane&#125;&#125;&#125;&#92;]</p><p style="margin: 0px; padding: 0px">其中每个L(0,0,x,y)的值就是传感器上的像素值。一个直观的例子是上图的第三个光路图，简化到二维情况的话，只看L(u,x)，假设在传感器平面上有6个像素，那么采集到的6条光线就分别是L(0,-1), L(0,-0.6), L(0,-0.2), L(0,0.2), L(0,0.6), L(0,1)。那么很自然地，如果改变uv的位置，也就是镜头中心的位置，不仅能采集xy平面的光线，uv平面的也可以采集了，所以就能采集整个uv和xy间的光场了，所以相机阵列就相当于在uv平面上布满了很多采样点。</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133715046-124625.jpg_small.jpg" border="0" /></p><p style="margin: 0px; padding: 0px">当然，上面说的是最直观最理想的情况，把相机近似成针孔模型还有个前提是景深足够，另外我的例子里xy平面是用传感器所在平面定义，另一种流行的定义方法是用相机的焦平面，也就是在镜头前方，也就是上图中的虚线箭头，这种方法相对来说就更为直观了，尤其是在假设焦距很小的情况下，虚线所在的平面就是相机平面距离为焦距的地方。事实上，在几何光学里，因为光线是严格直线传播，所以沿着光轴中心的不同位置上，如果都能采样的话，那么采到的像都是相似的，所以理论上讲uv和xy平面是可以沿着光路的中心轴任意位置定义的。另外，除了用x和y，也有很多学者喜欢用s和t描述像平面，不过这仅仅是字母使用习惯上的不同。</p><p style="margin: 0px; padding: 0px">相机阵列只是采集光场的最基本模型，实际实现的系统都是基于相机阵列的原理，但是具体结构非常不一样。</p><p style="margin: 0px; padding: 0px"><strong style="margin: 0px; padding: 0px">Lytro</strong></p><p style="margin: 0px; padding: 0px">Lytro采用的是在传感器表面覆盖一层微镜头阵列<a style="margin: 0px; padding: 0px; text-decoration: none; color: #399ab2" href="http://doc.okbase.net/frombeijingwithl/archive/124625.html#ref.4" target="_blank">[4]</a></p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133717296-124625.jpg_small.jpg" border="0" /></p><p style="margin: 0px; padding: 0px">微镜头阵列就是类似如下，近距离覆盖在传感器表面：</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133719546-124625.jpg_small.jpg" border="0" /></p><p style="margin: 0px; padding: 0px">这个图是Lytro创始人博士论文里的原型机的阵列，(A)是阵列宏观的可视效果，(B)和(C)是微观结构，后来在Lytro中已经改进成了六边形的镜头阵列。一个Lytro在传感器成像的原始图片如下：</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133721765-124625.jpg" border="0" /></p><p style="margin: 0px; padding: 0px">可以看到和相机阵列不同，Lytro采集到的图像是虚脱6边型构成的，不过其实背后的原理都是一样的，这一大幅看着像昆虫眼睛采到的图像是能够通过算法转化成前面提到的相机阵列等效图像的，而每一幅等效的图像又叫Sub-Aperture图像。和Lytro类似的还有Raytrix的光场相机，不过Raytrix的采样精度和采样数都大幅高于玩具般的Lytro，属于工业级光场相机。</p><p style="margin: 0px; padding: 0px"><strong style="margin: 0px; padding: 0px">Adobe Plenoptic Lenses</strong></p><p style="margin: 0px; padding: 0px">名字已经写得很清楚了，lenses，和Lytro还有Raytrix不同，Adobe的光场相机把光场采样镜头置于主镜头组前<a style="margin: 0px; padding: 0px; text-decoration: none; color: #399ab2" href="http://doc.okbase.net/frombeijingwithl/archive/124625.html#ref.5" target="_blank">[5]</a></p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133723890-124625.jpg" border="0" /></p><p style="margin: 0px; padding: 0px"><strong style="margin: 0px; padding: 0px">PiCam</strong></p><p style="margin: 0px; padding: 0px">这是个微缩版的相机阵列，用的就是手机上的那种镜头，4x4阵列，特点是用提出的算法优化了分辨率和深度图估计<a style="margin: 0px; padding: 0px; text-decoration: none; color: #399ab2" href="http://doc.okbase.net/frombeijingwithl/archive/124625.html#ref.6" target="_blank">[6]</a>。</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133726015-124625.jpg_small.jpg" border="0" /></p><p style="margin: 0px; padding: 0px">微缩相机阵列里还有一个例子是去年发布的华为荣耀6 Plus。</p><h1 style="margin: 0px; padding: 0px; color: #000000">光场和3D</h1><p style="margin: 0px; padding: 0px">知道了光场的直观意义，那么很自然地就会想到和普通的照片比起来，获取的信息不再是一幅简单的2D像素阵列，而是三维空间中的光线，也就是说光场中是包含三维信息的。一个简单的例子来说明：</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133728233-124625.png_small.png" border="0" /></p><p style="margin: 0px; padding: 0px">左边的例子是不同uv平面上的相机成像的差别，假设成像后焦平面都取相同的区域的话，可以看到因为uv的不同，所以不同距离上的物体在最终的图像上的位置也不一样，其实这个就是典型的视觉中的Stereo问题。另外既然提到了Stereo，也需要特别提到的是，在相机阵列采集到不同拍照位置的图像之后，有个非常重要的步骤叫做Calibration，也就是在选定的x平面上，要保证两个相机视野是重合的，如左图所示。那么深度的信息是如何获得的呢，来看下图：</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133730452-124625.png_small.png" border="0" /></p><p style="margin: 0px; padding: 0px">假象我们可以保持右边的相机的光场不变，然后向左平移，使得蓝色的光线在成像面上重合，那么最终蓝色方块在两个相机成像的照片里位置就会完全相同，这其实就等效于把原始位置成的像向左移动了一段距离，然后和左边相机成的图像叠加，那么就会发现蓝色方块重合了。类似的，如右图所示，如果把右边相机成的图像向左移动一大段距离，那么更远的绿色三角图像就重合了，要想是不同位置的物体重合就要对应不同的移动距离，而这个距离实际上是和物体到镜头的距离相关的，通过移动距离和相机采样点之间距离的比值就可以轻易求出，进而就相当于我们得出了蓝色方块和绿色三角的深度信息。顺带提一句，让蓝色方块和绿色三角重合的过程其实就已经是所谓的先拍照后聚焦的聚焦过程了，这篇文章不会展开来讲。那么再回到第一幅图中的插值问题，如何通过两个相机得到的图像求出一个虚拟的在两个相机之间的图像呢？</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133732671-124625.png_small.png" border="0" /></p><p style="margin: 0px; padding: 0px">以绿色三角为例子，因为我们用的是镜头前像平面的二维例子，所以这里用L(x,u)表示入射到虚拟位置的光线，则有</p><p style="margin: 0px; padding: 0px">&#92;[L&#92;left( x,u &#92;right)=&#123;&#123;&#92;lambda &#125;_&#123;0&#125;&#125;L&#92;left( &#123;&#123;x&#125;_&#123;0&#125;&#125;,&#123;&#123;u&#125;_&#123;0&#125;&#125; &#92;right)+&#123;&#123;&#92;lambda &#125;_&#123;1&#125;&#125;L&#92;left( &#123;&#123;x&#125;_&#123;1&#125;&#125;,&#123;&#123;u&#125;_&#123;1&#125;&#125; &#92;right)&#92;]</p><p style="margin: 0px; padding: 0px">其实就是以虚拟位置到已有采样位置的距离为权重的线性插值。那具体到采集到的图像这个过程是怎么实现的呢，在相机阵列中需要注意的一点是不仅仅是相机采样是离散点，图像因为是像素构成的所以也是离散采样。示意图如下：</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133734843-124625.png_small.png" border="0" /></p><p style="margin: 0px; padding: 0px">所以实际上用来插值L(u,x)的光线采样有4条，公式如下：</p><p style="margin: 0px; padding: 0px">&#92;[L&#92;left( x,u &#92;right)=&#123;&#123;&#92;lambda &#125;_&#123;0&#125;&#125;L&#92;left( &#123;&#123;x&#125;_&#123;00&#125;&#125;,&#123;&#123;u&#125;_&#123;0&#125;&#125; &#92;right)+&#123;&#123;&#92;lambda &#125;_&#123;1&#125;&#125;L&#92;left( &#123;&#123;x&#125;_&#123;01&#125;&#125;,&#123;&#123;u&#125;_&#123;0&#125;&#125; &#92;right)+&#123;&#123;&#92;lambda &#125;_&#123;2&#125;&#125;L&#92;left( &#123;&#123;x&#125;_&#123;10&#125;&#125;,&#123;&#123;u&#125;_&#123;1&#125;&#125; &#92;right)+&#123;&#123;&#92;lambda &#125;_&#123;3&#125;&#125;L&#92;left( &#123;&#123;x&#125;_&#123;11&#125;&#125;,&#123;&#123;u&#125;_&#123;1&#125;&#125; &#92;right)&#92;]</p><p style="margin: 0px; padding: 0px">其中</p><p style="margin: 0px; padding: 0px">&#92;[&#123;&#123;&#92;lambda &#125;_&#123;0&#125;&#125;=&#92;left( 1-&#92;frac&#123;&#92;left&#124; x-&#123;&#123;x&#125;_&#123;00&#125;&#125; &#92;right&#124;&#125;&#123;&#92;left&#124; &#123;&#123;x&#125;_&#123;01&#125;&#125;-&#123;&#123;x&#125;_&#123;00&#125;&#125; &#92;right&#124;&#125; &#92;right)&#92;left( 1-&#92;frac&#123;&#92;left&#124; u-&#123;&#123;u&#125;_&#123;0&#125;&#125; &#92;right&#124;&#125;&#123;&#92;left&#124; &#123;&#123;u&#125;_&#123;0&#125;&#125;-&#123;&#123;u&#125;_&#123;1&#125;&#125; &#92;right&#124;&#125; &#92;right)&#92;]</p><p style="margin: 0px; padding: 0px">&#92;[&#123;&#123;&#92;lambda &#125;_&#123;1&#125;&#125;=&#92;left( 1-&#92;frac&#123;&#92;left&#124; x-&#123;&#123;x&#125;_&#123;01&#125;&#125; &#92;right&#124;&#125;&#123;&#92;left&#124; &#123;&#123;x&#125;_&#123;01&#125;&#125;-&#123;&#123;x&#125;_&#123;00&#125;&#125; &#92;right&#124;&#125; &#92;right)&#92;left( 1-&#92;frac&#123;&#92;left&#124; u-&#123;&#123;u&#125;_&#123;0&#125;&#125; &#92;right&#124;&#125;&#123;&#92;left&#124; &#123;&#123;u&#125;_&#123;0&#125;&#125;-&#123;&#123;u&#125;_&#123;1&#125;&#125; &#92;right&#124;&#125; &#92;right)&#92;]</p><p style="margin: 0px; padding: 0px">&#92;[&#123;&#123;&#92;lambda &#125;_&#123;2&#125;&#125;=&#92;left( 1-&#92;frac&#123;&#92;left&#124; x-&#123;&#123;x&#125;_&#123;10&#125;&#125; &#92;right&#124;&#125;&#123;&#92;left&#124; &#123;&#123;x&#125;_&#123;11&#125;&#125;-&#123;&#123;x&#125;_&#123;10&#125;&#125; &#92;right&#124;&#125; &#92;right)&#92;left( 1-&#92;frac&#123;&#92;left&#124; u-&#123;&#123;u&#125;_&#123;1&#125;&#125; &#92;right&#124;&#125;&#123;&#92;left&#124; &#123;&#123;u&#125;_&#123;0&#125;&#125;-&#123;&#123;u&#125;_&#123;1&#125;&#125; &#92;right&#124;&#125; &#92;right)&#92;]</p><p style="margin: 0px; padding: 0px">&#92;[&#123;&#123;&#92;lambda &#125;_&#123;3&#125;&#125;=&#92;left( 1-&#92;frac&#123;&#92;left&#124; x-&#123;&#123;x&#125;_&#123;11&#125;&#125; &#92;right&#124;&#125;&#123;&#92;left&#124; &#123;&#123;x&#125;_&#123;11&#125;&#125;-&#123;&#123;x&#125;_&#123;10&#125;&#125; &#92;right&#124;&#125; &#92;right)&#92;left( 1-&#92;frac&#123;&#92;left&#124; u-&#123;&#123;u&#125;_&#123;1&#125;&#125; &#92;right&#124;&#125;&#123;&#92;left&#124; &#123;&#123;u&#125;_&#123;0&#125;&#125;-&#123;&#123;u&#125;_&#123;1&#125;&#125; &#92;right&#124;&#125; &#92;right)&#92;]</p><p style="margin: 0px; padding: 0px">这是二维光场的情况，如果实际应用中需要对4维光场插值，则这个公式一共涉及到16条光线，下面是个示意图：</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133737155-124625.jpg_small.jpg" border="0" /></p><p style="margin: 0px; padding: 0px">公式看上去很复杂，不过直观地理解也不困难，每根光线前的系数里，和u有关的部分就是指将图像按照相机采样位置差异进行移动的幅度，也就是把采到的图像进行平移(如下图)，而和x有关的部分就是在传感器上对光线通过的位置进行插值。利用深度信息的辅助，在整幅图像上进行这个过程就能得到一个没有采样点上的虚拟相机采到的插值图像。</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133739452-124625.png_small.png" border="0" /></p><p style="margin: 0px; padding: 0px">来做个简单的实例试一试，用手机拍9幅照片，也就是3x3的采样：</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133742390-124625.jpg_small.jpg" border="0" /></p><p style="margin: 0px; padding: 0px">接下来是前面提到的Calibration，以中心的字母U作为聚焦平面，并且重新构图裁剪画面：</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133746233-124625.jpg_small.jpg" border="0" /></p><p style="margin: 0px; padding: 0px">做Calibration的过程中可以得到照片拍摄时的位置信息：</p><p style="margin: 0px; padding: 0px; text-align: center"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133748608-124625.png_small.png" border="0" /></p><p style="margin: 0px; padding: 0px">可以看到由于手持手机的误差，我的采样位置是很不规则的，不过能大概看出是在&ldquo;田&rdquo;字格上采样，除了位置信息还能提取出深度信息，提取深度的算法有很多，为了方便我这里使用的是最原始的disparity比较：</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133750874-124625.jpg_small.jpg" border="0" /></p><p style="margin: 0px; padding: 0px">接下来进行采样插值，我采取的策略是在每四个采样点之间进行Quadrilinear采样：</p><p style="margin: 0px; padding: 0px; text-align: center"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133753124-124625.png_small.png" border="0" /></p><p style="margin: 0px; padding: 0px">采样的效果怎么样呢，沿着我的采样点我画了条轨迹试试，起点和终点分别是左下角和右下角的采样点，把对应的插值图像提取出来，轨迹和对应的动图如下：</p><p style="margin: 0px; padding: 0px"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133755358-124625.png_small.png" border="0" /></p><p style="margin: 0px; padding: 0px; text-align: center"><img style="margin: 0px; padding: 0px; border: 0px; cursor: pointer" src="http://doc.okbase.net/picture/addon/2015/01/20/A133759421-124625.gif" border="0" /></p><p style="margin: 0px; padding: 0px">参考文献：</p><p style="margin: 0px; padding: 0px"><a style="margin: 0px; padding: 0px; color: #399ab2" name="ref.1"></a>[1]&nbsp;<a style="margin: 0px; padding: 0px; text-decoration: none; color: #399ab2" href="http://wenku.baidu.com/link?url=ViSzmcYvSZNN-NYa-mxlqy8hnKJWxqj1hukSUYLIuVm79LUjYG54dfEOZTHVDGeMwsd4hFMTUepFMnsVLINlZ1o0-s5oGucwWg4o4RlejYG">http://wenku.baidu.com/link?url=ViSzmcYvSZNN-NYa-mxlqy8hnKJWxqj1hukSUYLIuVm79LUjYG54dfEOZTHVDGeMwsd4hFMTUepFMnsVLINlZ1o0-s5oGucwWg4o4RlejYG</a></p><p style="margin: 0px; padding: 0px"><a style="margin: 0px; padding: 0px; color: #399ab2" name="ref.2"></a>[2]&nbsp;<a style="margin: 0px; padding: 0px; text-decoration: none; color: #399ab2" href="http://web.media.mit.edu/~raskar/photo/">http://web.media.mit.edu/~raskar/photo/</a></p><p style="margin: 0px; padding: 0px"><a style="margin: 0px; padding: 0px; color: #399ab2" name="ref.3"></a>[3] A. Gershun, &ldquo;The light field,&rdquo; J. Math. Phys., Vol. 18, pp. 51&ndash;151, 1939</p><p style="margin: 0px; padding: 0px"><a style="margin: 0px; padding: 0px; color: #399ab2" name="ref.4"></a>[4]&nbsp;R. Ng, &quot;Digital Light Field Photography,&quot; PhD thesis, Stanford University, Stanford, CA (2006)</p><p style="margin: 0px; padding: 0px"><a style="margin: 0px; padding: 0px; color: #399ab2" name="ref.5"></a>[5]&nbsp;T. Georgiev, A. Lumsdaine, &quot;Focused plenoptic camera and rendering,&quot; Journal of Electronic Imaging 19(2), 2010</p><p style="margin: 0px; padding: 0px"><a style="margin: 0px; padding: 0px; color: #399ab2" name="ref.6"></a>[6]&nbsp;K. Venkataraman, et. al &quot;PiCam: An Ultra-Thin High Performance Monolithic Camera Array,&quot; ACM Transactions on Graphics(SIGGRAPH) 2013</p></div><div class="srcurl" style="margin: 0px; padding: 0px; color: #333333; font-family: verdana, Arial, Helvetica, sans-serif; font-size: 13.3333px; line-height: 24px">原文链接:<a style="margin: 0px; padding: 0px; text-decoration: none; color: #399ab2" href="http://www.cnblogs.com/frombeijingwithlove/p/4205907.html" target="_blank">http://www.cnblogs.com/frombeijingwithlove/p/4205907.html</a></div>
]]>
</description>
</item><item>
<link>http://i.renjihe.com/blog/read.php?7397</link>
<title><![CDATA[体绘制（Volume Rendering）概述]]></title> 
<author>renjihe1988 &lt;admin@yourname.com&gt;</author>
<category><![CDATA[CV&amp;Graphic]]></category>
<pubDate>Fri, 22 Jul 2016 06:36:27 +0000</pubDate> 
<guid>http://i.renjihe.com/blog/read.php?7397</guid> 
<description>
<![CDATA[ 
	<p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px"><strong>摘抄&ldquo;GPU Programming And Cg Language Primer 1rd Edition&rdquo; 中文名&ldquo;GPU编程与CG语言之阳春白雪下里巴人&rdquo;&nbsp; &nbsp;</strong></p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">1982 年2 月，美国国家科学基金会在华盛顿召开了科学可视化技术的首次会议，会议认为&ldquo;科学家不仅需要分析由计算机得出的计算数据，而且需要了解在计算过程中的数据变换，而这些都需要借助于计算机图形学以及图像处理技术&rdquo;。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">---- 《三维数据场可视化》1.1 节科学计算可视化概述</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">&nbsp;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">自 20 世纪 80 年代科学计算可视化（ Visualization in Scientific Computing ）被提出后，三维体数据的可视化逐渐称为发展的重点，并最终形成了体绘制技术领域。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">一些文章，甚至是优秀硕博士论文库上的文章，解释体绘制概念时，通常都说 &ldquo; 体绘制技术是直接根据三维体数据场信息产生屏幕上的二维图像 &rdquo; ，这种说法太过含糊，如果根据三维体数据场信息随便产生一张图像，难道也是体绘制吗？我查找相关文献后，发现这种说法是国外一些文献的误译，例如， M.Levoy 在文章 &ldquo;Display of surfaces from volume data&rdquo;( 文献【 14 】 ) 中提到 &ldquo;volume rendering describes a wide range of techniques for generating images from three-dimensional scalar data&rdquo; ，翻译过来就是 &ldquo; 体绘制描述了一系列的 &ldquo; 根据三维标量数据产生二维图片 &rdquo; 的技术 &rdquo; 。注意，人家文章中用的是 &ldquo; 描述 &rdquo; ，而不是对体绘制下定义。老实说，老外的这种说法虽然挑不出毛病，但是我依然感觉没有落实到重点。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">体绘制的核心在于 &ldquo; 展示体细节！而不是表面细节 &rdquo; 。我给出的定义是：依据三维体数据，将所有体细节同时展现在二维图片上的技术，称之为体绘制技术。利用体绘制技术，可以在一幅图像中显示多种物质的综合分布情况，并且可以通过不透明度的控制，反应等值面的情况。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">例如， CT 图片中展示的是人体的肌肉和骨骼信息，而不是表面信息（那是照片）。所以理解体绘制和面绘制技术的区别的 , 一个很直观的比喻是：普通照相机照出的相片和 CT 仪器拍出的 CT 照片，虽然都是二维图片，但是展现的对象是不同的！</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">国外自上世纪 80 年代末以来，在体绘制技术方面已经取得了长足的进步，西门子、东芝、通用电器，都有对 GPU 编程领域以及体绘制技术进行研究，并将体绘制技术运用到医疗器材中。然而，体绘制技术在中国的发展，如果说还处于萌芽阶段，实不为过！我在学习和研究过程中，在国内网站上甚至只找到了一个可用的体数据，还是国外代码中附带的演示数据，而国内的 openGPU 网站上关于体绘制的论坛板块则是根本是空白。国外已经常用的医疗器材和算法，在中国还没有成形，这实在是一种悲哀。一个讽刺的现象是，外国公司从事体绘制算法研究的却不乏中国人，这更是一种悲哀。写到这里，作为一名以 server the people 为毕生理想的有志青年，我有点伤感，有些沮丧，所以，还是先洗洗睡了，明天再来写下面的章节。</p><h2 style="margin: 0px; padding: 0px; font-family: Arial; line-height: 26px"><a style="color: #ff9900" name="t0"></a>14.1 体绘制与科学可视化</h2><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">科学可视化技术是运用计算机图形学、图像处理、计算机视觉等方法，将科学、工程学、医学等计算、测量过程中的符号、数字信息转换为直观的图形图像，并在屏幕上显示的理论、技术和方法。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">体绘制是科学可视化领域中的一个技术方向。如前所述，体绘制的目标是在一副图片上展示空间体细节。举例而言，你面前有一间房子，房子中有家具、家电，站在房子外面只能看到外部形状，无法观察到房子的布局或者房子中的物体；假设房子和房子中的物体都是半透明的，这样你就可以同时查看到所有的细节。这就是体绘制所要达到的效果。</p><h2 style="margin: 0px; padding: 0px; font-family: Arial; line-height: 26px"><a style="color: #ff9900" name="t1"></a>14.2 体绘制应用领域</h2><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">人类发展史上的重大技术带来的影响大致分为两种：其一，技术首先改变生活本身，然后改变人类对世界的看法，例如电视、电话等；还有一种技术，是首先改变人类对世界的看法，然后改变生活本身，例如伦琴射线、望远镜。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">体绘制技术应该属于后者，通过改变所见，而改变生活。体绘制计算的重要意义，首先在于可以在医疗领域 server the people, 有助于疾病的诊断，这一点应该不用多说，计算机断层扫描（ CT ）已经广泛应用于疾病的诊断。医疗领域的巨大需求推动了体绘制技术的告诉发展，如果了解 CT 的工作原理，也就大致了解了体绘制技术原理和流程，所以本书在附录 B 给出了医学体绘制的有关文献，作为补充阅读资料，当您对体素、光线投射等术语缺乏感性认识时，可以参阅理解；其二，体绘制计算可以用于地质勘探、气象分析、分子模型构造等科学领域。我在工作期间承担的一个较大的项目便是有关 &ldquo; 三维气象可视化 &rdquo; ，气象数据通常非常庞大，完全可以号称海量数据，每一个气压面上都有温度、湿度、风力风向等格点数据，气象研究人员希望可以同时观察到很多气压面的情况，这时就可以采用体绘制技术，对每个切面（气压面）进行同时显示。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">体绘制技术也能用于强化视觉效果，自然界中很多视觉效果是不规则的体，如流体、云、烟等，它们很难用常规的几何元素进行建模，使用粒子系统的模拟方法也不能尽善尽美，而使用体绘制可以达到较好的模拟效果。如 图 41 所示，这是使用体绘制技术进行烟的模拟效果。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px"><img style="border: none; max-width: 100%" src="http://p.blog.csdn.net/images/p_blog_csdn_net/liu_lin_xm/EntryImages/20091122/41.jpg" border="0" /><br /></p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="center"></p><h2 style="margin: 0px; padding: 0px; font-family: Arial; line-height: 26px"><a style="color: #ff9900" name="t2"></a>14.3 体绘制与光照模型</h2><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">尽管光照模型通常用于面绘制，但是并不意味着体绘制技术中不能使用光照模型。实际上 , 体绘制技术以物体对光的吸收原理为理论基础，在实现方式上，最终要基于透明度合成计算模型。此外，经典的光照模型，例如 phong 模型， cook-torrance 模型都可以做为体绘制技术的补充，完善体绘制效果，增强真实感。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">往往有初学者会分不清 &ldquo; 体绘制技术 &rdquo; 以及 &ldquo; 透明光照模型 &rdquo; 之间的区别。这个问题很有意思。实际上，体绘制技术与透明光照模型在感性认识上十分类似，在很多教程中对体绘制技术的阐述也涉及到透明物体。但是，透明光照模型，一般侧重于分析光在透明介质中的传播方式（折射，发散，散射，衰减等），并对这种传播方式所带来的效果进行模拟；而体绘制技术偏重于物体内部层次细节的真实展现。举例而言，对于一个透明的三棱镜，使用透明光照模型的目的在于 &ldquo; 模拟光的散射，折射现象（彩虹） &rdquo; ；而对于地形切片数据或者人体数据，则需要使用体绘制技术观察到其中的组织结构。此外，在实现方式上，透明光照模型一般是跟踪光线的交互过程，并在一系列的交互过程中计算颜色值；而体绘制技术是在同一射线方向上对体数据进行采样，获取多个体素的颜色值，然后根据其透明度进行颜色的合成。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">总的来说，透明光照模型侧重于光照效果展现，并偏向艺术化；而体绘制技术侧重展现物质内部细节，要求真实！</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">不过，现在体绘制技术实际上也可以用于艺术领域，因为体绘制技术所使用的方法，实际上具有很强的通用性，尤其是传统的 ray-cast 方法，完全可以应用到透明光照模型中（绘制烟雾等）。不同的技术之间会存在共融性，将技术和领域的关系近固化，是研究人员的大忌。科学史上很多前例都说明了一个事实：不同领域的交合点，往往会出现重大发现或发明。在爱因斯坦之前，又有谁知道时间、空间和质量之间的关系呢？</p><h2 style="margin: 0px; padding: 0px; font-family: Arial; line-height: 26px"><a style="color: #ff9900" name="t3"></a>体数据（ Volume Data ）</h2><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">学习任何一门技术，首先要弄清楚这项技术的起源以及数据来源。技术的起源也就是技术最原始的需求，最原始的发展动力，了解了这一点就了解了这项技术的价值。而了解一门技术的数据来源，就把握了技术的最初脉络，是 &ldquo; 持其牛耳 &rdquo; 的一种方法，正如软件工程中的数据流分析方法一般。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">我很想说，体数据与面数据的区别，就好像一个实心的铁球和一个空心的兵乓球的区别。不过这个比喻很显然有点俗，很难让人相信作者（我）是一个专业人士。于是我决定还是将与体数据相关的专业术语都阐述一遍。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">不过，在此之前，我需要先消除大家的恐惧感，研究表明，动物对于未知事物总是存在恐惧感，这也是阻碍进一步学习的关键所在。体数据不是什么特别高深的火星符号，它是对一种数据类型的描述，只要是包含了体细节的数据，都可以称之为体数据。举个例子，有一堆混凝土，其中包含了碳物质（ C ）若干，水分子（ H20 ）若干，还有不明化学成分的胶状物，你用这种混凝土建造了块方砖，如果存在一个三维数组，将方砖 X 、 Y 、 Z 方向上的物质分布表示出来，则该数组可以被称为体数据。不要小看上面这个比喻，体数据本质上就是按照这个原理进行组织的！</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">体数据一般有 2 种来源：</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">1.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 科学计算的结果，如：有限元的计算和流体物理计算；</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">2.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 仪器测量数据，如： CT 或 MRI 扫描数据、地震勘测数据、气象检测数据等。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">与体数据相关的专业术语有：体素（ Voxel ）、体纹理（ Volume Texture ）。尤其要注意：所谓面数据，并不是说二维平面数据，而是说这个数据中只有表面细节，没有包含体细节，实际上体数据和面数据的本质区别，在于是否包含了体细节，而不是在维度方面。</p><h3 style="margin: 0px; padding: 0px; font-family: Arial; line-height: 26px"><a style="color: #ff9900" name="t4"></a>14.4.2 体素（ Voxel ）</h3><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">Wikipedia 中对体属 voxel 的介绍为：</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">A voxel (a&nbsp;<a style="color: #ff9900; text-decoration: none" href="http://en.wikipedia.org/wiki/Portmanteau" title="Portmanteau">portmanteau&nbsp;</a>of the words&nbsp;<a style="color: #ff9900; text-decoration: none" href="http://en.wikipedia.org/wiki/Volumetric" title="Volumetric">volumetric&nbsp;</a>and&nbsp;<a style="color: #ff9900; text-decoration: none" href="http://en.wikipedia.org/wiki/Pixel" title="Pixel">pixel</a>) is a volume element, representing a value on a&nbsp;<a style="color: #ff9900; text-decoration: none" href="http://en.wikipedia.org/wiki/Regular_grid" title="Regular grid">regular grid&nbsp;</a>in&nbsp;<a style="color: #ff9900; text-decoration: none" href="http://en.wikipedia.org/wiki/3D_computer_graphics" title="3D computer graphics">three dimensional&nbsp;</a>space. This is analogous to a&nbsp;<a style="color: #ff9900; text-decoration: none" href="http://en.wikipedia.org/wiki/Pixel" title="Pixel">pixel&nbsp;</a>, which represents&nbsp;<a style="color: #ff9900; text-decoration: none" href="http://en.wikipedia.org/wiki/2D_computer_graphics" title="2D computer graphics">2D&nbsp;</a>image data in a&nbsp;<a style="color: #ff9900; text-decoration: none" href="http://en.wikipedia.org/wiki/Bitmap" title="Bitmap">bitmap&nbsp;</a>。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">即 &ldquo; 体素，是组成体数据的最小单元，一个体素表示体数据中三维空间某部分的值。体素相当于二维空间中像素的概念 &rdquo; 。 图 42 中每个小方块代表一个体素。体素不存在绝对空间位置的概念，只有在体空间中的相对位置，这一点和像素是一样的。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">通常我们看到的体数据都会有一个体素分布的描述，即，该数据由 n*m*t 个体素组成，表示该体数据在 X 、 Y 、 Z 方向上分别有 n 、 m 、 t 个体素。在数据表达上，体素代表三维数组中的一个单元。假设一个体数据在三维空间上 256*256*256 个体素组成，则，如果用三维数组表示，就必须在每一维上分配 256 个空间。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">在实际的仪器采样中，会给出体素相邻间隔的数据描述，单位是毫米（ mm ），例如 0.412mm 表示该体数据中相邻体素的间隔为 0.412 毫米 。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px"><img style="border: none; max-width: 100%" src="http://p.blog.csdn.net/images/p_blog_csdn_net/liu_lin_xm/EntryImages/20091122/42.jpg" border="0" /><br /></p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="center"></p><h3 style="margin: 0px; padding: 0px; font-family: Arial; line-height: 26px"><a style="color: #ff9900" name="t5"></a>14.4.1 体纹理（ Volume Texture ）</h3><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">体数据最主要的文件格式是 &ldquo; 体纹理（ volume texture ） &rdquo; ！故而，非常有必要对体纹理的概念进行详细的阐述。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">目前，学术性文章中关于体纹理的概念描述存在不小的混乱，很多书籍或者网页资料没有明确的区分 2d texture ， 3d texture ， volume texture 之间的区别。导致不少人认为 &ldquo; 只要是用于三维虚拟或仿真技术中的纹理都称之为 3d texture&rdquo; 。这是一个误会。纹理上的 2 ， 3 维之分本质上是根据其所描述的数据维数而定的，所谓 2d texture 指的是纹理只描述了空间的面数据，而 3d texture 则是描述了空间中的三维数据。 3d texture 另一个较为学术化的名称是： volume texture 。文献【 22 】上对体纹理的定义是：</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">3D texture (Three Dimensional Texture), also known as &quot;volume texture,&quot; is a logical extension of the traditional (and better known) 2D texture. In this context, a texture is simply a bitmap image that is used to provide surface coloring for a 3D model. A 3D texture can be thought of as a number of thin pieces of texture used to generate a three dimensional image map. 3D textures are typically represented by 3 coordinates.</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">翻译成中文就是 &ldquo; 三维纹理，即体纹理，是传统 2D 纹理在逻辑上的扩展。二维纹理是一张简单的位图图片，用于为三维模型提供表面点的颜色值；而一个三维纹理，可以被认为由很多张 2D 纹理组成的，用于描述三维空间数据的图片。三维纹理通过三维纹理坐标进行访问 &rdquo; 。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">从上面这句话，可以得到两点信息：</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">1.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 三维纹理和体纹理是同一概念；三维纹理和二维纹理是不同的；</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">2.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 三维纹理通过三维纹理坐标进行访问。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">这时可能会有人提出问题了，图片都是平面的，怎么能表示三维数据？请注意，我们通常所看到的图片确实都是平面的，但是并不意味着 x,y 平面上的像素点不能存放三维数据，举一个例子：在高级语言编程中，我们完全可以用一维数组去存放三维数组中的数据，只要按照一定规则存放即可！</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">按照一定规则将三维数据存放在 XY 像素平面所得到的纹理，称之为 volume texture 。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">体数据通常是由 CT 仪器进行扫描得到的，然后保存在图片的像素点上。目前国际上比较常用的体纹理格式有，基于 DirectX 的 .dds 格式和 .raw 格式。注意，很多人会将 .raw 格式当作摄像器材使用的那种格式，其实这两个格式的后缀虽然都是 .raw ，但是其数据组织形式是不同的。用于体纹理的 .raw 格式，存放的是三维数据，用于摄像器材的 .raw 格式只是普通的二维图片。 图 43 从左到右分别是 University of T&uuml;bingen （ Germany ）、 Viatronix Inc.(USA) 、 Walter Reed Army Medical Center (USA) 三家机构的通过仪器扫描得到的体纹理数据的体绘制图片。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left"><img style="border: none; max-width: 100%" src="http://p.blog.csdn.net/images/p_blog_csdn_net/liu_lin_xm/EntryImages/20091122/43.jpg" border="0" /><br /></p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="center"></p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">这三个体纹理数据的描述分别是： 256 x 320 x 128 /0.66, 0.66, 0.66 ； 512 x 512 x 174/0.8398, 0.8398, 3.2 ； 512 x 512 x 463/0.625, 0.625, 1.0 。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">由于在国内的网站上很难找到体数据，所以下面我给出几个国外的网址，这些网址提供用于教学和研究只用的体纹理数据（只能用于教学和研究）。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">http://wwwvis.informatik.uni-stuttgart.de/~engel/pre-integrated/data.html</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">http://www9.informatik.uni-erlangen.de/External/vollib/</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">http://www.volren.org/</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;</p><h2 style="margin: 0px; padding: 0px; font-family: Arial; line-height: 26px"><a style="color: #ff9900" name="t6"></a>14.5 体绘制算法</h2><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">国际上留下的体绘制算法主要有：光线投射算法（ Ray-casting ）、错切 - 变形算法（ Shear-warp ）、频域体绘制算法（ Frequency Domain ）和抛雪球算法（ Splatting ）。其中又以光线投射算法最为重要和通用。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">究其原因，无外乎有三点：其一，该算法在解决方案上基于射线扫描过程，符合人类生活常识，容易理解；其二，该算法可以达到较好的绘制效果；其三，该算法可以较为轻松的移植到 GPU 上进行实现，可以达到实时绘制的要求。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">本书的第 15 章将重点阐述光线投射算法。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;</p><h2 style="margin: 0px; padding: 0px; font-family: Arial; line-height: 26px"><a style="color: #ff9900" name="t7"></a>15.1 光线投射算法原理</h2><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">光线投射方法是基于图像序列的直接体绘制算法。从图像的每一个像素，沿固定方向（通常是视线方向）发射一条光线，光线穿越整个图像序列，并在这个过程中，对图像序列进行采样获取颜色信息，同时依据光线吸收模型将颜色值进行累加，直至光线穿越整个图像序列，最后得到的颜色值就是渲染图像的颜色。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">为什么在上面的定义是穿越 &ldquo; 图像序列 &rdquo; ，而不是直接使用 &ldquo; 体纹理 &rdquo; ？原因在于，体数据有多种组织形式，在基于 CPU 的高级语言编程中，有时并不使用体纹理，而是使用图像序列。在基于 GPU 的着色程序中，则必须使用体纹理。这里所说的图像序列，也可以理解为切片数据。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">尤其要注意：光线投射算法是从视点到 &ldquo; 图像序列最表面的外层像素 &rdquo; 引射线穿越体数据，而不少教程中都是糊里糊涂的写到 &ldquo; 从屏幕像素出发 &rdquo; ，这种说法太过简单，而且很容易让人误解技术的实现途径，可以说这是一种以讹传讹的说法！从屏幕像素出发引出射线，是光线跟踪算法，不是光线投射算法。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">体绘制中的光线投射方法与真实感渲染技术中的光线跟踪算法有些类似，即沿着光线的路径进行色彩的累计。但两者的具体操作不同。首先，光线投射方法中的光线是直线穿越数据场，而光线跟踪算法中需要计算光线的反射和折射现象。其次，光线投射算法是沿着光线路径进行采样，根据样点的色彩和透明度，用体绘制的色彩合成算子进行色彩的累计，而光线跟踪算法并不刻意进行色彩的累计，而只考虑光线和几何体相交处的情况；最后，光线跟踪算法中光线的方向是从视点到屏幕像素引射线，并要进行射线和场景实体的求交判断和计算，而光线投射算法，是从视点到物体上一点引射线（ 16.1.2 节会进行详细阐述），不必进行射线和物体的求交判断。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">上述文字，对于光线投射算法的描述可能太过简单，会引起一些疑惑，不过这是正常的，有了疑惑才会去思考解决之道，最怕看了以后没有任何疑惑，那只是浮光掠影似的一知半解，而不是真正的了然于胸。</p><h3 style="margin: 0px; padding: 0px; font-family: Arial; line-height: 26px"><a style="color: #ff9900" name="t8"></a>15.1.1 吸收模型</h3><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">几乎每一个直接体绘制算法都将体数据当作 &ldquo; 在某一密度条件下，光线穿越体时，每个体素对光线的吸收发射分布情况 &rdquo; 。这一思想来源于物理光学，并最终通过光学模型（ Optical Models ）进行分类描述。为了区别之前的光照渲染模型，下面统一将 Optical Model 翻译为光学模型。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">文献【 15 】中对大多数在直接体绘制算法中使用的重要光学模型进行了描述，这里给出简要概述。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">1.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 吸收模型（ Absorption only ）：将体数据当作由冷、黑的体素组成，这些体素对光线只是吸收，本身既不发射光线，也不反射、透射光线；</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">2.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 发射模型（ Emission only ）：体数据中的体素只是发射光线，不吸收光线；</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">3.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 吸收和发射模型（ Absorption plus emission ）：这种光学模型使用最为广泛，体数据中的体素本身发射光线，并且可以吸收光线，但不对光线进行反射和透射。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">4.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 散射和阴影模型（ Scattering and Shading/shadowing ）：体素可以散射（反射和折射）外部光源的光线，并且由于体素之间的遮挡关系，可以产生阴影；</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">5.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 多散射模型（ Multiple Scattering ）：光线在被眼睛观察之前，可以被多个体素散射。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">通常我们使用 吸收和发射模型（ Absorption plus emission ）。为了增强真实感，也可以加上阴影（包括自阴影）计算。</p><h2 style="margin: 0px; padding: 0px; font-family: Arial; line-height: 26px"><a style="color: #ff9900" name="t9"></a>15.2 光线投射算法若干细节之处</h2><h3 style="margin: 0px; padding: 0px; font-family: Arial; line-height: 26px"><a style="color: #ff9900" name="t10"></a>15.2.1 光线如何穿越体纹理</h3><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">这一节中将阐述光线如何穿越体纹理。这是一个非常重要的细节知识点，很多人就是因为无法理解 &ldquo; 体纹理和光线投射的交互方式 &rdquo; 而放弃学习体绘制技术。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">前面的章节似乎一直在暗示这一点：通过一个体纹理，就可以进行体渲染。我最初学习体绘制时，也被这种暗示迷惑了很久，后来查找到一个国外的软件，可以将体纹理渲染到立方体或者圆柱体中，这时我才恍然大悟：体纹理并不是空间的模型数据，空间体模型（通常是规则的立方体或圆柱体）和体纹理相互结合才能进行体渲染。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">举例而言，我们要在电脑中看到一个纹理贴图效果，那么至少需要一张二维的纹理和一个面片，才能进行纹理贴图操作。这个面片实际上就是纹理的载体。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">同理，在体绘制中同样需要一个三维模型作为体纹理的载体，体纹理通过纹理坐标（三维）和模型进行对应，然后由视点向模型上的点引射线，该射线穿越模型空间等价于射线穿越了体纹理。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">通常使用普通的立方体或者圆柱体作为体绘制的空间模型。本章使用立方体作为体纹理的载体。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">注意：体纹理通过纹理坐标和三维模型进行对应，考虑到 OpenGL 和 Direct3D 使用的体纹理坐标并不相同，所以写程序时请注意到这一点。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px"><img style="border: none; max-width: 100%" src="http://p.blog.csdn.net/images/p_blog_csdn_net/liu_lin_xm/EntryImages/20091122/44.jpg" border="0" /><br /></p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="center"></p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">图 44 展示了体纹理坐标在立方体上的分布，经过测试，这种分布关系是基于 OpenGL 的。在宿主程序中确定立方体 8 个顶点的体纹理坐标，注意是三元向量，然后传入 GPU ，立方体 6 个面内部点的体纹理坐标会在 GPU 上自动插值得到。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">根据视点和立方体表面点可以唯一确定一条射线，射线穿越整个立方体等价于穿越体数据，并在穿越过程中对体数据等距采样，对每次得到的采样数据按照光透公式进行反复累加。这个累加过程基于 11 章讲过的透明合成公式，不过之前只是进行了简单的讲解，在本章中将针对透明度，透明合成，以及排序关系做全面阐述。</p><h3 style="margin: 0px; padding: 0px; font-family: Arial; line-height: 26px"><a style="color: #ff9900" name="t11"></a>15.2.2 透明度、合成</h3><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">透明度本质上代表着光穿透物体的能力，光穿透一个物体会导致波长比例的变化，如果穿越多个物体，则这种变化是累加的。所以，透明物体的渲染，本质上是将透明物体的颜色和其后物体的颜色进行混合，这被称为 alpha 混合技术。图形硬件实现 alpha 混合技术，使用 over 操作符。 Alpha 混合技术的公式如下所示：</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left"><img style="border: none; max-width: 100%" src="http://p.blog.csdn.net/images/p_blog_csdn_net/liu_lin_xm/EntryImages/20091122/gs-15-1.jpg" border="0" />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">其中，as 表示透明物体的透明度， cs表示透明物体的原本颜色， cd表示目标物体的原本颜色， co 则是通过透明物体观察目标物体所得到的颜色值。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">如果有多个透明物体，通常需要对物体进行排序，除非所有物体的透明度都是一样的。在图形硬件中实现多个透明物体的绘制是依赖于 Z 缓冲区。在光线投射算法中，射线穿越体纹理的同时也就是透明度的排序过程。所以这里存在一个合成的顺序问题。可以将射线穿越纹理的过程作为采样合成过程，这是从前面到背面进行排序，也可以反过来从背面到前面排序，毫无疑问这两种方式得到的效果是不太一样的。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">如果从前面到背面进行采样合成，则合成公式为：</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left"><img style="border: none; max-width: 100%" src="http://p.blog.csdn.net/images/p_blog_csdn_net/liu_lin_xm/EntryImages/20091122/gs-15-2.jpg" border="0" />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">其中， Ci 和 Ai分别是在体纹理上采样所得到的颜色值和不透明度，其实也就是体素中蕴含的数据； deta Ci和 deta Ai表示累加的颜色值和不透明度。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">注意，很多体纹理其实并没有包含透明度，所以有时是自己定义一个初始的透明度，然后进行累加。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">如果从背面到前面进行采样合成，则公式为：</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left"><img style="border: none; max-width: 100%" src="http://p.blog.csdn.net/images/p_blog_csdn_net/liu_lin_xm/EntryImages/20091122/gs-15-3.jpg" border="0" />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><h3 style="margin: 0px; padding: 0px; font-family: Arial; line-height: 26px"><a style="color: #ff9900" name="t12"></a>15.2.3 沿射线进行采样</h3><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px"><img style="border: none; max-width: 100%" src="http://p.blog.csdn.net/images/p_blog_csdn_net/liu_lin_xm/EntryImages/20091122/45.jpg" border="0" /><br /></p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="center"></p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">如 图 45 所示，假定光线从 F 点投射到立方体中，并从 L 点投出，在立方体中穿越的距离为 m 。当光线从 F 点投射到立方体中，穿越距离为 n （ n&lt;m ）时进行采样，则存在公式：</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left"><img style="border: none; max-width: 100%" src="http://p.blog.csdn.net/images/p_blog_csdn_net/liu_lin_xm/EntryImages/20091122/gs-15-4.jpg" border="0" />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">其中 Tstart表示立方体表面被投射点的体纹理坐标； d表示投射方向；detal 表示采样间隔，随着 n 的增加而递增；t 为求得的采样纹理坐标。通过求得的采样纹理坐标就可以在体纹理上查询体素数据。直到 n&gt;m ，或者透明度累加超过 1 ，一条射线的采样过程才结束。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">下面总结一下：首先需要一个确定了顶点纹理坐标的三维立方体，光线穿越立方体的过程，就是穿越体纹理的过程，在整个穿越过程中，计算采样体纹理坐标，并进行体纹理采样，这个采样过程直到光线投出立方体或者累加的透明度为 1 时结束。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">我想这个过程应该不复杂，大家一定要记住：纹理坐标是联系三维模型和体纹理数据之间的桥梁，通过计算光线穿越三维模型，可以计算体纹理在光线穿越方向上的变化，这就是计算采样纹理坐标的方法。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">高中时学习物理的力学部分，最初一直处于浑浑噩噩的状态，遇到应用题不知道从何处入手，后来看一本参考资料讲到 &ldquo; 加速度是联系力和运动状态的桥梁，遇到题目首先分析加速度的求法 &rdquo; ，由此举一反三，不再感觉物理难学。所以在此我也借用那句话，总结纹理坐标的作用。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">现在还存在一个问题：如何知道光线投射出了立方体？这个问题等价于计算光线在立方体中穿越的距离 m 。在下一节中将进行阐述。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">附：在 OpenGL 和 DirectX 中，体纹理坐标的分布规则是不一样的，所以要针对自己当前使用的 profile 来确定顶点体纹理坐标的设置。这也从侧面说明了， Cg 语言是基于 OpenGL 和 DirectX 的。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">&nbsp;</p><h3 style="margin: 0px; padding: 0px; font-family: Arial; line-height: 26px"><a style="color: #ff9900" name="t13"></a>15.2.2 如何判断光线投射出体纹理</h3><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">上一节阐述过：光线投射出体纹理，等价于光线投射出立方体。所以如何判断光线投射出体纹理，可以转换为判断光线投射出立方体。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">首先计算光线在立方体中入射到出射的行进距离 m ，然后当每次采样体纹理时同时计算光线在立方体中的穿越距离 n ，如果 n&gt;=m ，则说明光线射出立方体。给定光线方向，以及采样的距离间隔，就可以求出光线在立方体中的穿越距离 n 。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">如果是在 CPU 上，距离 m 很容易通过解析几何的知识求得，直接求出光线和几何体的两个交点坐标，然后计算欧几里德距离即可。但是在 GPU 上计算光线和几何体的交点是一个老大难的问题，尤其在几何体不规则的情况下；此外，就算是规则的几何体，光线与其求交的过程也是非常消耗时间，所以通过求取交点然后计算距离的方法不予采用。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">请思考一下，在 GPU 中确定点和点之间顺序关系的还有哪个量？深度值（我自问自答）。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">在 GPU 中可以间接反应点和点之间关系的有两个量，一个是纹理坐标，另一个就是深度值。通常在渲染中会进行深度剔除，也就是只显示深度值小的片段。不过也存在另外一个深度剔除，将深度值小的片段剔除，而留下深度值最大的片段（深度值的剔除方法设置，在 OpenGL 和 Direct 中都有现成函数调用）。如果使用后者，则场景中渲染显示的是离视点最远的面片集合。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">所以，计算距离 m 的方法如下：</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">1.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 剔除深度值较大的片段（正常的渲染状态），渲染场景深度图 frontDepth （参阅第 14 章），此时 frontDepth 上的每个像素的颜色值都代表&ldquo;某个方向上离视点最近的点的距离&rdquo;；</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">2.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 剔除深度值较小的片段，渲染场景深度图 backDepth ， backDepth 上的每个像素的颜色值都代表&ldquo;某个方向上离视点最远的点的距离&rdquo;；</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">3.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; 将两张深度图上的数据进行相减，得到的值就是光线投射距离 m 。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">如果认真实现过第 14 章讲的 shadow Map 算法，对这个过程应该不会感到太复杂。可能存在的问题是：背面渲染很多人没有接触过。这里对背面渲染的一些细微之处进行阐述，以免大家走弯路。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">通常，背面的面片（不朝向视点的面片）是不会被渲染出来的，图形学基础比较好的同学应该知道，三个顶点通常按逆时针顺序组成一个三角面，这样做的好处是，背面面片的法向量与视线法向量的点积为负数，可以据此做面片剔除算法（光照模型实现中也常用到），所以只是改变深度值的比较方法还不够，还必须关闭按照逆 / 顺时针进行面片剔除功能，这样才能渲染出背面深度图。 图 46 是立方体的正面和背面深度图。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left"><img style="border: none; max-width: 100%" src="http://p.blog.csdn.net/images/p_blog_csdn_net/liu_lin_xm/EntryImages/20091122/46.jpg" border="0" /><br /></p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="center"></p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="left">附：在很多教程上，都是将 frontDepth 和 backDepth 相减后的值，保存为另外一个纹理，称之为方向纹理，每个像素由 r 、 g 、 b 、 a 组成，前三个通道存储颜色值，最后的 a 通道存放距离值，我觉得这个过程稍微繁琐了些，此外由于方向向量可能存在负值，而颜色通道中只能保存正值，所以必须将方向向量归一化到【 0 ， 1 】空间，这个过程有可能导致数据精度的损失。基于如上的考虑，我将方向向量的计算放到片段着色程序中，通过视点和顶点位置进行计算。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;</p><h2 style="margin: 0px; padding: 0px; font-family: Arial; line-height: 26px"><a style="color: #ff9900" name="t14"></a>算法流程</h2><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px"><img style="border: none; max-width: 100%" src="http://p.blog.csdn.net/images/p_blog_csdn_net/liu_lin_xm/EntryImages/20091122/47.jpg" border="0" /><br /></p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="center"><br /></p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">图 47 展示了使用光线投射算法进行体绘制的实现流程。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">首先要渲染出正向面深度图和背向面深度图，这是为了计算射线穿越的最大距离，做为循环采样控制的结束依据；然后在顶点着色程序中计算顶点位置和射线方向，射线方向由视线方向和点的世界坐标决定，其实射线方向也可以放在片段着色程序中进行计算。然后到了最关键的地方，就是循环纹理采样、合成。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">每一次循环都要计算新的采样纹理坐标和采样距离，然后进行颜色合成和透明度累加，如果采样距离超过了最大穿越距离，或者透明度累加到 1 ，则循环结束。将合成得到的颜色值输出即可。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">图 48 给出了使用光线投射算法进行体绘制的效果图：</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px"><img style="border: none; max-width: 100%" src="http://p.blog.csdn.net/images/p_blog_csdn_net/liu_lin_xm/EntryImages/20091122/48.jpg" border="0" /><br /></p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px" align="center"></p><h2 style="margin: 0px; padding: 0px; font-family: Arial; line-height: 26px"><a style="color: #ff9900" name="t15"></a>15.4 光线投射算法实现</h2><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">本节给出光线投射算法的着色程序实现代码。依然是分为三个部分：结构体、顶点着色程序和片段着色程序。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">代码 22 光线投射算法结构体</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">struct VertexIn</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&#123;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp; float4 position : POSITION;&nbsp;&nbsp;&nbsp;&nbsp;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp; float4 texCoord:&nbsp; TEXCOORD;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&#125;;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">struct VertexScreen</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&#123;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp; float4 position&nbsp;&nbsp; : POSITION;&nbsp;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp; float4 worldPos&nbsp;&nbsp; : TEXCOORD0;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp; float4 projPos&nbsp;&nbsp;&nbsp; : TEXCOORD1;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp; float4 texCoord&nbsp;&nbsp; : TEXCOORD2;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&#125;;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">代码 23 光线投射算法顶点着色程序</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">VertexScreen main_v(VertexIn posIn,</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;uniform float4x4 world,</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;uniform float4x4 worldViewProj,</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;uniform float4x4 texViewProj)</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&#123;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp; VertexScreen posOut;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp; posOut.position = mul(worldViewProj, posIn.position);</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp; posOut.worldPos = mul(world,posIn.position);</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp; posOut.projPos = mul(texViewProj, posOut.worldPos);&nbsp;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp; posOut.texCoord = posIn.texCoord;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp; return posOut;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&#125;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">代码 24 光线投射算法片段着色程序</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">void main_f(VertexScreen posIn,</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; uniform float3 eyePosition,</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; uniform sampler3D volumeTex: register(s0),</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; uniform sampler2D frontDepthTex: register(s1) ,</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; uniform sampler2D backDepthTex: register(s2) ,</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; out float4 result&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : COLOR)</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&#123;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // 根据视点和当前顶点世界坐标计算方向</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; float3 dir = posIn.worldPos.xyz-eyePosition;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; dir = normalize(dir);</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; float3 deltaDir = float3(0.0, 0.0, 0.0);</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // 获取当前顶点的三维纹理坐标</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; float3 tex = posIn.texCoord.xyz;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; float2 uvDelta;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; uvDelta.x = 0.0;//ddx( tex ).x;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; uvDelta.y = 0.0;//ddy( tex ).y;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // 取出深度间隔值 , 并设置采样间隔</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; float2 uv= posIn.projPos.xy/posIn.projPos.w;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; float frontDis = tex2D(frontDepthTex,uv).x;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; float backDis = tex2D(backDepthTex,uv).x;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; float len = backDis-frontDis;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // 初始化颜色值、采样值、透明度</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp; float3 norm_dir = normalize(dir);</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp; float stepsize = 0.01;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp; float delta = stepsize;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp; float3 delta_dir = norm_dir * delta;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp; float delta_dir_len = length(delta_dir);</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp; float3 vec = posIn.texCoord.xyz;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp; float4 col_acc = float4(0,0,0,0);</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp; float alpha_acc = 0;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp; float length_acc = 0;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp; float4 color_sample;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp; float alpha_sample;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp; for(int i = 0; i &lt; 800; i++)&#123;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; color_sample = tex3D(volumeTex,vec);</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; alpha_sample = color_sample.a * stepsize;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; col_acc&nbsp;&nbsp; += (1.0 - alpha_acc) * color_sample * alpha_sample * 3;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; alpha_acc += alpha_sample;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; vec += delta_dir;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; length_acc += delta_dir_len;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if(length_acc &gt;= len &#124;&#124; alpha_acc &gt; 1.0) break; // 采样循环控制条件</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&#125;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; result.xyz = col_acc.xyz*2.0+float3(0.2,0.2,0.2);</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; result.w = col_acc.w;&nbsp;&nbsp;</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">&#125;</p><h2 style="margin: 0px; padding: 0px; font-family: Arial; line-height: 26px"><a style="color: #ff9900" name="t16"></a>15.5 本章小结</h2><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">本书的第14 、15 章阐述了体绘制中光线投射算法的基本原理和实现流程。实际上，在此基础上可以对光线投射算法加以扩展，例如将光线投射算法和阴影绘制算法相结合，可以渲染出真实感更强的图像。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">此外，有些体数据是中间是空的，在射线方向上进行采样时需要跳过空区域，这其中也需要额外的算法处理，在英文中称为&ldquo;Object-Order Empty Space Skipping &rdquo;。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">目前我所发现关于体绘制以及光线投射算法最好的教材是Markus Hadwiger 等人所写的&ldquo;Advanced Illumination Techniques for GPU-Based Volume Raycasting &rdquo;。此书发表在SIGGRAPH ASIA2008 上，是目前所能找到最新也是非常权威的教材，共166 页。英文阅读能力比较好的同学可以尝试着看一下。</p><p style="margin: 0px; padding: 0px; font-family: Arial; font-size: 14px; line-height: 26px">本章已经是此书的最后一章，最后希望中国的计算机科学可以真正上升到科学研究的层次，而不是一直在混沌中热衷做泥瓦匠的工作。</p>
]]>
</description>
</item><item>
<link>http://i.renjihe.com/blog/read.php?7395</link>
<title><![CDATA[地形纹理Splatting技术(翻译)]]></title> 
<author>renjihe1988 &lt;admin@yourname.com&gt;</author>
<category><![CDATA[CV&amp;Graphic]]></category>
<pubDate>Fri, 22 Jul 2016 06:35:30 +0000</pubDate> 
<guid>http://i.renjihe.com/blog/read.php?7395</guid> 
<description>
<![CDATA[ 
	<p style="margin: 10px auto; padding: 0px; line-height: 21.6px">文章来源:<a style="margin: 0px; padding: 0px; color: #000000" href="http://www.gamedev.net/reference/articles/article2238.asp">http://www.gamedev.net/reference/articles/article2238.asp</a></p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px"><span style="margin: 0px; padding: 0px; font-size: 14pt">Texture Splatting in Direct3D Introduction</span></p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;If you've been looking into terrain texturing techniques, you've probably heard about texture splatting. The term was coined by Charles Bloom, who discussed it at&nbsp;<a style="margin: 0px; padding: 0px; color: #000000" href="http://www.cbloom.com/3d/techdocs/splatting.txt">http://www.cbloom.com/3d/techdocs/splatting.txt</a>. With no disrespect to Charles Bloom, it was not the most clear or concise of articles, and has left many confused in its wake. While many use and recommend it, few have taken the time to adequately explain it. I hope to clear up the mystery surrounding it and demonstrate how to implement it in your own terrain engine.</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 如果有已经学习过地形纹理技术，你很可能已经听说过纹理splatting技术。这个术语是Charles Bloom创造的，他在<a style="margin: 0px; padding: 0px; color: #000000" href="http://www.cbloom.com/3d/techdocs/splatting.txt">http://www.cbloom.com/3d/techdocs/splatting.txt</a>里对这个技术进行了阐述。并不是想对Charles Bloom失礼，他所写的并不是一篇条理清晰的文章，存在许多的令人迷惑的地方。使用它的大部分人少有对其进行充分的解释。我希望自己能揭开围绕它的迷雾，并阐述如何在你自己的地形引擎中实现这个技术。</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px"><span style="margin: 0px; padding: 0px; font-size: 14pt">&nbsp;The Basics</span></p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;What is texture splatting? In its simplest form, it is a way to blend textures together on a surface using alphamaps.</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">那什么是splatting呢?&nbsp; 最简单的解释如下：它是一种使用alphamaps技术将纹理融合到表面的技术。</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;I will use the term alphamap to refer to a grayscale image residing in a single channel of a texture. It can be any channel alpha, red, green, blue, or even luminance. In texture splatting, it will be used to control how much of a texture appears at a given location. This is done by a simple multiplication, alphamap * texture. If the value of a pexel in the alphamap is 1, that texture will appear there in full value; if the value of a pexel in the alphamap is 0, that texture will not appear there at all.</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">我将使用术语alphamap来关联属于纹理中某通道的颜色。一个纹理中通常有多个通道：红、绿、蓝、或者是亮度。在纹理的splatting中，alphamap将用于控制该纹理在当前位置显示颜色的多少。通过一个简单的乘法很容易做到：alphamap * texture（texture指代当前位置纹理的颜色值）。如果某像素的alphamap是1，则纹理显示全值，如果某像素的alphamap是0，则该纹理完全不显示。</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;For terrain, the texture might be grass, dirt, rock, snow, or any other type of terrain you can think of. Bloom refers to a texture and its corresponding alphamap as a splat. An analogy would be throwing a glob of paint at a canvas. The splat is wherever you see that glob. Multiple globs of paint layered on top of each other create the final picture.</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">在地形里，纹理可能是草、泥土、岩石、雪或者你能想到的其他类型。Bloom将纹理和其对应的alphamap值统称为一个splat。类似于在帆布上涂鸦的效果。splat就是无处不在的小水滴，通过在绘制层混合这些水滴创建最好的图像。</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;Let's say you have a 128x128 heightmap terrain, divided into 32x32 chunks. Each chunk would then be made up of 33x33 vertices. Each chunk has the base textures repeated several times over it ?but the alphamap is stretched over the entire area. (0, 0) of the chunk would have alphamap coordinates of (0, 0) and texture coordinates of (0, 0). (33, 33) of the chunk would have alphamap coordinates of (1, 1) and texture coordinates of (x, x), where x is the number of times you want the textures to be repeated. x will depend on the resolution of the textures. Try to make sure they repeat enough to make detail up close, but not so much that the repetition is obvious from far away.</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">假设你有一个128&times;128的地形高度图，将其分割为32&times;32的块。每块由33&times;33个顶点构成。每块通过平铺贴图的形式贴上了基本的纹理。但alphamap贴图覆盖了整个块的区域，块(0, 0)的位置对应alphamap坐标和纹理坐标(0, 0)的位置，第(33, 33)个顶点alphamap坐标为（1，1），而纹理坐标为 (x, x)，x是你想让纹理重复的次数。x视纹理的分辨率而定。应该通过平铺纹理确保纹理有足够的细节，但从远处看的话，细节就不重要了。</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;The resolution of your alphamap per chunk is something you need to decide for yourself, but I recommend powers of two. For a 32&times;32 chunk, you could have a 32&times;32 alphamap (one texel per unit), a 64&times;64 alphamap (two texels per unit), or even a 128&times;128 alphamap (four texels per unit). When deciding what resolution to use, remember that you need an alphamap for every texture that appears on a given chunk. The higher the resolution is, the more control over the blending you have, at the cost of memory.</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">每个块的alphamap的分辨率需要你去制定，但我建议是2的次方。如果是32&times;32的块，你可以创建一个32&times;32 alphamap（每个单位一个texel），64&times;64 alphamap或者是128&times;128 alphamap。在选择使用哪个分辨率的时候，记住你需要为每个呈现于所给块上的纹理一个alphamap（译者：如果在一个块上你打算使用4种纹理的元素，那么这个块将由4个alphamap进行混合而得到）。分辨率越高，你需要做的混合就越多，内存消耗也越大。</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px"><br />&nbsp;The size of the chunk is a little trickier to decide. Too small and you will have too many state changes and draw calls, too large and the alphamaps may contain mostly empty space. For example, if you decided to create an alphamap with 1 texel per unit with a chunk size of 128x128, but the alphamap only has non-zero values in one small 4x4 region, 124x124 of your alphamap is wasted memory. If your chunk size was 32x32, only 28x28 would be wasted. This brings up a point: if a given texture does not appear at all over a given chunk, don't give that chunk an alphamap for that texture.</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">　　块大小的选择有一定的技巧。太小的话，你将涉及过多的状态改变和绘制调用。太到的话，alphamaps有可能包含过多的空区域。例如：如果你打算创建一个一单位一个texel的128&times;128的块，但alphamap仅仅在一个4&times;4的小区域有非零的值，124&times;124的内存空间都被浪费了。如果块是32&times;32，那么浪费的空间仅仅是28&times;28。这是一个需注意的地方：如果给的纹理并不覆盖块的所有区域，那么不必为块提供<br />与纹理相关的alphamap。</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;The reason the terrain is divided into chunks is now apparent. Firstly, and most importantly, it can save video memory, and lots of it. Secondly, it can reduce fillrate consumption. By using smaller textures, the video card has less sampling to do if the texture does not appear on every chunk. Thirdly, it fits into common level of detail techniques such as geomipmapping that require the terrain to be divided into chunks anyway.</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">　　为什么地形需要分为块的原因逐渐明朗。首先，分块能节省大量显存空间。再次，它降低了速度上的消耗。使用较小纹理时，如果纹理不出现在块中，显卡的采样处理将减小。第三，这种方法适用于geomipmapping等需要地形切分的LOD地形技术。</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;Creating the Blends</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;The key to getting smooth blending is linear interpolation of the alphamaps. Suppose there is a1 right next to a0. When the alphamap is stretched out over the terrain, Direct3D creates an even blend between the two values. The stretched alphamap is then combined with terrain texture, causing the texture itself to blend.</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;Rendering then becomes the simple matter of going through each chunk and rendering the splats on it. Generally, the first splat will be completely opaque, with the following splats having varying values in their alphamaps. Let me demonstrate with some graphics. Let's say the first splat is dirt. Because it is the first that appears on that chunk, it will have an alphamap that is completely solid.</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px"><br />　　获得平滑混合效果的关键是对alphamaps进行线性插值。假设a1在a0的右边。当alphamap延展到整个地形，Direct3D在两个值之间创建平滑的混合。延展的alphamap用纹理连接起来促使了纹理自身的混合。<br />&nbsp;遍历每个块并在其上绘制splat是一个简单的小问题。通常，第一个splat将是完全不透明的，接下来的splats的值根据alphamaps将有变换。让我们用一些图进行论证。第一个splat为泥土层。因为泥土更像是在块中的最底层显示的东西，它的alphamap应该是完全不透明的。</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;&nbsp;<img style="margin: 0px; padding: 0px; border: 1px solid black; max-width: 660px" src="http://pic002.cnblogs.com/img/dawnli/201005/2010050911065868.gif" border="0" alt="线框" />*&nbsp;<img style="margin: 0px; padding: 0px; border: 0px; max-width: 660px" src="http://pic002.cnblogs.com/img/dawnli/201005/2010050911075331.gif" border="0" />&nbsp; =&nbsp;&nbsp;<img style="margin: 0px; padding: 0px; border: 0px; max-width: 660px" src="http://pic002.cnblogs.com/img/dawnli/201005/2010050911075331.gif" border="0" /></p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;　　After the first splat is rendered, the chunk is covered with dirt. Then a grass layer is added on top of that:<br />　　第一个splat绘制后，块被泥土覆盖。结着草层将被加在上边。</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px"><img style="margin: 0px; padding: 0px; border: 0px; max-width: 660px" src="http://pic002.cnblogs.com/img/dawnli/201005/2010050911091266.jpg" border="0" /></p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;The process is repeated for the rest of the splats for the chunk.<br />&nbsp;It is important that you render everything in the same order for each chunk. Splat addition is not commutative. Skipping splats won't cause any harm, but if you change the order around, another chunk could end up looking like this:<br />&nbsp;剩下的splats对于块的操作都是类似的重复。为每个块绘制东西的顺序是十分重要的。Splat混合的顺序不可交换。不进行splats混合倒不会有什么问题，但如果你改变了周围块的绘制顺序，另一个块的绘制结果如下：</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px"><img style="margin: 0px; padding: 0px; border: 0px; max-width: 660px" src="http://pic002.cnblogs.com/img/dawnli/201005/2010050911101112.jpg" border="0" /></p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;The grass splat is covered up because the dirt splat is completely opaque and was rendered second.<br />&nbsp;You may be wondering why the first splat should be opaque. Let's say it wasn't, and instead was only solid where the grass splat was clear. Here's what happens:</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">因为泥土splat完全不透明，并且是第二次绘制的，致使草层被掩盖。<br />你可能对第一个splat要保持不透明有所疑问。让我们将其设为透明试试，替代图的一部分草层splat被清空。结果如下：</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px"><img style="margin: 0px; padding: 0px; border: 0px; max-width: 660px" src="http://pic002.cnblogs.com/img/dawnli/201005/2010050911102157.jpg" border="0" /></p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;It's obvious this does not look right when compared with the blend from before. By having the first splat be completely opaque, you prevent any roles?from appearing like in the picture above.<br />很明显，混合后的效果并不是很好。但如果将第一个splat设置为完全透明的话，效果就不一样了。（<span style="margin: 0px; padding: 0px; color: #ff0000">这里不知如何翻译合适）</span></p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px"><span style="margin: 0px; padding: 0px; color: #ff0000">&nbsp;</span></p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px"><span style="margin: 0px; padding: 0px; font-size: 14pt">&nbsp;Creating the Alphamaps</span></p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;Now that we know what texture splatting is, we need to create the alphamaps to describe our canvas. But how do we decide what values to give the alphamaps?</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;Some people base it off of terrain height, but I recommend giving the ability to make the alphamaps whatever you want them to be. This gives you the flexibility to put any texture wherever you want with no limitations. It's as simple as drawing out the channels in your paint program of choice. Even better, you could create a simple world editor that allows the artist to see their alphamap and interact with it in the actual world.</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">　　现在我们了解了什么是texture splatting，我们需要创建alphamaps来描述涂鸦用的帆布。但我们该往alphamaps上填充什么值呢？<br />&nbsp;一些人创建alphamaps时脱离了地形高度值，但我建议读者最好有控制alphamaps的能力。这是你将任何纹理置于你所希望的地方。在你的程序中加入绘制通道。如果你能创建一个简单的世界编辑器允许美工看到alphamap，并能够将它融入实际的世界中。</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px"><span style="margin: 0px; padding: 0px; font-size: 14pt">&nbsp;Implementation</span></p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;Let's take a step back and look at what we have: Some sort of terrain representation, such as a heightmap A set of textures to be rendered on the terrain. An alphamap for each texture</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">Look at #3. We know that each alphamap has to be in a texture. Does this mean that every alphamap needs its own texture? Thankfully, the answer is no. Because the alphamap only has to be in a single channel of a texture, we can pack up to four alphamaps into a single texture ?one in red, one in green, one in blue, and one in alpha. In order to access these individual channels we will need to use a pixel shader, and because we need five textures (one with the alphamaps and four to blend), PS 1.4 is required. Unfortunately this is a still stiff requirement, so I will show how to use texture splatting with the fixed function pipeline as well as with a pixel shader.</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">实现<br />&nbsp;退一步说，看看我们将实现什么：某种地面的表示，例如贴了多种纹理的高度图A需要绘制到地形。每个纹理的alphamap如 #3。我们知道每个alphamap都呈现一个纹理。这是否意味着每个alphamap需要其自身的纹理呢？谢天谢地，答案是否定的。一个alphamap只需占用纹理的一个通道。我们可以将四个alphamap打包进一张纹理中，r、g、b、a四个通道。我们需要使用 5张纹理，一张用于alphamap，四张用于混合。PS shader1.4的支持是必须的。不幸的是，硬件的要求比较高，所以我将介绍一种使用固定管线的绘制方法实现纹理的splatting。</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px"><br />&nbsp;Splatting with the Fixed Function Pipeline</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;Using the fixed function pipeline has one benefit that the pixel shader technique lacks: it will run on virtually any video card. All it requires is one texture unit for the alphamap, one texture unit for the texture, and the correct blending states.</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;I chose to put the alphamap in stage 0 and the texture in stage 1. This was to stay consistent with the pixel shader, which makes most sense with the alphamap in stage 0. The texture stage states are relatively straightforward from there. Stage 0 passes its alpha value up to stage 1. Stage 1 uses that alpha value as its own and pairs it with its own color value.</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">当显卡不支持着色技术时，固定管线的绘制方法便显示其益处：这种方法可运行在基本所有的显卡上。所需的仅仅是一个用于alphamap的纹理单位，一个用于纹理的纹理单位以及正确的混合状态设置。</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">// Alphamap: take the alpha from the alphamap, we don't care about the color<br />g_Direct3DDevice-&gt;SetTextureStageState(0, D3DTSS_ALPHAOP, D3DTOP_SELECTARG1);<br />g_Direct3DDevice-&gt;SetTextureStageState(0, D3DTSS_ALPHAARG1, D3DTA_TEXTURE);</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">// Texture: take the color from the texture, take the alpha from the previous stage<br />g_Direct3DDevice-&gt;SetTextureStageState(1, D3DTSS_COLOROP, D3DTOP_SELECTARG1);<br />g_Direct3DDevice-&gt;SetTextureStageState(1, D3DTSS_COLORARG1, D3DTA_TEXTURE);<br />g_Direct3DDevice-&gt;SetTextureStageState(1, D3DTSS_ALPHAOP, D3DTOP_SELECTARG1);<br />g_Direct3DDevice-&gt;SetTextureStageState(1, D3DTSS_ALPHAARG1, D3DTA_CURRENT);</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;We have to set the blending render states as well in order to get the multiple splats to combine together correctly. D3DRS_SRCBLEND is the alpha coming from the splat being rendered, so we set it to D3DBLEND_SRCALPHA. The final equation we want is FinalColor = Alpha * Texture + (1 ?Alpha) * PreviousColor. This is done by setting D3DRS_DESTBLEND to D3DBLEND_INVSRCALPHA.<br />g_Direct3DDevice-&gt;SetRenderState(D3DRS_ALPHABLENDENABLE, TRUE);<br />g_Direct3DDevice-&gt;SetRenderState(D3DRS_SRCBLEND, D3DBLEND_SRCALPHA);<br />g_Direct3DDevice-&gt;SetRenderState(D3DRS_DESTBLEND, D3DBLEND_INVSRCALPHA);</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">我们必须正确地设置绘制状态使得splats被正确地连接起来。D3DRS_SRCBLEND是splat被绘制所需的alpha状态，所以我们设置D3DBLEND_SRCALPHA。混合公式如下：FinalColor = Alpha * Texture + (1-Alpha) * PreviousColor。通过设置D3DRS_DESTBLEND to D3DBLEND_INVSRCALPHA，可以达到这种混合效果。</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px"><span style="margin: 0px; padding: 0px; font-size: 14pt">&nbsp;Splatting with a Pixel Shader</span></p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">Why even bother with the pixel shader? Using all the channels available in a texture instead of only one saves memory. It also allows us to render four splats in a single pass, reducing the number of vertices that need to be transformed. Because all of the texture combining takes place in the shader, there are no texture stage states to worry about. We just load the texture with an alphamap in each channel into stage 0, the textures into stages 1 through 4, and render.</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">为什么恰好要涉及pixel shader呢？使用纹理中的多个通道来替换传统的仅仅是节省内存的技术。它容许我们在一个绘制过程里渲染四个splats，降低了需要变换的顶点数。因为所有的纹理混合发生在shader操作中，所以无需关心纹理的stage状态。我们正好将每个通道的alphamap放在stage 0，纹理放在stage 1~4，然后进行绘制。</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px"><br />ps_1_4</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">////////////////////////////////<br />// r0: alphamaps<br />// r1 - r4: textures<br />////////////////////////////////</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">// Sample textures<br />texld r0, t0&nbsp;&nbsp;//t0 放在 r0存储器中<br />texld r1, t1&nbsp;&nbsp;//<br />texld r2, t1<br />texld r3, t1<br />texld r4, t1</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">// Combine the textures together based off of their alphamaps<br />mul r1, r1, r0.x&nbsp;&nbsp;//r1 = r0.x * r1<br />lrp r2, r0.y, r2, r1&nbsp;//以r0.y为参数在r2与r1之间做插值，结果放在r2中<br />lrp r3, r0.z, r3, r2&nbsp;//以r0.z为参数在r3与r2之间做插值，结果放在r3中<br />lrp r0, r0.w, r4, r3&nbsp;//以r0.w为参数在r4与r3之间做插值，结果放在r0中</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px"><br />&nbsp;The mul instruction multiplies the first texture by its alphamap, which is stored in the red channel of the texture in sampler 0. The lrp instruction does the following arithmetic: dest = src0 * src1 + (1 - src0) * src2. Let's say r0.x is the alphamap for a dirt texture stored in r1, and r0.y is the alphamap for a grass texture stored in r2. r2 contains the following after the first lrp: GrassAlpha * GrassTexture + (1-GrassAlpha) * DirtBlended, where DirtBlended is DirtAlpha * DirtTexture. As you can see, lrp does the same thing as the render states and texture stage states we set before. The final lrp uses r0 as the destination register, which is the register used as the final pixel color. This eliminates the need for a final mov instruction.</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">乘法指令将sampler0纹理的x值与sampler1纹理的值相乘. lrp指令做了一下的计算：dest = src0 * src1 + (1 - src0) * src2.<br />我们可以这样理解：r0.x是存于r1的灰土纹理的alphamap分量，r0.y是存于r2的草纹理的alphamap分量，依此类推。经过第一个lrp操作后r2的值将变为：GrassAlpha * GrassTexture + (1-GrassAlpha) * DirtBlended。正如你所看到的，lrp所做的与之前提到的固定管线绘制操作一样。最后的lrp操作将r0作为目标寄存器，该寄存器的值便是最后的像素颜色。这省去(eliminate)了一个mov指令。</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;What if you only need to render two or three splats for a chunk? If you want to reuse the pixel shader, simply have the remaining channels be filled with 0. That way they will have no influence on the final result. You could also create another pixel shader for two splats and a third for three splats, but the additional overhead of more SetPixelShader calls may be less efficient than using an extra instruction or two.</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">如果你仅仅要为一个chunk绘制2到3个splats，那什么是你需要的呢？如果你想重复使用 pixel shader ，要实现的功能仅仅是将剩余没有到的通道置0。这种方式将不会对最后的结果产生影响。你也可以针对2个splat的操作创建另一个pixel shader，也可以创建第三个pixel shader用于3个splat的操作，但是SetPixelShader带来的额外的开销比使用一个额外的指令效率低。</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;Multiple passes are required if you need to render more than four splats for a chunk. Let's say you have to render seven splats. You first render the first four, leaving three left. The alpha channel of your second alphamap texture would be filled with 0, causing the fourth texture to cancel out in the equation. You simply set the alphamap texture and the three textures to be blended and render. The D3DRS_BLEND and D3DRS_SRCBLEND stages from before perform the same thing as the lrp in the pixel shader, allowing the second pass to combine seamlessly with the first.</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">如果你想绘制多于4个splats的时候，就需要多passes的操作。假设需要渲染7个splat。你先绘制前4个。第二个alphamap未用到的alpha通道将被填充为0, 使第四个纹理从方程中剔除。你仅仅需要设置alphamap和剩余的三个纹理进行混合和渲染。前面介绍的D3DRS_BLEND和D3DRS_SRCBLEND渲染状态设置可实现同样的效果，将第二个pass与前面的pass混合。</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px"><br /><span style="margin: 0px; padding: 0px; font-size: 14pt">&nbsp;The Demo</span></p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;The demo application uses the two techniques described here to render a texture splatted quad. I decided not to go for a full heightmap to make it as easy as possible to find the key parts in texture splatting. Because of this, the demo is completely fillrate limited. The initial overhead of the pixel shader may cause some video cards to perform worse with it than with its fixed function equivalent, so take the frame rates with a grain of salt. The pixel shader will almost always come out ahead in a more complex scene.</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;You can toggle between the fixed function pipeline and the pixel shader through the option in the View menu.</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;The textures used are property of nVidia? and are available in their full resolution at<a style="margin: 0px; padding: 0px; color: #000000" href="http://developer.nvidia.com/object/IO_TTVol_01.html">http://developer.nvidia.com/object/IO_TTVol_01.html</a>.</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px"><br />演示程序使用了两种技术描述了渲染splatted四边形的方法。为了简化splatting操作，我没有引入一个完整的高度图。也正因为如此，演示程序的功能有一定的限制。</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px"><span style="margin: 0px; padding: 0px; font-size: 14pt">Sources</span></p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;Terrain Texture Compositing by Blending in the Frame-Buffer by Charles Bloom,<a style="margin: 0px; padding: 0px; color: #000000" href="http://www.cbloom.com/3d/techdocs/splatting.txt">http://www.cbloom.com/3d/techdocs/splatting.txt</a></p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;And, of course, the helpful people at&nbsp;<a style="margin: 0px; padding: 0px; color: #000000" href="http://www.gamedev.net/">http://www.gamedev.net</a></p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;Feel free to send any questions or comments to&nbsp;<a style="margin: 0px; padding: 0px; color: #000000" href="mailto:nglasser@charter.net">nglasser@charter.net</a>&nbsp;or private message Raloth on the forums!</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px"><span style="margin: 0px; padding: 0px; font-size: 14pt"><span style="margin: 0px; padding: 0px; color: #ff0000">----------------------------------------------------------------------------------------</span></span></p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px"><span style="margin: 0px; padding: 0px; font-size: 14pt"><span style="margin: 0px; padding: 0px; color: #ff0000"><span style="margin: 0px; padding: 0px; font-size: 18pt"><span style="margin: 0px; padding: 0px; font-family: 黑体">译注：</span></span></span></span>文中用的是比较早的shader版本，用汇编写的，我改成了通俗的版本:</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">float4 main_ps(float2 iTexCoord0: TEXCOORD0) : COLOR&nbsp;<br />&#123;&nbsp;<br />&nbsp; float3 cov1 = tex2D(SplatMap0, iTexCoord0).rgb;<br />&nbsp; float3 cov2 = tex2D(SplatMap1, iTexCoord0).rgb;<br />&nbsp;<br />&nbsp; float4 oColor;&nbsp;<br />&nbsp; oColor = tex2D(TexSplat0, iTexCoord0) * cov1.x<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; + tex2D(TexSplat1, iTexCoord0) * cov1.y<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; + tex2D(TexSplat2, iTexCoord0) * cov1.z<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; + tex2D(TexSplat3, iTexCoord0) * cov2.x<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; + tex2D(TexSplat4, iTexCoord0) * cov2.y<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; + tex2D(TexSplat5, iTexCoord0) * cov2.z;<br />&nbsp;&nbsp;&nbsp;<br />&nbsp;&nbsp; return oColor;<br />&#125;</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">另外，如显存及带宽足够大的话，用于Splatting的地形纹理可以组合在一张纹理中，减少创建纹理的开销，类似这样：</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px"><img style="margin: 0px; padding: 0px; border: 0px; max-width: 660px" src="http://pic002.cnblogs.com/img/dawnli/201005/2010050911171370.jpg" border="0" /></p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">对应的shader代码可以改成：</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">float4 main_ps(float2 iTexCoord0: TEXCOORD0) : COLOR&nbsp;<br />&#123;<br />&nbsp;<br />&nbsp; float4 oColor;&nbsp;&nbsp;&nbsp;&nbsp;<br />&nbsp; float3 cov1 = tex2D(SplatMap0, iTexCoord0).rgb;<br />&nbsp; float3 cov2 = tex2D(SplatMap1, iTexCoord0).rgb;<br />&nbsp;&nbsp;<br />&nbsp; float2 splatTexCoord0;<br />&nbsp; float2 splatTexCoord1;&nbsp;<br />&nbsp; float2 splatTexCoord2;<br />&nbsp; float2 splatTexCoord3;<br />&nbsp;<br />&nbsp; iTexCoord0.x = fmod( iTexCoord0.x,1.0 );<br />&nbsp; iTexCoord0.y = fmod( iTexCoord0.y,1.0 );<br />&nbsp;&nbsp;<br /><span style="margin: 0px; padding: 0px; color: #ff0000">&nbsp; splatTexCoord0 = iTexCoord0/2.0;<br />&nbsp; splatTexCoord1 = splatTexCoord0 + float2( 0.5,0.0 );<br />&nbsp; splatTexCoord2 = splatTexCoord0 + float2( 0.0,0.5 );&nbsp;&nbsp;<br />&nbsp; splatTexCoord3 = splatTexCoord0 + float2( 0.5,0.5 );</span>&nbsp;&nbsp;<br />&nbsp;&nbsp;<br />&nbsp; oColor = tex2D(TexSplat0, splatTexCoord0) * cov1.x<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; + tex2D(TexSplat0, splatTexCoord1) * cov1.y<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; + tex2D(TexSplat0, splatTexCoord2) * cov1.z<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; + tex2D(TexSplat0, splatTexCoord3) * cov2.x<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; + tex2D(TexSplat1, splatTexCoord0) * cov2.y<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; + tex2D(TexSplat1, splatTexCoord1) * cov2.z;<br />&nbsp;&nbsp;&nbsp;<br />&nbsp;&nbsp; return oColor;<br />&#125;</p><p style="margin: 10px auto; padding: 0px; line-height: 21.6px">&nbsp;<span style="margin: 0px; padding: 0px; font-size: 14pt"><span style="margin: 0px; padding: 0px; color: #ff0000">----------------------------------------------------------------------------------------</span></span></p>
]]>
</description>
</item>
</channel>
</rss>